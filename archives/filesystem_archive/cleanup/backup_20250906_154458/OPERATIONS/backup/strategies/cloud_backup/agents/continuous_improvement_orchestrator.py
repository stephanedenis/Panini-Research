#!/usr/bin/env python3
"""
ü§ñ ORCHESTRATEUR AGENTS AM√âLIORATION CONTINUE
===========================================

Orchestrateur autonome pour coordination:
- Agent Recherche Th√©orique (mise √† jour connaissances)
- Agent Critique Adverse (am√©lioration continue)
- Cycles de validation et am√©lioration
- Fonctionnement 100% autonome et externalis√©

Objectif: Am√©lioration continue autonome de l'√©cosyst√®me PaniniFS
via recherche th√©orique et critique constructive.
"""

import asyncio
import json
import subprocess
import time
import sys
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

# Import surveillance GitHub
sys.path.append('/home/stephane/GitHub/PaniniFS-1/Copilotage/scripts')
from github_workflow_monitor import GitHubWorkflowMonitor
from typing import Dict, List, Optional
import os
from pathlib import Path
import schedule
import threading

class ContinuousImprovementOrchestrator:
    """Orchestrateur principal am√©lioration continue"""
    
    def __init__(self):
        self.session_id = f"orchestrator_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        self.base_path = Path("/home/stephane/GitHub/PaniniFS-1")
        self.agents_path = self.base_path / "Copilotage" / "agents"
        self.logs_path = self.base_path / "logs"
        
        # Configuration surveillance
        self.monitoring_active = True
        self.last_github_check = None
        self.github_monitor = GitHubWorkflowMonitor()
        
        # Statistiques session
        self.session_stats = {
            'start_time': datetime.now().isoformat(),
            'research_cycles': 0,
            'critic_cycles': 0,
            'github_checks': 0,
            'improvements_identified': 0,
            'errors_encountered': 0
        }
        
        print(f"ü§ñ Orchestrateur initialis√© - Session: {self.session_id}")
        self._log_orchestrator_event('initialization', 'INFO', 'Orchestrateur d√©marr√© avec surveillance GitHub')
            
    def _setup_scheduling(self):
        """Configure planning automatique des agents"""
        print("üìÖ Configuration planning automatique...")
        
        # Agent recherche th√©orique - hebdomadaire
        schedule.every().sunday.at(self.schedule_config['research_time']).do(
            self._execute_research_agent
        )
        
        # Agent critique - quotidien
        schedule.every().day.at(self.schedule_config['criticism_time']).do(
            self._execute_critic_agent
        )
        
        # Rapport quotidien
        schedule.every().day.at(self.schedule_config['report_time']).do(
            self._generate_daily_report
        )
        
        print("‚úÖ Planning configur√©:")
        print(f"  üìö Recherche th√©orique: {self.schedule_config['research_day']} {self.schedule_config['research_time']}")
        print(f"  üî• Critique adverse: quotidien {self.schedule_config['criticism_time']}")
        print(f"  üìä Rapport: quotidien {self.schedule_config['report_time']}")
        
    def _execute_initial_cycle(self):
        """Ex√©cute le cycle initial complet d'am√©lioration"""
        print("üîÑ CYCLE INITIAL AM√âLIORATION CONTINUE")
        print("=" * 50)
        
        try:
            # 1. Surveillance GitHub workflows
            github_status = self._monitor_github_workflows()
            
            # 2. Recherche th√©orique
            if self._execute_research_agent():
                print("‚úÖ Agent recherche th√©orique termin√©")
            else:
                print("‚ùå √âchec agent recherche")
                
            # 3. Analyse critique
            if self._execute_critic_agent():
                print("‚úÖ Agent critique adverse termin√©")  
            else:
                print("‚ùå √âchec agent critique")
                
            # 4. Analyse crois√©e
            self._cross_analysis_research_criticism()
            
            # 5. Surveillance continue GitHub
            if github_status:
                print("‚úÖ Surveillance GitHub int√©gr√©e")
            
            print("üéØ Cycle initial termin√© - surveillance continue activ√©e")
            
        except Exception as e:
            print(f"‚ùå Erreur cycle initial: {e}")
            self._log_orchestrator_event('initial_cycle_error', 'ERROR', f'Erreur: {e}')
    
    def _monitor_github_workflows(self) -> bool:
        """Surveille les workflows GitHub et g√©n√®re des alertes"""
        print("üîç Surveillance GitHub Workflows...")
        
        try:
            import subprocess
            
            # Tentative v√©rification workflows avec GitHub CLI
            try:
                result = subprocess.run(
                    ['gh', 'workflow', 'list'], 
                    cwd=self.base_path,
                    capture_output=True, 
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    workflows_info = result.stdout
                    
                    # V√©rification runs r√©cents
                    runs_result = subprocess.run(
                        ['gh', 'run', 'list', '--limit', '5'],
                        cwd=self.base_path,
                        capture_output=True,
                        text=True,
                        timeout=30
                    )
                    
                    # Analyse √©checs r√©cents
                    failed_runs = []
                    if runs_result.returncode == 0:
                        lines = runs_result.stdout.strip().split('
')
                        for line in lines[1:]:  # Skip header
                            if 'failure' in line.lower() or 'failed' in line.lower():
                                failed_runs.append(line.strip())
                    
                    # G√©n√©ration alerte si √©checs
                    if failed_runs:
                        alert_message = f"‚ö†Ô∏è ALERTES GITHUB WORKFLOWS D√âTECT√âES:
"
                        for failed in failed_runs:
                            alert_message += f"  ‚Ä¢ {failed}
"
                        
                        print(alert_message)
                        
                        # Log alerte
                        self._log_orchestrator_event(
                            'github_workflow_failures', 
                            'WARNING',
                            f'{len(failed_runs)} workflows en √©chec d√©tect√©s'
                        )
                        
                        # Sauvegarde rapport d√©taill√©
                        self._save_github_monitoring_report(workflows_info, runs_result.stdout, failed_runs)
                    else:
                        print("  ‚úÖ Tous workflows GitHub op√©rationnels")
                        self._log_orchestrator_event('github_workflows_healthy', 'INFO', 'Workflows op√©rationnels')
                    
                    return True
                    
                else:
                    print("  ‚ö†Ô∏è GitHub CLI non configur√© - surveillance manuelle recommand√©e")
                    self._log_orchestrator_event('github_cli_unavailable', 'WARNING', 'GitHub CLI non configur√©')
                    return False
                    
            except FileNotFoundError:
                print("  ‚ö†Ô∏è GitHub CLI non install√© - Installation: 'sudo apt install gh'")
                self._log_orchestrator_event('github_cli_missing', 'WARNING', 'GitHub CLI non install√©')
                return False
                
            except subprocess.TimeoutExpired:
                print("  ‚ö†Ô∏è Timeout surveillance GitHub - v√©rification manuelle requise")
                self._log_orchestrator_event('github_timeout', 'WARNING', 'Timeout surveillance workflows')
                return False
                
        except Exception as e:
            print(f"  ‚ùå Erreur surveillance GitHub: {e}")
            self._log_orchestrator_event('github_monitoring_error', 'ERROR', f'Erreur: {e}')
            return False
    
    def _save_github_monitoring_report(self, workflows_info: str, runs_info: str, failed_runs: List[str]):
        """Sauvegarde rapport d√©taill√© surveillance GitHub"""
        try:
            from datetime import datetime
            
            report = {
                'timestamp': datetime.now().isoformat(),
                'workflows_status': workflows_info,
                'recent_runs': runs_info,
                'failed_runs': failed_runs,
                'total_failures': len(failed_runs),
                'monitoring_status': 'active',
                'recommendations': [
                    'V√©rifier logs des workflows en √©chec',
                    'Corriger erreurs de configuration',
                    'Red√©clencher workflows si n√©cessaire',
                    'Monitorer tendances √©checs'
                ]
            }
            
            # Sauvegarde JSON
            report_path = os.path.join(self.base_path, f'github_monitoring_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
                
            print(f"  üìä Rapport GitHub sauv√©: {report_path}")
            
        except Exception as e:
            print(f"  ‚ùå Erreur sauvegarde rapport GitHub: {e}")
        
    def _execute_research_agent(self) -> bool:
        """Ex√©cute l'agent de recherche th√©orique"""
        try:
            print(f"üî¨ Lancement Agent Recherche Th√©orique - {datetime.now()}")
            
            # Marquer agent comme running
            self.agents['theoretical_research']['status'] = 'running'
            self.agents['theoretical_research']['last_run'] = datetime.now()
            
            # Ex√©cution agent
            script_path = os.path.join(self.agents_path, self.agents['theoretical_research']['script'])
            
            # Note: En production r√©elle, utiliser subprocess.run pour isolation
            # Ici, import direct pour d√©monstration
            import sys
            sys.path.append(self.agents_path)
            
            try:
                from theoretical_research_agent import TheoreticalResearchAgent
                
                # Ex√©cution asynchrone
                async def run_research():
                    agent = TheoreticalResearchAgent()
                    await agent.autonomous_research_cycle()
                    
                # Ex√©cute dans event loop
                asyncio.run(run_research())
                
                # Mise √† jour m√©triques
                self.improvement_metrics['research_cycles_completed'] += 1
                self.improvement_metrics['knowledge_updates'] += 1
                
                self.agents['theoretical_research']['status'] = 'completed'
                
                self._log_orchestrator_event('research_agent_completed', 'SUCCESS', 
                                            'Agent recherche th√©orique termin√© avec succ√®s')
                
                print("‚úÖ Agent Recherche Th√©orique termin√©")
                return True
                
            except Exception as e:
                print(f"‚ùå Erreur ex√©cution agent recherche: {e}")
                self.agents['theoretical_research']['status'] = 'error'
                
                self._log_orchestrator_event('research_agent_error', 'ERROR', f'Erreur: {e}')
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur critique agent recherche: {e}")
            return False
            
    def _execute_critic_agent(self) -> bool:
        """Ex√©cute l'agent critique adverse"""
        try:
            print(f"üî• Lancement Agent Critique Adverse - {datetime.now()}")
            
            # Marquer agent comme running
            self.agents['adversarial_critic']['status'] = 'running'
            self.agents['adversarial_critic']['last_run'] = datetime.now()
            
            # Ex√©cution agent
            script_path = os.path.join(self.agents_path, self.agents['adversarial_critic']['script'])
            
            try:
                import sys
                sys.path.append(self.agents_path)
                
                from adversarial_critic_agent import AdversarialCriticAgent
                
                agent = AdversarialCriticAgent()
                agent.autonomous_criticism_cycle()
                
                # Mise √† jour m√©triques
                self.improvement_metrics['criticism_cycles_completed'] += 1
                self.improvement_metrics['issues_identified'] += len(agent.critical_findings)
                
                self.agents['adversarial_critic']['status'] = 'completed'
                
                self._log_orchestrator_event('critic_agent_completed', 'SUCCESS',
                                           f'Agent critique termin√© - {len(agent.critical_findings)} critiques')
                
                print(f"‚úÖ Agent Critique Adverse termin√© - {len(agent.critical_findings)} critiques identifi√©es")
                return True
                
            except Exception as e:
                print(f"‚ùå Erreur ex√©cution agent critique: {e}")
                self.agents['adversarial_critic']['status'] = 'error'
                
                self._log_orchestrator_event('critic_agent_error', 'ERROR', f'Erreur: {e}')
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur critique agent critique: {e}")
            return False
            
    def _cross_analysis_research_criticism(self):
        """Analyse crois√©e entre recherche et critique"""
        print("üîÑ Analyse crois√©e recherche/critique...")
        
        try:
            # Recherche derniers rapports
            research_reports = self._find_latest_reports('theoretical_research_report_')
            critic_reports = self._find_latest_reports('adversarial_criticism_report_')
            
            if not research_reports or not critic_reports:
                print("‚ö†Ô∏è Rapports insuffisants pour analyse crois√©e")
                return
                
            # Chargement derniers rapports
            latest_research = self._load_latest_report(research_reports)
            latest_critic = self._load_latest_report(critic_reports)
            
            # Analyse crois√©e
            cross_analysis = {
                'timestamp': datetime.now().isoformat(),
                'research_session': latest_research.get('session_id', 'unknown'),
                'critic_session': latest_critic.get('session_id', 'unknown'),
                'theoretical_gaps_vs_criticisms': self._analyze_gaps_vs_criticisms(latest_research, latest_critic),
                'validation_opportunities': self._find_validation_opportunities(latest_research, latest_critic),
                'contradiction_resolution': self._resolve_contradictions(latest_research, latest_critic),
                'improvement_priorities': self._prioritize_improvements(latest_research, latest_critic)
            }
            
            # Sauvegarde analyse crois√©e
            cross_analysis_path = f"{self.base_path}/cross_analysis_{self.session_id}.json"
            with open(cross_analysis_path, 'w', encoding='utf-8') as f:
                json.dump(cross_analysis, f, indent=2, ensure_ascii=False)
                
            print(f"‚úÖ Analyse crois√©e sauvegard√©e: {cross_analysis_path}")
            
            self._log_orchestrator_event('cross_analysis_completed', 'SUCCESS',
                                       'Analyse crois√©e recherche/critique termin√©e')
            
        except Exception as e:
            print(f"‚ùå Erreur analyse crois√©e: {e}")
            self._log_orchestrator_event('cross_analysis_error', 'ERROR', f'Erreur: {e}')
            
    def _find_latest_reports(self, prefix: str) -> List[str]:
        """Trouve les derniers rapports d'un type"""
        reports = []
        for file in os.listdir(self.base_path):
            if file.startswith(prefix) and file.endswith('.json'):
                reports.append(os.path.join(self.base_path, file))
        return sorted(reports, key=os.path.getmtime, reverse=True)
        
    def _load_latest_report(self, report_files: List[str]) -> Dict:
        """Charge le dernier rapport d'une liste"""
        if not report_files:
            return {}
            
        try:
            with open(report_files[0], 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur chargement rapport {report_files[0]}: {e}")
            return {}
            
    def _analyze_gaps_vs_criticisms(self, research_data: Dict, critic_data: Dict) -> List[Dict]:
        """Analyse gaps th√©oriques vs critiques identifi√©es"""
        correlations = []
        
        research_gaps = research_data.get('theoretical_gaps', [])
        critic_findings = critic_data.get('critical_findings', [])
        
        for gap in research_gaps:
            gap_type = gap.get('gap_type', '')
            
            # Recherche critiques correspondantes
            related_criticisms = []
            for finding in critic_findings:
                if any(keyword in finding.get('issue', '').lower() 
                      for keyword in gap_type.lower().split('_')):
                    related_criticisms.append(finding.get('issue', ''))
                    
            if related_criticisms:
                correlations.append({
                    'theoretical_gap': gap_type,
                    'gap_severity': gap.get('severity', 'UNKNOWN'),
                    'related_criticisms': related_criticisms,
                    'correlation_strength': 'HIGH' if len(related_criticisms) > 2 else 'MEDIUM',
                    'action_priority': 'URGENT' if gap.get('severity') == 'HIGH' else 'MEDIUM'
                })
                
        return correlations
        
    def _find_validation_opportunities(self, research_data: Dict, critic_data: Dict) -> List[Dict]:
        """Trouve opportunit√©s validation entre recherche et d√©fenses"""
        opportunities = []
        
        validations = research_data.get('validation_opportunities', [])
        defensive_responses = critic_data.get('defensive_responses', [])
        
        for validation in validations:
            # Recherche d√©fenses qui pourraient √™tre renforc√©es par cette validation
            for defense in defensive_responses:
                if validation.get('validation_type', '') in defense.get('defense_arguments', []):
                    opportunities.append({
                        'validation_paper': validation.get('paper_title', ''),
                        'defense_topic': defense.get('original_critique', ''),
                        'reinforcement_potential': 'HIGH' if validation.get('strength') == 'STRONG' else 'MEDIUM',
                        'action': 'Citer ce paper pour renforcer d√©fense'
                    })
                    
        return opportunities
        
    def _resolve_contradictions(self, research_data: Dict, critic_data: Dict) -> List[Dict]:
        """R√©sout contradictions entre recherche positive et critiques"""
        resolutions = []
        
        key_findings = research_data.get('key_findings', [])
        contradictions = critic_data.get('critical_findings', [])
        
        for finding in key_findings:
            finding_topic = finding.get('title', '').lower()
            
            # Recherche critiques contradictoires
            conflicting_criticisms = []
            for criticism in contradictions:
                if any(keyword in criticism.get('issue', '').lower() 
                      for keyword in finding_topic.split()[:3]):  # Premiers mots titre
                    conflicting_criticisms.append(criticism)
                    
            if conflicting_criticisms:
                resolutions.append({
                    'positive_finding': finding.get('title', ''),
                    'conflicting_criticisms': [c.get('issue', '') for c in conflicting_criticisms],
                    'resolution_strategy': 'Approfondir recherche pour r√©concilier perspectives',
                    'confidence_gap': 'HIGH' if len(conflicting_criticisms) > 1 else 'MEDIUM'
                })
                
        return resolutions
        
    def _prioritize_improvements(self, research_data: Dict, critic_data: Dict) -> List[Dict]:
        """Priorise am√©liorations bas√©es sur recherche + critique"""
        priorities = []
        
        # Gaps th√©oriques haute priorit√©
        for gap in research_data.get('theoretical_gaps', []):
            if gap.get('severity') == 'HIGH':
                priorities.append({
                    'type': 'theoretical_gap',
                    'description': gap.get('description', ''),
                    'priority_score': 10,
                    'source': 'research_agent'
                })
                
        # Critiques critiques
        for finding in critic_data.get('critical_findings', []):
            if finding.get('severity') == 'CRITICAL':
                priorities.append({
                    'type': 'critical_issue',
                    'description': finding.get('issue', ''),
                    'priority_score': 9,
                    'source': 'critic_agent'
                })
                
        # Tri par score priorit√©
        priorities.sort(key=lambda x: x['priority_score'], reverse=True)
        
        return priorities[:10]  # Top 10
        
    def _generate_daily_report(self):
        """G√©n√®re rapport quotidien √©tat syst√®me"""
        print(f"üìä G√©n√©ration rapport quotidien - {datetime.now()}")
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'orchestrator_session': self.session_id,
            'agents_status': self.agents.copy(),
            'improvement_metrics': self.improvement_metrics.copy(),
            'recent_activity': self._get_recent_activity(),
            'next_scheduled_actions': self._get_next_scheduled_actions(),
            'system_health': self._assess_system_health(),
            'recommendations': self._generate_daily_recommendations()
        }
        
        # Sauvegarde
        daily_report_path = f"{self.base_path}/daily_improvement_report_{datetime.now().strftime('%Y%m%d')}.json"
        with open(daily_report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        print(f"‚úÖ Rapport quotidien sauvegard√©: {daily_report_path}")
        
        # Rapport console
        self._print_daily_summary(report)
        
    def _get_recent_activity(self) -> List[Dict]:
        """R√©cup√®re activit√© r√©cente (24h)"""
        recent_threshold = datetime.now() - timedelta(hours=24)
        
        recent_activity = []
        for event in self.orchestrator_log:
            event_time = datetime.fromisoformat(event.get('timestamp', ''))
            if event_time >= recent_threshold:
                recent_activity.append(event)
                
        return recent_activity
        
    def _get_next_scheduled_actions(self) -> List[Dict]:
        """R√©cup√®re prochaines actions programm√©es"""
        next_actions = []
        
        # Calcul prochaines ex√©cutions
        now = datetime.now()
        
        # Prochaine recherche (dimanche)
        days_until_sunday = (6 - now.weekday()) % 7
        if days_until_sunday == 0:  # Aujourd'hui dimanche
            days_until_sunday = 7
            
        next_research = now + timedelta(days=days_until_sunday)
        next_research = next_research.replace(hour=2, minute=0, second=0, microsecond=0)
        
        next_actions.append({
            'action': 'Agent Recherche Th√©orique',
            'scheduled_time': next_research.isoformat(),
            'frequency': 'weekly'
        })
        
        # Prochaine critique (demain)
        next_critic = (now + timedelta(days=1)).replace(hour=1, minute=0, second=0, microsecond=0)
        
        next_actions.append({
            'action': 'Agent Critique Adverse',
            'scheduled_time': next_critic.isoformat(),
            'frequency': 'daily'
        })
        
        return next_actions
        
    def _assess_system_health(self) -> Dict:
        """√âvalue sant√© du syst√®me d'am√©lioration continue"""
        health = {
            'overall_status': 'UNKNOWN',
            'agents_operational': 0,
            'recent_errors': 0,
            'improvement_trend': 'STABLE',
            'issues': []
        }
        
        # Statut agents
        for agent_name, agent_data in self.agents.items():
            if agent_data.get('status') in ['completed', 'idle']:
                health['agents_operational'] += 1
            elif agent_data.get('status') == 'error':
                health['issues'].append(f"Agent {agent_name} en erreur")
                
        # Erreurs r√©centes
        recent_threshold = datetime.now() - timedelta(hours=24)
        for event in self.orchestrator_log:
            if (event.get('level') == 'ERROR' and 
                datetime.fromisoformat(event.get('timestamp', '')) >= recent_threshold):
                health['recent_errors'] += 1
                
        # Statut global
        if health['agents_operational'] == len(self.agents) and health['recent_errors'] == 0:
            health['overall_status'] = 'HEALTHY'
        elif health['recent_errors'] > 3:
            health['overall_status'] = 'CRITICAL'
        else:
            health['overall_status'] = 'WARNING'
            
        return health
        
    def _generate_daily_recommendations(self) -> List[str]:
        """G√©n√®re recommandations quotidiennes"""
        recommendations = []
        
        # Bas√© sur m√©triques
        if self.improvement_metrics['issues_identified'] > self.improvement_metrics['issues_resolved']:
            recommendations.append("Prioriser r√©solution des issues identifi√©es par agent critique")
            
        if self.improvement_metrics['research_cycles_completed'] == 0:
            recommendations.append("Lancer cycle recherche th√©orique pour mise √† jour connaissances")
            
        if self.improvement_metrics['theoretical_gaps_closed'] == 0:
            recommendations.append("Adresser gaps th√©oriques identifi√©s")
            
        # Recommandations par d√©faut
        if not recommendations:
            recommendations.append("Syst√®me fonctionnel - Continuer monitoring automatique")
            
        return recommendations
        
    def _print_daily_summary(self, report: Dict):
        """Affiche r√©sum√© quotidien en console"""
        print("\n" + "="*60)
        print("üìä R√âSUM√â QUOTIDIEN AM√âLIORATION CONTINUE")
        print("="*60)
        
        # Statut agents
        print("\nü§ñ STATUT AGENTS:")
        for agent, data in report['agents_status'].items():
            status_emoji = {"idle": "üí§", "running": "üèÉ", "completed": "‚úÖ", "error": "‚ùå"}
            emoji = status_emoji.get(data.get('status', 'unknown'), "‚ùì")
            print(f"  {emoji} {agent}: {data.get('status', 'unknown')}")
            
        # M√©triques
        print("\nüìà M√âTRIQUES:")
        metrics = report['improvement_metrics']
        print(f"  üî¨ Cycles recherche: {metrics['research_cycles_completed']}")
        print(f"  üî• Cycles critique: {metrics['criticism_cycles_completed']}")
        print(f"  üêõ Issues identifi√©es: {metrics['issues_identified']}")
        print(f"  ‚úÖ Issues r√©solues: {metrics['issues_resolved']}")
        
        # Sant√© syst√®me
        print(f"\nüè• SANT√â SYST√àME: {report['system_health']['overall_status']}")
        
        # Recommandations
        print("\nüí° RECOMMANDATIONS:")
        for rec in report['recommendations']:
            print(f"  ‚Ä¢ {rec}")
            
        print("\n" + "="*60)
        
    def _continuous_monitoring(self):
        """Monitoring continu du syst√®me avec surveillance GitHub"""
        while self.is_running:
            try:
                # V√©rification agents
                self._check_agents_health()
                
                # Surveillance GitHub workflows (toutes les 15 minutes)
                if datetime.now().minute % 15 == 0:
                    self._monitor_github_workflows()
                
                # Ex√©cution t√¢ches programm√©es
                schedule.run_pending()
                
                # Pause
                time.sleep(60)  # V√©rification chaque minute
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur monitoring: {e}")
                self._log_orchestrator_event('monitoring_error', 'ERROR', f'Erreur: {e}')
                time.sleep(300)  # Pause plus longue en cas d'erreur
                
    def _check_agents_health(self):
        """V√©rifie sant√© des agents"""
        for agent_name, agent_data in self.agents.items():
            # V√©rification timeout
            if agent_data.get('status') == 'running':
                if agent_data.get('last_run'):
                    last_run = agent_data['last_run']
                    if isinstance(last_run, str):
                        last_run = datetime.fromisoformat(last_run)
                        
                    # Timeout apr√®s 2h
                    if datetime.now() - last_run > timedelta(hours=2):
                        print(f"‚ö†Ô∏è Agent {agent_name} en timeout - Reset status")
                        agent_data['status'] = 'error'
                        self._log_orchestrator_event('agent_timeout', 'WARNING', 
                                                   f'Agent {agent_name} timeout')
                        
    def _main_orchestration_loop(self):
        """Loop principal d'orchestration"""
        print("\nüîÑ LOOP PRINCIPAL ORCHESTRATEUR D√âMARR√â")
        print("   Appuyez Ctrl+C pour arr√™ter")
        
        try:
            while self.is_running:
                time.sleep(10)  # Loop principal l√©ger
                
        except KeyboardInterrupt:
            print("\nüõë Interruption d√©tect√©e")
            
    def stop_autonomous_operation(self):
        """Arr√™te op√©ration autonome"""
        print("\nüõë ARR√äT ORCHESTRATEUR AM√âLIORATION CONTINUE")
        
        self.is_running = False
        
        # Rapport final
        final_report = {
            'session_id': self.session_id,
            'stop_timestamp': datetime.now().isoformat(),
            'total_runtime': self._calculate_runtime(),
            'final_metrics': self.improvement_metrics.copy(),
            'agents_final_status': self.agents.copy(),
            'total_events': len(self.orchestrator_log)
        }
        
        final_path = f"{self.base_path}/orchestrator_final_report_{self.session_id}.json"
        with open(final_path, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
            
        print(f"üìä Rapport final sauvegard√©: {final_path}")
        print("‚úÖ Orchestrateur arr√™t√© proprement")
        
    def _calculate_runtime(self) -> str:
        """Calcule temps d'ex√©cution total"""
        if self.orchestrator_log:
            start_time = datetime.fromisoformat(self.orchestrator_log[0]['timestamp'])
            end_time = datetime.now()
            runtime = end_time - start_time
            return f"{runtime.total_seconds():.0f} seconds"
        return "Unknown"
        
    def _log_orchestrator_event(self, event_type: str, level: str, message: str):
        """Log √©v√©nement orchestrateur"""
        event = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type,
            'level': level,
            'message': message,
            'session_id': self.session_id
        }
        
        self.orchestrator_log.append(event)
        
        # Log console si important
        if level in ['ERROR', 'WARNING']:
            level_emoji = {'ERROR': '‚ùå', 'WARNING': '‚ö†Ô∏è', 'INFO': '‚ÑπÔ∏è'}
            emoji = level_emoji.get(level, '‚ÑπÔ∏è')
            print(f"{emoji} [{level}] {message}")
            
    def _generate_comprehensive_report(self):
        """G√©n√®re rapport compr√©hensif initial"""
        print("üìä G√©n√©ration rapport compr√©hensif...")
        
        comprehensive_report = {
            'orchestrator_session': self.session_id,
            'timestamp': datetime.now().isoformat(),
            'initialization_summary': {
                'agents_configured': len(self.agents),
                'scheduling_active': True,
                'monitoring_active': True,
                'initial_cycle_completed': True
            },
            'agents_capabilities': {
                'theoretical_research': {
                    'description': 'Recherche bibliographique automatis√©e',
                    'apis_used': ['arxiv', 'semantic_scholar', 'openalex'],
                    'update_frequency': 'weekly',
                    'knowledge_domains': ['panini_grammar', 'melcuk_theory', 'semantic_compression']
                },
                'adversarial_critic': {
                    'description': 'Critique constructive multi-dimensionnelle',
                    'analysis_categories': ['theoretical', 'technical', 'scientific', 'commercial'],
                    'criticism_frequency': 'daily',
                    'improvement_focus': 'continuous_quality_enhancement'
                }
            },
            'improvement_framework': {
                'research_to_validation_pipeline': 'Recherche ‚Üí Validation ‚Üí Application',
                'criticism_to_improvement_cycle': 'Critique ‚Üí D√©fense ‚Üí Am√©lioration ‚Üí Re-critique',
                'cross_validation': 'Recherche vs Critique pour coh√©rence',
                'autonomous_operation': '100% externalis√© et programm√©'
            },
            'success_metrics': {
                'knowledge_currency': 'Mise √† jour r√©guli√®re connaissances th√©oriques',
                'quality_improvement': 'R√©duction continue issues identifi√©es',
                'credibility_enhancement': 'Validation externe et peer review',
                'innovation_validation': 'Confirmation originalit√© et valeur ajout√©e'
            }
        }
        
        # Sauvegarde
        comprehensive_path = f"{self.base_path}/comprehensive_ci_report_{self.session_id}.json"
        with open(comprehensive_path, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)
            
        print(f"‚úÖ Rapport compr√©hensif sauvegard√©: {comprehensive_path}")

def main():
    """Fonction principale"""
    orchestrator = ContinuousImprovementOrchestrator()
    
    print("ü§ñ ORCHESTRATEUR AM√âLIORATION CONTINUE PANINI")
    print("Objectif: Recherche th√©orique + Critique adverse autonomes")
    print("Mode: 100% externalis√© et programm√©")
    print("=" * 60)
    
    try:
        orchestrator.start_autonomous_operation()
    except Exception as e:
        print(f"‚ùå Erreur critique orchestrateur: {e}")
    finally:
        orchestrator.stop_autonomous_operation()

if __name__ == "__main__":
    main()
