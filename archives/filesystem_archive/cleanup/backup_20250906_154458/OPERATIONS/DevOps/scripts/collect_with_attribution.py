#!/usr/bin/env python3
"""
Collecteur s√©mantique avec tra√ßabilit√© compl√®te
Usage: python collect_with_attribution.py --source wikipedia --concept "intelligence artificielle"
"""

import json
import datetime
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
import hashlib
import sys
import os

# Ajouter le r√©pertoire parent pour imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

@dataclass
class Agent:
    id: str
    type: str  # human, machine, collective
    name: str
    version: Optional[str] = None
    bias_profile: Optional[Dict] = None

@dataclass 
class ProvenanceRecord:
    source_agent: str
    timestamp: str
    method: str
    source_url: str
    extraction_confidence: float
    parent_sources: List[str]

@dataclass
class SemanticAtom:
    id: str
    concept: str
    definition: str
    context: str
    provenance: ProvenanceRecord
    
class AttributionCollector:
    def __init__(self, agent_profile: Agent):
        self.agent = agent_profile
        self.atoms = []
        
    def extract_from_wikipedia(self, concept: str) -> List[SemanticAtom]:
        """Extraction Wikipedia avec attribution compl√®te"""
        try:
            import wikipedia
            wikipedia.set_lang("fr")  # Fran√ßais par d√©faut
        except ImportError:
            print("‚ö†Ô∏è  wikipedia module non install√©. Installation...")
            os.system("pip install wikipedia")
            import wikipedia
            wikipedia.set_lang("fr")
        
        # R√©cup√©ration page
        try:
            print(f"  üîç Recherche Wikipedia: {concept}")
            page = wikipedia.page(concept)
            content = page.content[:2000]  # Premier paragraphe
            
            # G√©n√©ration ID unique
            atom_id = hashlib.md5(f"{concept}_{page.url}_{datetime.datetime.now()}".encode()).hexdigest()[:8]
            
            # Extraction premi√®re phrase comme d√©finition
            sentences = content.split('.')
            definition = sentences[0] if sentences else content[:200]
            
            # Cr√©ation atome s√©mantique
            atom = SemanticAtom(
                id=atom_id,
                concept=concept,
                definition=definition.strip(),
                context=content,
                provenance=ProvenanceRecord(
                    source_agent=self.agent.id,
                    timestamp=datetime.datetime.now().isoformat(),
                    method=f"wikipedia_extraction_{self.agent.version}",
                    source_url=page.url,
                    extraction_confidence=0.85,  # Heuristique
                    parent_sources=[page.url]
                )
            )
            
            self.atoms.append(atom)
            print(f"    ‚úÖ Extrait: {definition[:100]}...")
            return [atom]
            
        except wikipedia.exceptions.DisambiguationError as e:
            print(f"    ‚ö†Ô∏è  Ambigu√Øt√© pour '{concept}', utilisation premi√®re option: {e.options[0]}")
            return self.extract_from_wikipedia(e.options[0])
            
        except wikipedia.exceptions.PageError:
            print(f"    ‚ùå Page non trouv√©e pour: {concept}")
            return []
            
        except Exception as e:
            print(f"    ‚ùå Erreur extraction {concept}: {e}")
            return []
            
    def save_to_store(self, filename: str):
        """Sauvegarde avec m√©tadonn√©es compl√®tes"""
        store = {
            "collection_metadata": {
                "collector_agent": asdict(self.agent),
                "collection_date": datetime.datetime.now().isoformat(),
                "total_atoms": len(self.atoms),
                "version": "0.1.0"
            },
            "semantic_atoms": [asdict(atom) for atom in self.atoms]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(store, f, indent=2, ensure_ascii=False)
            
        print(f"‚úÖ {len(self.atoms)} atomes sauv√©s dans {filename}")

def main():
    print("üöÄ COLLECTEUR S√âMANTIQUE AVEC TRA√áABILIT√â")
    print("=========================================")
    
    # Configuration agent collecteur
    agent = Agent(
        id="autonomous_copilot_v1",
        type="machine", 
        name="PaniniFS Autonomous Copilot",
        version="1.0.0",
        bias_profile={
            "source": "wikipedia_fr", 
            "language": "french", 
            "cultural_context": "western",
            "extraction_method": "first_sentence_heuristic"
        }
    )
    
    print(f"ü§ñ Agent configur√©: {agent.name} v{agent.version}")
    
    # Collecte concepts test
    collector = AttributionCollector(agent)
    
    concepts = [
        "intelligence artificielle",
        "machine learning", 
        "r√©seaux de neurones",
        "apprentissage profond",
        "transformers",
        "blockchain",
        "algorithme"
    ]
    
    print(f"\nüìä Collecte de {len(concepts)} concepts:")
    for i, concept in enumerate(concepts, 1):
        print(f"[{i}/{len(concepts)}] {concept}")
        collector.extract_from_wikipedia(concept)
    
    # Sauvegarde avec tra√ßabilit√©
    store_file = "demo_semantic_store.json"
    collector.save_to_store(store_file)
    
    print(f"\nüéØ COLLECTE TERMIN√âE")
    print(f"‚ú® {len(collector.atoms)} atomes s√©mantiques trac√©s")
    print(f"üìÑ Donn√©es sauv√©es: {store_file}")
    print(f"üîç Chaque atome contient: concept, d√©finition, contexte, provenance compl√®te")
    
    # Affichage exemple
    if collector.atoms:
        example = collector.atoms[0]
        print(f"\nüìã EXEMPLE D'ATOME S√âMANTIQUE:")
        print(f"   ID: {example.id}")
        print(f"   Concept: {example.concept}")
        print(f"   D√©finition: {example.definition[:100]}...")
        print(f"   Agent: {example.provenance.source_agent}")
        print(f"   Timestamp: {example.provenance.timestamp}")
        print(f"   Source: {example.provenance.source_url}")
        print(f"   Confiance: {example.provenance.extraction_confidence}")

if __name__ == "__main__":
    main()
