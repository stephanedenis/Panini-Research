#!/usr/bin/env python3
"""
Collecteur Th√©ories Information - Shannon et successeurs
üßÆ Exploration th√©ories information, compression, fractales pour PaniniFS
"""

import json
import datetime
from typing import List, Dict, Any
import re
import os

class InformationTheoryCollector:
    def __init__(self):
        self.store = {
            "metadata": {
                "version": "1.0",
                "description": "Collecte th√©ories information, compression, fractales",
                "creation_date": datetime.datetime.now().isoformat(),
                "source_type": "information_theory",
                "focus_areas": ["shannon_theory", "compression_algorithms", "fractal_geometry", "emergence_theory"]
            },
            "semantic_atoms": []
        }
    
    def collect_shannon_fundamentals(self) -> List[Dict]:
        """Concepts fondamentaux de Shannon et th√©orie information"""
        concepts = [
            {
                "concept": "Entropie Informationnelle",
                "definition": "Mesure quantitative de l'incertitude contenue dans un message, H(X) = -Œ£ p(x) log‚ÇÇ p(x), fondement de la th√©orie de l'information",
                "category": "shannon_theory",
                "mathematical_form": "H(X) = -Œ£ p(x) log‚ÇÇ p(x)",
                "breakthrough_year": 1948,
                "relevance_score": 0.98
            },
            {
                "concept": "Capacit√© de Canal",
                "definition": "Maximum d'information transmissible par unit√© de temps sur un canal bruit√©, C = B log‚ÇÇ(1 + S/N) selon th√©or√®me Shannon-Hartley",
                "category": "shannon_theory", 
                "mathematical_form": "C = B log‚ÇÇ(1 + S/N)",
                "breakthrough_year": 1948,
                "relevance_score": 0.95
            },
            {
                "concept": "Information Mutuelle",
                "definition": "Quantit√© d'information commune entre deux variables al√©atoires, I(X;Y) = H(X) + H(Y) - H(X,Y), mesure d√©pendance informationnelle",
                "category": "shannon_theory",
                "mathematical_form": "I(X;Y) = H(X) + H(Y) - H(X,Y)",
                "breakthrough_year": 1948,
                "relevance_score": 0.93
            },
            {
                "concept": "Complexit√© de Kolmogorov",
                "definition": "Longueur minimale d'un programme informatique capable de produire une cha√Æne donn√©e, mesure absolue de complexit√© informationnelle",
                "category": "algorithmic_information",
                "mathematical_form": "K(x) = min{|p| : U(p) = x}",
                "breakthrough_year": 1965,
                "relevance_score": 0.96
            },
            {
                "concept": "Entropie Diff√©rentielle",
                "definition": "Extension de l'entropie de Shannon aux variables continues, h(X) = -‚à´ f(x) log f(x) dx, fondement pour signaux analogiques",
                "category": "continuous_information",
                "mathematical_form": "h(X) = -‚à´ f(x) log f(x) dx",
                "breakthrough_year": 1948,
                "relevance_score": 0.91
            }
        ]
        
        return self._convert_to_atoms(concepts, "shannon_fundamentals")
    
    def collect_compression_algorithms(self) -> List[Dict]:
        """Algorithmes compression - extracteurs essence information"""
        concepts = [
            {
                "concept": "Compression LZ77",
                "definition": "Algorithme compression sans perte utilisant fen√™tre glissante pour trouver r√©p√©titions, base de formats ZIP et GZIP",
                "category": "lossless_compression",
                "algorithm_family": "dictionary_based",
                "compression_ratio": "2:1 √† 8:1",
                "relevance_score": 0.89
            },
            {
                "concept": "Transform√©e Cosinus Discr√®te",
                "definition": "Transformation math√©matique DCT = Œ£ f(x) cos(œÄn(x+0.5)/N) concentrant √©nergie signal sur basses fr√©quences, c≈ìur JPEG/MP3",
                "category": "lossy_compression",
                "mathematical_form": "DCT(k) = Œ£ f(x) cos(œÄk(x+0.5)/N)",
                "applications": ["JPEG", "MP3", "MPEG"],
                "relevance_score": 0.94
            },
            {
                "concept": "Codage Huffman",
                "definition": "Algorithme codage entropique optimal assignant codes courts aux symboles fr√©quents, atteignant limite th√©orique Shannon",
                "category": "entropy_coding",
                "optimality": "optimal_for_symbol_probabilities",
                "theoretical_limit": "shannon_entropy",
                "relevance_score": 0.92
            },
            {
                "concept": "Ondelettes Daubechies",
                "definition": "Famille ondelettes orthogonales √† support compact, permettant analyse multi-r√©solution avec localisation temps-fr√©quence",
                "category": "wavelet_compression",
                "mathematical_property": "orthogonal_compact_support",
                "applications": ["JPEG2000", "audio_compression"],
                "relevance_score": 0.88
            },
            {
                "concept": "Quantification Vectorielle",
                "definition": "Technique compression groupant vecteurs similaires en codes repr√©sentatifs, exploitant corr√©lations multi-dimensionnelles",
                "category": "vector_quantization",
                "dimension_reduction": "high_dimensional_clustering",
                "applications": ["speech_coding", "image_compression"],
                "relevance_score": 0.85
            },
            {
                "concept": "Pr√©diction Lin√©aire",
                "definition": "Mod√©lisation signal comme combinaison lin√©aire √©chantillons pr√©c√©dents, base compression audio sans perte FLAC",
                "category": "predictive_coding",
                "mathematical_form": "xÃÇ(n) = Œ£ a·µ¢ x(n-i)",
                "applications": ["FLAC", "speech_coding"],
                "relevance_score": 0.87
            }
        ]
        
        return self._convert_to_atoms(concepts, "compression_algorithms")
    
    def collect_fractal_geometry(self) -> List[Dict]:
        """G√©om√©trie fractale - structures √©mergentes auto-similaires"""
        concepts = [
            {
                "concept": "Dimension Fractale",
                "definition": "Mesure non-enti√®re de complexit√© g√©om√©trique, D = log(N)/log(r) o√π N objets √† √©chelle r, r√©v√®le structure auto-similaire",
                "category": "fractal_geometry",
                "mathematical_form": "D = log(N)/log(r)",
                "breakthrough_year": 1967,
                "relevance_score": 0.94
            },
            {
                "concept": "Ensemble de Mandelbrot",
                "definition": "Ensemble fractal d√©fini par it√©ration z_{n+1} = z_n¬≤ + c, fronti√®re r√©v√©lant complexit√© infinie √† toutes √©chelles",
                "category": "complex_dynamics",
                "mathematical_form": "z_{n+1} = z_n¬≤ + c",
                "dimensional_properties": "fractal_boundary",
                "relevance_score": 0.91
            },
            {
                "concept": "Attracteur √âtrange",
                "definition": "Structure fractale vers laquelle √©volue syst√®me dynamique chaotique, combine attraction et sensibilit√© conditions initiales",
                "category": "chaos_theory",
                "properties": ["attraction", "fractal_structure", "sensitive_dependence"],
                "examples": ["lorenz_attractor", "henon_map"],
                "relevance_score": 0.93
            },
            {
                "concept": "Compression Fractale",
                "definition": "Technique compression exploitant auto-similarit√© images via transformations affines contractantes, th√©or√®me point fixe Banach",
                "category": "fractal_compression",
                "mathematical_basis": "banach_fixed_point_theorem",
                "compression_approach": "self_similarity_encoding",
                "relevance_score": 0.86
            },
            {
                "concept": "Mouvement Brownien Fractionnaire",
                "definition": "Processus stochastique auto-similaire avec param√®tre Hurst H, g√©n√©ralise mouvement brownien avec m√©moire longue",
                "category": "stochastic_fractals",
                "mathematical_form": "fBm(H), 0 < H < 1",
                "memory_property": "long_range_dependence",
                "relevance_score": 0.89
            },
            {
                "concept": "Mesure Hausdorff",
                "definition": "G√©n√©ralisation notion mesure pour ensembles fractals, Œº_H(E) = lim inf Œ£ (diam U·µ¢)^s o√π E ‚äÇ ‚à™U·µ¢",
                "category": "measure_theory",
                "mathematical_form": "Œº_H(E) = lim inf Œ£ (diam U·µ¢)^s",
                "applications": ["fractal_dimension", "geometric_measure"],
                "relevance_score": 0.88
            }
        ]
        
        return self._convert_to_atoms(concepts, "fractal_geometry")
    
    def collect_emergence_theories(self) -> List[Dict]:
        """Th√©ories √©mergence - complexit√© issue de simplicit√©"""
        concepts = [
            {
                "concept": "√âmergence Forte",
                "definition": "Propri√©t√©s syst√®me non r√©ductibles aux propri√©t√©s composants, cr√©ant nouveaux niveaux causalit√© descendante",
                "category": "emergence_theory",
                "causality_type": "downward_causation",
                "irreducibility": "non_reductive",
                "relevance_score": 0.92
            },
            {
                "concept": "Transition de Phase",
                "definition": "Changement qualitatif comportement syst√®me √† param√®tre critique, √©mergence ordre macroscopique depuis d√©sordre microscopique",
                "category": "phase_transitions",
                "emergence_type": "macroscopic_order",
                "critical_phenomena": "universality_classes",
                "relevance_score": 0.90
            },
            {
                "concept": "Auto-Organisation Critique",
                "definition": "Tendance syst√®mes complexes √©voluer vers √©tat critique sans r√©glage externe, √©mergence lois puissance universelles",
                "category": "self_organization",
                "mathematical_signature": "power_laws",
                "examples": ["sandpile_model", "forest_fires"],
                "relevance_score": 0.91
            },
            {
                "concept": "Percolation",
                "definition": "Transition phase g√©om√©trique o√π connectivit√© globale √©merge √† seuil critique pc, m√©taphore √©mergence propri√©t√©s collectives",
                "category": "percolation_theory",
                "critical_parameter": "percolation_threshold",
                "emergence_property": "infinite_cluster",
                "relevance_score": 0.87
            },
            {
                "concept": "R√©seaux Complexes",
                "definition": "Structures topologiques exhibant propri√©t√©s √©mergentes: petit monde, invariance √©chelle, communaut√©s auto-organis√©es",
                "category": "network_science",
                "emergent_properties": ["small_world", "scale_free", "clustering"],
                "applications": ["social_networks", "brain_networks"],
                "relevance_score": 0.89
            }
        ]
        
        return self._convert_to_atoms(concepts, "emergence_theories")
    
    def _convert_to_atoms(self, concepts: List[Dict], collection_type: str) -> List[Dict]:
        """Conversion concepts en atomes s√©mantiques standardis√©s"""
        atoms = []
        
        for i, concept_data in enumerate(concepts):
            atom = {
                "concept": concept_data["concept"],
                "definition": concept_data["definition"],
                "category": concept_data["category"],
                "metadata": {
                    key: value for key, value in concept_data.items() 
                    if key not in ["concept", "definition", "category"]
                },
                "provenance": {
                    "source_agent": "information_theory_collector",
                    "timestamp": datetime.datetime.now().isoformat(),
                    "extraction_confidence": concept_data.get("relevance_score", 0.85),
                    "collection_method": f"structured_{collection_type}",
                    "atom_id": f"info_theory_{datetime.datetime.now().strftime('%Y%m%d')}_{collection_type}_{i:03d}"
                }
            }
            atoms.append(atom)
        
        return atoms
    
    def collect_all_domains(self) -> List[Dict]:
        """Collection compl√®te tous domaines th√©ories information"""
        all_atoms = []
        
        print("üßÆ Collecte th√©ories Shannon...")
        all_atoms.extend(self.collect_shannon_fundamentals())
        
        print("üóúÔ∏è  Collecte algorithmes compression...")
        all_atoms.extend(self.collect_compression_algorithms())
        
        print("üåÄ Collecte g√©om√©trie fractale...")
        all_atoms.extend(self.collect_fractal_geometry())
        
        print("‚≠ê Collecte th√©ories √©mergence...")
        all_atoms.extend(self.collect_emergence_theories())
        
        return all_atoms
    
    def save_collection(self, filename: str = "information_theory_semantic_store.json"):
        """Sauvegarde collection th√©ories information"""
        atoms = self.collect_all_domains()
        self.store["semantic_atoms"] = atoms
        self.store["metadata"]["total_atoms"] = len(atoms)
        
        # Statistiques par domaine
        domain_stats = {}
        for atom in atoms:
            category = atom["category"]
            domain_stats[category] = domain_stats.get(category, 0) + 1
        
        self.store["metadata"]["domain_distribution"] = domain_stats
        self.store["metadata"]["mathematical_concepts"] = len([
            atom for atom in atoms 
            if "mathematical_form" in atom.get("metadata", {})
        ])
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.store, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Collection th√©ories information sauv√©e: {filename}")
        print(f"üìä {len(atoms)} concepts collect√©s")
        print(f"üßÆ Domaines couverts: {list(domain_stats.keys())}")
        print(f"üî¢ Concepts math√©matiques: {self.store['metadata']['mathematical_concepts']}")
        
        return len(atoms)

def main():
    print("üßÆ COLLECTEUR TH√âORIES INFORMATION")
    print("==================================")
    print("üéØ Shannon, compression, fractales, √©mergence")
    print("üí° Exploration math√©matiques pour PaniniFS")
    print("")
    
    collector = InformationTheoryCollector()
    total_collected = collector.save_collection()
    
    print(f"\nüèÜ COLLECTION TERMIN√âE")
    print(f"üìà {total_collected} concepts math√©matiques int√©gr√©s")
    print(f"üåü √âlargissement horizon PaniniFS vers domaines fondamentaux!")

if __name__ == "__main__":
    main()
