"""
PaniniFS v4.0 - Provenance Manager

Tracks origin, evolution, and contributors for all objects in CAS.
Provides full audit trail and traceability.

Author: PaniniFS Research
License: MIT
"""

from dataclasses import dataclass, asdict, field
from typing import Dict, Any, Optional, List
from datetime import datetime
from pathlib import Path
from enum import Enum
import json
import yaml


# ============================================================================
# Enums
# ============================================================================

class SourceType(Enum):
    """Type of object origin"""
    EMPIRICAL_ANALYSIS = "empirical_analysis"  # Extracted from data analysis
    MANUAL_CREATION = "manual_creation"         # Created by human
    DERIVED = "derived"                         # Derived from parent(s)
    IMPORTED = "imported"                       # Imported from external source
    AI_GENERATED = "ai_generated"               # Generated by AI
    CONSENSUS = "consensus"                     # Community consensus/vote


class EventType(Enum):
    """Type of evolution event"""
    CREATED = "created"                 # Initial creation
    EXTRACTED = "extracted"             # Extracted from analysis
    REFINED = "refined"                 # Refined/improved
    MERGED = "merged"                   # Merged from multiple sources
    FORKED = "forked"                   # Forked to new branch
    DEPRECATED = "deprecated"           # Marked as deprecated
    CERTIFIED = "certified"             # Certified by authority
    LICENSED = "licensed"               # License applied/changed
    TRANSFERRED = "transferred"         # Ownership transferred


class AgentType(Enum):
    """Type of agent performing action"""
    HUMAN = "human"                             # Human user
    AUTOMATED_SCRIPT = "automated_script"       # Automated script
    AI_ASSISTANT = "ai_assistant"               # AI assistant
    CONSENSUS = "consensus"                     # Community consensus


class ContributorRole(Enum):
    """Role of contributor"""
    PRIMARY_AUTHOR = "primary_author"
    CO_AUTHOR = "co_author"
    MAINTAINER = "maintainer"
    CONTRIBUTOR = "contributor"
    REVIEWER = "reviewer"
    TESTER = "tester"
    DOCUMENTER = "documenter"
    TRANSLATOR = "translator"
    SPONSOR = "sponsor"


# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class Origin:
    """
    Origin of an object
    
    Documents where and how an object was created.
    """
    source_type: SourceType
    created_at: str  # ISO 8601
    created_by: str  # Identity (email, user ID, etc.)
    
    # Optional details
    dataset: Optional[str] = None
    analysis_hash: Optional[str] = None
    parent_hashes: List[str] = field(default_factory=list)
    location: Optional[str] = None
    
    # Validation
    confidence: float = 1.0  # [0.0, 1.0]
    validation_method: Optional[str] = None
    peer_reviewed: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['source_type'] = self.source_type.value
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Origin':
        data = data.copy()
        data['source_type'] = SourceType(data['source_type'])
        return cls(**data)


@dataclass
class Agent:
    """
    Agent that performed an action
    
    Can be human, automated script, AI assistant, or consensus.
    """
    agent_type: AgentType
    identity: str  # User ID, email, script name, etc.
    
    display_name: Optional[str] = None
    # "gpg", "ssh_key", "oauth", "did"
    verification_method: Optional[str] = None
    verified: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['agent_type'] = self.agent_type.value
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Agent':
        data = data.copy()
        data['agent_type'] = AgentType(data['agent_type'])
        return cls(**data)


@dataclass
class EvolutionEvent:
    """
    An event in the evolution of an object
    
    Documents transformations, refinements, merges, etc.
    """
    timestamp: str  # ISO 8601
    event_type: EventType
    agent: Agent
    
    # Optional details
    derivation_hash: Optional[str] = None
    capabilities_added: List[str] = field(default_factory=list)
    capabilities_removed: List[str] = field(default_factory=list)
    breaking_changes: bool = False
    reason: Optional[str] = None
    issue_refs: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['event_type'] = self.event_type.value
        data['agent'] = self.agent.to_dict()
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EvolutionEvent':
        data = data.copy()
        data['event_type'] = EventType(data['event_type'])
        data['agent'] = Agent.from_dict(data['agent'])
        return cls(**data)


@dataclass
class Contributor:
    """
    Contributor to an object
    
    Documents who contributed and how.
    """
    id: str
    role: ContributorRole
    contributions: List[str]  # Types of contributions
    contribution_pct: float  # [0.0, 100.0]
    
    first_contribution: str  # ISO 8601
    last_contribution: str   # ISO 8601
    
    # Optional
    display_name: Optional[str] = None
    affiliation: Optional[str] = None
    orcid: Optional[str] = None  # Academic identifier
    copyright_holder: bool = False
    license_grant: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['role'] = self.role.value
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Contributor':
        data = data.copy()
        data['role'] = ContributorRole(data['role'])
        return cls(**data)


@dataclass
class ProvenanceChain:
    """
    Complete provenance chain for an object
    
    Documents origin, evolution, and contributors.
    """
    object_hash: str
    object_type: str
    
    origin: Origin
    evolution: List[EvolutionEvent] = field(default_factory=list)
    contributors: List[Contributor] = field(default_factory=list)
    
    # Metadata
    traceability_metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'object_hash': self.object_hash,
            'object_type': self.object_type,
            'origin': self.origin.to_dict(),
            'evolution': [e.to_dict() for e in self.evolution],
            'contributors': [c.to_dict() for c in self.contributors],
            'traceability_metadata': self.traceability_metadata
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProvenanceChain':
        return cls(
            object_hash=data['object_hash'],
            object_type=data['object_type'],
            origin=Origin.from_dict(data['origin']),
            evolution=[EvolutionEvent.from_dict(e) for e in data['evolution']],
            contributors=[Contributor.from_dict(c) for c in data['contributors']],
            traceability_metadata=data.get('traceability_metadata', {})
        )
    
    def to_yaml(self) -> str:
        """Export to YAML format"""
        return yaml.dump(self.to_dict(), sort_keys=False, allow_unicode=True)
    
    @classmethod
    def from_yaml(cls, yaml_str: str) -> 'ProvenanceChain':
        """Import from YAML format"""
        data = yaml.safe_load(yaml_str)
        return cls.from_dict(data)


# ============================================================================
# Provenance Manager
# ============================================================================

class ProvenanceManager:
    """
    Manages provenance chains for all objects in CAS
    
    Provides:
    - Origin tracking
    - Evolution timeline
    - Contributor management
    - Queries (by creator, by origin, by date)
    """
    
    def __init__(self, store_path: Path):
        """
        Initialize provenance manager
        
        Args:
            store_path: Path to CAS store directory
        """
        self.store_path = Path(store_path)
        self.provenance_path = self.store_path / "provenance"
        
        # Create directories
        self.provenance_path.mkdir(parents=True, exist_ok=True)
        (self.provenance_path / "by_creator").mkdir(exist_ok=True)
        (self.provenance_path / "by_origin").mkdir(exist_ok=True)
        (self.provenance_path / "timeline").mkdir(exist_ok=True)
    
    def _get_object_provenance_path(self, object_hash: str, object_type: str) -> Path:
        """Get path to provenance file for object"""
        # objects/{type}/{hash[:2]}/{hash}/provenance.json
        obj_dir = self.store_path / "objects" / object_type / object_hash[:2] / object_hash
        obj_dir.mkdir(parents=True, exist_ok=True)
        return obj_dir / "provenance.json"
    
    def create_provenance(self,
                         object_hash: str,
                         object_type: str,
                         origin: Origin) -> ProvenanceChain:
        """
        Create new provenance chain for object
        
        Args:
            object_hash: Content hash of object
            object_type: Type of object (pattern, grammar, etc.)
            origin: Origin information
        
        Returns:
            ProvenanceChain instance
        """
        chain = ProvenanceChain(
            object_hash=object_hash,
            object_type=object_type,
            origin=origin
        )
        
        # Save to file
        self._save_provenance(chain)
        
        # Update indexes
        self._update_indexes(chain)
        
        return chain
    
    def _save_provenance(self, chain: ProvenanceChain):
        """Save provenance chain to file"""
        path = self._get_object_provenance_path(chain.object_hash, chain.object_type)
        
        with open(path, 'w') as f:
            json.dump(chain.to_dict(), f, indent=2)
    
    def load_provenance(self, object_hash: str, object_type: str) -> Optional[ProvenanceChain]:
        """
        Load provenance chain for object
        
        Args:
            object_hash: Content hash
            object_type: Object type
        
        Returns:
            ProvenanceChain or None if not found
        """
        path = self._get_object_provenance_path(object_hash, object_type)
        
        if not path.exists():
            return None
        
        with open(path) as f:
            data = json.load(f)
        
        return ProvenanceChain.from_dict(data)
    
    def record_event(self,
                    object_hash: str,
                    object_type: str,
                    event: EvolutionEvent) -> ProvenanceChain:
        """
        Record evolution event for object
        
        Args:
            object_hash: Content hash
            object_type: Object type
            event: Evolution event to record
        
        Returns:
            Updated ProvenanceChain
        """
        chain = self.load_provenance(object_hash, object_type)
        
        if chain is None:
            raise ValueError(f"No provenance chain found for {object_hash}")
        
        # Add event
        chain.evolution.append(event)
        
        # Save
        self._save_provenance(chain)
        
        # Update indexes
        self._update_indexes(chain)
        
        return chain
    
    def add_contributor(self,
                       object_hash: str,
                       object_type: str,
                       contributor: Contributor) -> ProvenanceChain:
        """
        Add contributor to object
        
        Args:
            object_hash: Content hash
            object_type: Object type
            contributor: Contributor to add
        
        Returns:
            Updated ProvenanceChain
        """
        chain = self.load_provenance(object_hash, object_type)
        
        if chain is None:
            raise ValueError(f"No provenance chain found for {object_hash}")
        
        # Check if contributor already exists
        for c in chain.contributors:
            if c.id == contributor.id:
                # Update existing
                c.last_contribution = contributor.last_contribution
                c.contribution_pct = contributor.contribution_pct
                c.contributions = list(set(c.contributions + contributor.contributions))
                break
        else:
            # Add new
            chain.contributors.append(contributor)
        
        # Save
        self._save_provenance(chain)
        
        # Update indexes
        self._update_indexes(chain)
        
        return chain
    
    def get_full_history(self, object_hash: str, object_type: str) -> Dict[str, Any]:
        """
        Get full history of object
        
        Returns:
            Dict with origin, evolution timeline, contributors
        """
        chain = self.load_provenance(object_hash, object_type)
        
        if chain is None:
            return {}
        
        return {
            'object_hash': chain.object_hash,
            'object_type': chain.object_type,
            'origin': chain.origin.to_dict(),
            'evolution_timeline': [e.to_dict() for e in chain.evolution],
            'contributors': [c.to_dict() for c in chain.contributors],
            'event_count': len(chain.evolution),
            'contributor_count': len(chain.contributors),
            'created_at': chain.origin.created_at,
            'last_modified': chain.evolution[-1].timestamp if chain.evolution else chain.origin.created_at
        }
    
    def find_by_creator(self, creator_id: str) -> List[Dict[str, Any]]:
        """
        Find all objects created by specific creator
        
        Args:
            creator_id: Creator identity
        
        Returns:
            List of object info dicts
        """
        index_file = self.provenance_path / "by_creator" / f"{creator_id}.json"
        
        if not index_file.exists():
            return []
        
        with open(index_file) as f:
            return json.load(f)
    
    def find_by_origin(self, source_type: SourceType) -> List[Dict[str, Any]]:
        """
        Find all objects with specific origin type
        
        Args:
            source_type: Type of origin
        
        Returns:
            List of object info dicts
        """
        index_file = self.provenance_path / "by_origin" / f"{source_type.value}.json"
        
        if not index_file.exists():
            return []
        
        with open(index_file) as f:
            return json.load(f)
    
    def timeline_view(self, date: str) -> List[Dict[str, Any]]:
        """
        Get all events on specific date
        
        Args:
            date: Date in YYYY-MM-DD format
        
        Returns:
            List of events
        """
        timeline_file = self.provenance_path / "timeline" / f"{date}.json"
        
        if not timeline_file.exists():
            return []
        
        with open(timeline_file) as f:
            return json.load(f)
    
    def _update_indexes(self, chain: ProvenanceChain):
        """Update provenance indexes"""
        # Index by creator
        creator_id = chain.origin.created_by
        creator_index = self.provenance_path / "by_creator" / f"{creator_id}.json"
        
        objects = []
        if creator_index.exists():
            with open(creator_index) as f:
                objects = json.load(f)
        
        # Update or add
        obj_info = {
            'object_hash': chain.object_hash,
            'object_type': chain.object_type,
            'created_at': chain.origin.created_at,
            'source_type': chain.origin.source_type.value
        }
        
        # Remove old entry if exists
        objects = [o for o in objects if o['object_hash'] != chain.object_hash]
        objects.append(obj_info)
        
        with open(creator_index, 'w') as f:
            json.dump(objects, f, indent=2)
        
        # Index by origin type
        origin_type = chain.origin.source_type.value
        origin_index = self.provenance_path / "by_origin" / f"{origin_type}.json"
        
        objects = []
        if origin_index.exists():
            with open(origin_index) as f:
                objects = json.load(f)
        
        # Update or add
        objects = [o for o in objects if o['object_hash'] != chain.object_hash]
        objects.append(obj_info)
        
        with open(origin_index, 'w') as f:
            json.dump(objects, f, indent=2)
        
        # Index by timeline (for each event)
        for event in chain.evolution:
            date = event.timestamp[:10]  # YYYY-MM-DD
            timeline_file = self.provenance_path / "timeline" / f"{date}.json"
            
            events = []
            if timeline_file.exists():
                with open(timeline_file) as f:
                    events = json.load(f)
            
            event_info = {
                'object_hash': chain.object_hash,
                'object_type': chain.object_type,
                'timestamp': event.timestamp,
                'event_type': event.event_type.value,
                'agent': event.agent.identity
            }
            
            # Avoid duplicates
            if event_info not in events:
                events.append(event_info)
            
            with open(timeline_file, 'w') as f:
                json.dump(events, f, indent=2)
    
    def export_to_yaml(self, object_hash: str, object_type: str, output_path: Path):
        """
        Export provenance chain to YAML file
        
        Args:
            object_hash: Content hash
            object_type: Object type
            output_path: Path to output YAML file
        """
        chain = self.load_provenance(object_hash, object_type)
        
        if chain is None:
            raise ValueError(f"No provenance chain found for {object_hash}")
        
        with open(output_path, 'w') as f:
            f.write(chain.to_yaml())
    
    def import_from_yaml(self, yaml_path: Path) -> ProvenanceChain:
        """
        Import provenance chain from YAML file
        
        Args:
            yaml_path: Path to YAML file
        
        Returns:
            ProvenanceChain instance
        """
        with open(yaml_path) as f:
            yaml_str = f.read()
        
        chain = ProvenanceChain.from_yaml(yaml_str)
        
        # Save
        self._save_provenance(chain)
        self._update_indexes(chain)
        
        return chain


# ============================================================================
# Utility Functions
# ============================================================================

def create_origin(
    source_type: SourceType,
    created_by: str,
    dataset: Optional[str] = None,
    analysis_hash: Optional[str] = None,
    parent_hashes: Optional[List[str]] = None,
    confidence: float = 1.0
) -> Origin:
    """
    Convenience function to create Origin
    
    Args:
        source_type: Type of origin
        created_by: Creator identity
        dataset: Optional dataset name
        analysis_hash: Optional analysis hash
        parent_hashes: Optional parent object hashes
        confidence: Confidence score [0.0, 1.0]
    
    Returns:
        Origin instance
    """
    return Origin(
        source_type=source_type,
        created_at=datetime.utcnow().isoformat() + 'Z',
        created_by=created_by,
        dataset=dataset,
        analysis_hash=analysis_hash,
        parent_hashes=parent_hashes or [],
        confidence=confidence
    )


def create_event(
    event_type: EventType,
    agent_identity: str,
    agent_type: AgentType = AgentType.HUMAN,
    derivation_hash: Optional[str] = None,
    capabilities_added: Optional[List[str]] = None,
    reason: Optional[str] = None
) -> EvolutionEvent:
    """
    Convenience function to create EvolutionEvent
    
    Args:
        event_type: Type of event
        agent_identity: Identity of agent
        agent_type: Type of agent
        derivation_hash: Optional derivation hash
        capabilities_added: Optional list of added capabilities
        reason: Optional reason for event
    
    Returns:
        EvolutionEvent instance
    """
    return EvolutionEvent(
        timestamp=datetime.utcnow().isoformat() + 'Z',
        event_type=event_type,
        agent=Agent(
            agent_type=agent_type,
            identity=agent_identity
        ),
        derivation_hash=derivation_hash,
        capabilities_added=capabilities_added or [],
        reason=reason
    )


def create_contributor(
    contributor_id: str,
    role: ContributorRole,
    contributions: List[str],
    contribution_pct: float = 100.0
) -> Contributor:
    """
    Convenience function to create Contributor
    
    Args:
        contributor_id: Contributor identity
        role: Contributor role
        contributions: List of contribution types
        contribution_pct: Contribution percentage
    
    Returns:
        Contributor instance
    """
    now = datetime.utcnow().isoformat() + 'Z'
    return Contributor(
        id=contributor_id,
        role=role,
        contributions=contributions,
        contribution_pct=contribution_pct,
        first_contribution=now,
        last_contribution=now
    )
