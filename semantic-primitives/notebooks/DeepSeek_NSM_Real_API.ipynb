{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f0076e",
   "metadata": {},
   "source": [
    "# üî¨ Analyse Comparative DeepSeek vs NSM-Greimas\n",
    "\n",
    "**Projet** : Panini Research - Semantic Primitives  \n",
    "**Date** : 12 novembre 2025  \n",
    "**Objectif** : Valider convergence entre mod√®le symbolique (NSM-Greimas) et neural (DeepSeek)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Hypoth√®ses Test√©es\n",
    "\n",
    "| Hypoth√®se | M√©trique | Seuil | Statut |\n",
    "|-----------|----------|-------|--------|\n",
    "| **H1** - Clustering cat√©goriel | Puret√© | > 0.7 | üîÑ Test |\n",
    "| **H2** - Carr√©s s√©miotiques | Validation | > 70% | üîÑ Test |\n",
    "| **H3** - Isotopies convergentes | Corr√©lation | > 0.6 | üîÑ Test |\n",
    "| **H4** - Reconstruction lin√©aire | R¬≤ | > 0.5 | üîÑ Test |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Avantages Colab Pro\n",
    "\n",
    "- **GPU** : NVIDIA A100/V100 (encodage 100x plus rapide)\n",
    "- **RAM** : 52 GB (corpus 1000+ phrases)\n",
    "- **Runtime** : 24h continues\n",
    "- **Stockage** : Google Drive int√©gr√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf10e81",
   "metadata": {},
   "source": [
    "## üîß Setup Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e38ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier GPU disponible\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU disponible : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de GPU d√©tect√© - Activer GPU dans Runtime > Change runtime type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d489ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer d√©pendances\n",
    "!pip install -q openai matplotlib seaborn scikit-learn scipy plotly numpy pandas\n",
    "\n",
    "print(\"‚úÖ D√©pendances install√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive pour sauvegardes\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cr√©er dossier r√©sultats\n",
    "output_dir = '/content/drive/MyDrive/Panini/DeepSeek_Analysis'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Google Drive mont√©\")\n",
    "print(f\"üìÅ R√©sultats : {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44320999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloner repo Panini Research\n",
    "!git clone https://github.com/stephanedenis/Panini-Research.git\n",
    "%cd Panini-Research/semantic-primitives\n",
    "\n",
    "print(\"‚úÖ Repo clon√©\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ab983",
   "metadata": {},
   "source": [
    "## üîë Configuration API DeepSeek\n",
    "\n",
    "**IMPORTANT** : Stocker votre cl√© API dans les secrets Colab :\n",
    "\n",
    "1. Cliquer sur üîë (ic√¥ne cl√©) dans la barre lat√©rale gauche\n",
    "2. Ajouter secret : `DEEPSEEK_API_KEY` = votre cl√©\n",
    "3. Activer \"Notebook access\"\n",
    "\n",
    "**Obtenir cl√© API** : https://platform.deepseek.com/api_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger cl√© API depuis secrets Colab\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
    "    print(\"‚úÖ Cl√© API DeepSeek charg√©e\")\n",
    "    print(f\"   Pr√©fixe : {DEEPSEEK_API_KEY[:8]}...\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Erreur : Cl√© API non trouv√©e dans secrets Colab\")\n",
    "    print(\"   ‚Üí Ajouter DEEPSEEK_API_KEY dans les secrets (üîë)\")\n",
    "    DEEPSEEK_API_KEY = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc7f10",
   "metadata": {},
   "source": [
    "## üì¶ Import Modules Panini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter chemin modules\n",
    "import sys\n",
    "sys.path.append('/content/Panini-Research/semantic-primitives/panlang')\n",
    "sys.path.append('/content/Panini-Research/semantic-primitives/analysis-scripts')\n",
    "\n",
    "# Imports Panini\n",
    "from nsm_primitives_complet import NSM_PRIMITIVES\n",
    "from greimas_nsm_extension import ReconstructeurGreimasNSM\n",
    "from deepseek_analyzer import (\n",
    "    ClientDeepSeek, \n",
    "    ConfigDeepSeek, \n",
    "    ModeleDeepSeek,\n",
    "    AnalyseurConvergence\n",
    ")\n",
    "\n",
    "# Imports standard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Modules import√©s\")\n",
    "print(f\"   - NSM primitives : {len(NSM_PRIMITIVES)}\")\n",
    "print(f\"   - Reconstructeur Greimas charg√©\")\n",
    "print(f\"   - Analyseur convergence pr√™t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d9329",
   "metadata": {},
   "source": [
    "## üöÄ Initialisation Analyseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7785539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration DeepSeek\n",
    "config = ConfigDeepSeek(\n",
    "    api_key=DEEPSEEK_API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    "    model=ModeleDeepSeek.CHAT,\n",
    "    temperature=0.0  # D√©terministe pour reproductibilit√©\n",
    ")\n",
    "\n",
    "# Client DeepSeek (mode r√©el si cl√© disponible)\n",
    "client = ClientDeepSeek(config)\n",
    "\n",
    "# Analyseur convergence\n",
    "analyseur = AnalyseurConvergence(client)\n",
    "\n",
    "print(\"‚úÖ Analyseur initialis√©\")\n",
    "print(f\"   Mode : {'R√âEL (API DeepSeek)' if DEEPSEEK_API_KEY else 'SIMULATION'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0409b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¨ EXP√âRIENCE 1 : Clustering Primitives NSM\n",
    "\n",
    "**Objectif** : V√©rifier si les 12 cat√©gories NSM sont lin√©airement s√©parables dans l'espace DeepSeek\n",
    "\n",
    "**Protocole** :\n",
    "1. Encoder 60 primitives NSM avec DeepSeek\n",
    "2. R√©duction dimensionnelle t-SNE (4096 ‚Üí 2D)\n",
    "3. Clustering K-means (k=12 cat√©gories)\n",
    "4. Mesure puret√© + silhouette\n",
    "\n",
    "**Seuil validation** : Puret√© > 0.7, Silhouette > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85767b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder primitives NSM\n",
    "print(\"üîÑ Encodage 60 primitives NSM avec DeepSeek...\")\n",
    "print(\"   (Dur√©e estim√©e : 2-3 min avec GPU)\\n\")\n",
    "\n",
    "embeddings_primitives = analyseur.encoder_primitives_nsm()\n",
    "\n",
    "print(f\"\\n‚úÖ {len(embeddings_primitives)} primitives encod√©es\")\n",
    "print(f\"   Dimension embeddings : {embeddings_primitives[0]['embedding'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation t-SNE\n",
    "print(\"üîÑ Calcul t-SNE et visualisation...\\n\")\n",
    "\n",
    "coords_2d, categories = analyseur.visualiser_tsne(\n",
    "    embeddings_primitives,\n",
    "    output_path=f\"{output_dir}/tsne_primitives_nsm_real.png\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "print(f\"\\n‚úÖ Visualisation sauvegard√©e : {output_dir}/tsne_primitives_nsm_real.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation clustering\n",
    "print(\"üîÑ √âvaluation clustering K-means...\\n\")\n",
    "\n",
    "metriques = analyseur.evaluer_clustering(embeddings_primitives)\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS EXP√âRIENCE 1\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Puret√© clustering    : {metriques['purete']:.3f} (seuil > 0.7)\")\n",
    "print(f\"Silhouette score     : {metriques['silhouette']:.3f} (seuil > 0.5)\")\n",
    "print(f\"Nombre clusters      : {metriques['n_clusters']}\")\n",
    "\n",
    "# Validation\n",
    "h1_validee = metriques['purete'] > 0.7 and metriques['silhouette'] > 0.5\n",
    "print(f\"\\n{'‚úÖ' if h1_validee else '‚ùå'} H1 - Clustering cat√©goriel : {'VALID√âE' if h1_validee else 'R√âFUT√âE'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396bb0c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¨ EXP√âRIENCE 2 : Carr√©s S√©miotiques Greimas\n",
    "\n",
    "**Objectif** : V√©rifier si les oppositions Greimas respectent un ordre g√©om√©trique dans DeepSeek\n",
    "\n",
    "**Protocole** :\n",
    "1. Encoder 20 paires de contraires (BON/MAUVAIS, etc.)\n",
    "2. Calculer 4 positions du carr√© : S1, S2, non-S1, non-S2\n",
    "3. Mesurer distances cosinus\n",
    "4. Valider ordre : d(contraire) > d(contradiction) > d(subcontraire)\n",
    "\n",
    "**Seuil validation** : > 70% des carr√©s valident structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser carr√©s s√©miotiques\n",
    "print(\"üîÑ Analyse 20 carr√©s s√©miotiques...\")\n",
    "print(\"   (Dur√©e estim√©e : 3-4 min avec GPU)\\n\")\n",
    "\n",
    "analyse_carres = analyseur.analyser_carres_semiotiques()\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS EXP√âRIENCE 2\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Carr√©s analys√©s      : {len(analyse_carres['resultats'])}\")\n",
    "print(f\"Carr√©s valides       : {sum(1 for r in analyse_carres['resultats'] if r['structure_valide'])}\")\n",
    "print(f\"Taux validation      : {analyse_carres['taux_validation']:.1%}\")\n",
    "\n",
    "# Validation\n",
    "h2_validee = analyse_carres['taux_validation'] > 0.7\n",
    "print(f\"\\n{'‚úÖ' if h2_validee else '‚ùå'} H2 - Carr√©s s√©miotiques : {'VALID√âE' if h2_validee else 'R√âFUT√âE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap carr√©s\n",
    "print(\"\\nüîÑ G√©n√©ration heatmap carr√©s s√©miotiques...\\n\")\n",
    "\n",
    "analyseur.visualiser_heatmap_carres(\n",
    "    analyse_carres,\n",
    "    output_path=f\"{output_dir}/heatmap_carres_real.png\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "print(f\"‚úÖ Heatmap sauvegard√©e : {output_dir}/heatmap_carres_real.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad8b03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¨ EXP√âRIENCE 3 : Isotopies Corpus Litt√©raire\n",
    "\n",
    "**Objectif** : Comparer isotopies NSM avec features principales DeepSeek\n",
    "\n",
    "**Protocole** :\n",
    "1. Corpus litt√©raire (Camus, Hugo, Proust, Saint-Exup√©ry)\n",
    "2. D√©tection isotopies NSM (fr√©quences primitives)\n",
    "3. Encodage DeepSeek + PCA\n",
    "4. Corr√©lation isotopies NSM ‚Üî features PCA\n",
    "\n",
    "**Seuil validation** : Corr√©lation > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a363d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger corpus litt√©raire\n",
    "sys.path.append('/content/Panini-Research/semantic-primitives/tests')\n",
    "from test_corpus_litteraire import CORPUS_CAMUS, CORPUS_HUGO, CORPUS_PROUST, CORPUS_EXUPERY\n",
    "\n",
    "# Corpus complet (105 phrases)\n",
    "corpus_complet = CORPUS_CAMUS + CORPUS_HUGO + CORPUS_PROUST + CORPUS_EXUPERY\n",
    "\n",
    "print(f\"üìö Corpus litt√©raire charg√©\")\n",
    "print(f\"   - Camus : {len(CORPUS_CAMUS)} phrases\")\n",
    "print(f\"   - Hugo : {len(CORPUS_HUGO)} phrases\")\n",
    "print(f\"   - Proust : {len(CORPUS_PROUST)} phrases\")\n",
    "print(f\"   - Saint-Exup√©ry : {len(CORPUS_EXUPERY)} phrases\")\n",
    "print(f\"   - TOTAL : {len(corpus_complet)} phrases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser isotopies (avec GPU)\n",
    "print(\"\\nüîÑ Analyse isotopies corpus complet...\")\n",
    "print(\"   (Dur√©e estim√©e : 5-7 min avec GPU)\\n\")\n",
    "\n",
    "analyse_isotopies = analyseur.analyser_isotopies_corpus(\n",
    "    corpus_complet,\n",
    "    nom_corpus=\"Corpus Litt√©raire Complet (105 phrases)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS EXP√âRIENCE 3\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Phrases analys√©es    : {len(corpus_complet)}\")\n",
    "print(f\"Isotopies d√©tect√©es  : {len(analyse_isotopies['isotopies_nsm'])}\")\n",
    "print(f\"Variance PCA         : {analyse_isotopies['variance_expliquee'].sum():.1%}\")\n",
    "\n",
    "# Top isotopies avec corr√©lations\n",
    "print(f\"\\nüîç Top 10 isotopies NSM :\")\n",
    "top_isotopies = sorted(\n",
    "    analyse_isotopies['isotopies_nsm'].items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "for prim, freq in top_isotopies:\n",
    "    if prim in analyse_isotopies['correlations']:\n",
    "        corr = analyse_isotopies['correlations'][prim]['max_correlation']\n",
    "        print(f\"  {prim:15s} : freq={freq:3d}, corr={corr:.3f}\")\n",
    "\n",
    "# Validation\n",
    "correlations_fortes = [c['max_correlation'] for c in analyse_isotopies['correlations'].values() if c['max_correlation'] > 0.6]\n",
    "h3_validee = len(correlations_fortes) >= len(analyse_isotopies['correlations']) * 0.5\n",
    "\n",
    "print(f\"\\n{'‚úÖ' if h3_validee else '‚ùå'} H3 - Isotopies convergentes : {'VALID√âE' if h3_validee else 'R√âFUT√âE'}\")\n",
    "print(f\"   Isotopies r > 0.6 : {len(correlations_fortes)}/{len(analyse_isotopies['correlations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff793e1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Visualisation 3D Interactive (Plotly)\n",
    "\n",
    "Projection t-SNE 3D des primitives NSM dans l'espace DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE 3D\n",
    "print(\"üîÑ Calcul t-SNE 3D (peut prendre 2-3 min)...\\n\")\n",
    "\n",
    "embeddings_array = np.array([item['embedding'] for item in embeddings_primitives])\n",
    "labels = [item['primitive'] for item in embeddings_primitives]\n",
    "categories = [item['categorie'] for item in embeddings_primitives]\n",
    "\n",
    "tsne_3d = TSNE(n_components=3, perplexity=30, max_iter=1000, random_state=42)\n",
    "coords_3d = tsne_3d.fit_transform(embeddings_array)\n",
    "\n",
    "# Couleurs par cat√©gorie\n",
    "categories_uniques = list(set(categories))\n",
    "color_map = {cat: i for i, cat in enumerate(categories_uniques)}\n",
    "colors = [color_map[cat] for cat in categories]\n",
    "\n",
    "# Graphique 3D interactif\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=coords_3d[:, 0],\n",
    "    y=coords_3d[:, 1],\n",
    "    z=coords_3d[:, 2],\n",
    "    mode='markers+text',\n",
    "    text=labels,\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=colors,\n",
    "        colorscale='Viridis',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=\"Cat√©gorie\", tickvals=list(range(len(categories_uniques))), ticktext=categories_uniques)\n",
    "    ),\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=8)\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Primitives NSM dans l'espace DeepSeek (3D interactif)\",\n",
    "    scene=dict(\n",
    "        xaxis_title='Dimension 1',\n",
    "        yaxis_title='Dimension 2',\n",
    "        zaxis_title='Dimension 3'\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Sauvegarder HTML interactif\n",
    "html_path = f\"{output_dir}/viz_3d_interactive.html\"\n",
    "fig.write_html(html_path)\n",
    "print(f\"\\n‚úÖ Visualisation 3D sauvegard√©e : {html_path}\")\n",
    "print(\"   ‚Üí Ouvrir ce fichier dans navigateur pour interaction compl√®te\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9a465",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üíæ Sauvegarde R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83264c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer r√©sultats pour sauvegarde\n",
    "resultats_complets = {\n",
    "    'metadata': {\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'mode': 'R√âEL' if DEEPSEEK_API_KEY else 'SIMULATION',\n",
    "        'modele': 'deepseek-chat',\n",
    "        'corpus_size': len(corpus_complet)\n",
    "    },\n",
    "    'experience_1': {\n",
    "        'purete': float(metriques['purete']),\n",
    "        'silhouette': float(metriques['silhouette']),\n",
    "        'n_clusters': int(metriques['n_clusters']),\n",
    "        'hypothese_validee': h1_validee\n",
    "    },\n",
    "    'experience_2': {\n",
    "        'taux_validation': float(analyse_carres['taux_validation']),\n",
    "        'carres_valides': sum(1 for r in analyse_carres['resultats'] if r['structure_valide']),\n",
    "        'carres_total': len(analyse_carres['resultats']),\n",
    "        'hypothese_validee': h2_validee\n",
    "    },\n",
    "    'experience_3': {\n",
    "        'isotopies_detectees': len(analyse_isotopies['isotopies_nsm']),\n",
    "        'variance_pca': float(analyse_isotopies['variance_expliquee'].sum()),\n",
    "        'correlations_fortes': len(correlations_fortes),\n",
    "        'hypothese_validee': h3_validee,\n",
    "        'top_isotopies': dict(top_isotopies)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarder JSON\n",
    "json_path = f\"{output_dir}/resultats_deepseek_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(resultats_complets, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ R√©sultats sauvegard√©s : {json_path}\")\n",
    "\n",
    "# Sauvegarder embeddings (pour analyses futures)\n",
    "embeddings_path = f\"{output_dir}/embeddings_primitives.npy\"\n",
    "np.save(embeddings_path, embeddings_array)\n",
    "print(f\"‚úÖ Embeddings sauvegard√©s : {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8dba2a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä RAPPORT FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ebf6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üî¨ ANALYSE COMPARATIVE DEEPSEEK vs NSM-GREIMAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìÖ Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üñ•Ô∏è Mode : {'R√âEL (API DeepSeek)' if DEEPSEEK_API_KEY else 'SIMULATION'}\")\n",
    "print(f\"üìö Corpus : {len(corpus_complet)} phrases litt√©raires\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"R√âSULTATS EXP√âRIENCES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'‚úÖ' if h1_validee else '‚ùå'} EXP√âRIENCE 1 : Clustering Primitives NSM\")\n",
    "print(f\"   Puret√©          : {metriques['purete']:.3f} (seuil > 0.7)\")\n",
    "print(f\"   Silhouette      : {metriques['silhouette']:.3f} (seuil > 0.5)\")\n",
    "print(f\"   ‚Üí H1 : {'VALID√âE' if h1_validee else 'R√âFUT√âE'}\")\n",
    "\n",
    "print(f\"\\n{'‚úÖ' if h2_validee else '‚ùå'} EXP√âRIENCE 2 : Carr√©s S√©miotiques Greimas\")\n",
    "print(f\"   Taux validation : {analyse_carres['taux_validation']:.1%} (seuil > 70%)\")\n",
    "print(f\"   Carr√©s valides  : {sum(1 for r in analyse_carres['resultats'] if r['structure_valide'])}/{len(analyse_carres['resultats'])}\")\n",
    "print(f\"   ‚Üí H2 : {'VALID√âE' if h2_validee else 'R√âFUT√âE'}\")\n",
    "\n",
    "print(f\"\\n{'‚úÖ' if h3_validee else '‚ùå'} EXP√âRIENCE 3 : Isotopies Corpus Litt√©raire\")\n",
    "print(f\"   Isotopies r>0.6 : {len(correlations_fortes)}/{len(analyse_isotopies['correlations'])}\")\n",
    "print(f\"   Variance PCA    : {analyse_isotopies['variance_expliquee'].sum():.1%}\")\n",
    "print(f\"   ‚Üí H3 : {'VALID√âE' if h3_validee else 'R√âFUT√âE'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "hypotheses_validees = sum([h1_validee, h2_validee, h3_validee])\n",
    "print(f\"\\nHypoth√®ses valid√©es : {hypotheses_validees}/3\")\n",
    "\n",
    "if hypotheses_validees >= 2:\n",
    "    print(\"\\n‚úÖ CONVERGENCE VALID√âE\")\n",
    "    print(\"   Les mod√®les NSM-Greimas et DeepSeek convergent significativement.\")\n",
    "elif hypotheses_validees == 1:\n",
    "    print(\"\\n‚ö†Ô∏è CONVERGENCE PARTIELLE\")\n",
    "    print(\"   Les mod√®les convergent partiellement, divergences importantes.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå DIVERGENCE\")\n",
    "    print(\"   Les mod√®les capturent des r√©alit√©s s√©mantiques diff√©rentes.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FICHIERS G√âN√âR√âS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìÅ Dossier : {output_dir}\")\n",
    "print(\"\\nVisualisations :\")\n",
    "print(\"  - tsne_primitives_nsm_real.png\")\n",
    "print(\"  - heatmap_carres_real.png\")\n",
    "print(\"  - viz_3d_interactive.html (ouvrir dans navigateur)\")\n",
    "print(\"\\nDonn√©es :\")\n",
    "print(\"  - resultats_deepseek_YYYYMMDD_HHMMSS.json\")\n",
    "print(\"  - embeddings_primitives.npy\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ANALYSE TERMIN√âE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed37e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üöÄ Prochaines √âtapes\n",
    "\n",
    "## Actions Recommand√©es\n",
    "\n",
    "1. **T√©l√©charger r√©sultats** depuis Google Drive\n",
    "2. **Mettre √† jour rapport** avec r√©sultats API r√©elle\n",
    "3. **Analyser divergences** (si hypoth√®ses r√©fut√©es)\n",
    "4. **Exp√©rience 4** : Reconstruction lin√©aire (r√©gression DeepSeek ‚Üí NSM)\n",
    "5. **Publication** : R√©diger article ACL 2026\n",
    "\n",
    "## Corpus √âtendu (Optionnel)\n",
    "\n",
    "Pour analyse plus robuste, charger corpus large :\n",
    "\n",
    "```python\n",
    "# T√©l√©charger depuis Google Drive\n",
    "corpus_1000 = pd.read_csv('/content/drive/MyDrive/Panini/corpus_1000_phrases.csv')\n",
    "\n",
    "# Relancer Exp√©rience 3\n",
    "analyse_large = analyseur.analyser_isotopies_corpus(\n",
    "    corpus_1000['phrase'].tolist(),\n",
    "    nom_corpus=\"Corpus Large (1000+ phrases)\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Comparaison Multi-Mod√®les\n",
    "\n",
    "Tester convergence avec autres LLMs :\n",
    "\n",
    "- OpenAI GPT-4\n",
    "- Anthropic Claude\n",
    "- Google Gemini\n",
    "- Meta Llama 3\n",
    "\n",
    "**Question** : Quel mod√®le converge le plus vers NSM-Greimas ?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
