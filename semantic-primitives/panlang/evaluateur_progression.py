#!/usr/bin/env python3
"""
Ã‰valuateur de progression et recommandations stratÃ©giques
Analyse les rÃ©sultats obtenus et dÃ©termine la meilleure stratÃ©gie
"""

import json
import os
import time
from pathlib import Path
import subprocess

class ProgressionEvaluator:
    """Ã‰valuateur de progression des analyses PaniniFS"""
    
    def __init__(self):
        self.results = {}
        self.processes = {}
        self.recommendations = []
        self.quality_score = 0.0
        
    def load_analysis_results(self):
        """Charge tous les rÃ©sultats d'analyses disponibles"""
        print("ğŸ“Š CHARGEMENT RÃ‰SULTATS ANALYSES")
        print("=" * 40)
        
        # RÃ©sultats ambiguÃ¯tÃ©s
        ambiguity_files = list(Path('.').glob('analyse_ambiguites_dictionnaire_*.json'))
        if ambiguity_files:
            latest_ambiguity = max(ambiguity_files, key=os.path.getctime)
            with open(latest_ambiguity, 'r', encoding='utf-8') as f:
                self.results['ambiguity'] = json.load(f)
            print(f"âœ… AmbiguÃ¯tÃ©s: {latest_ambiguity}")
        
        # RÃ©sultats raffinement
        refinement_files = list(Path('.').glob('dictionnaire_raffine_*.json'))
        if refinement_files:
            latest_refinement = max(refinement_files, key=os.path.getctime)
            with open(latest_refinement, 'r', encoding='utf-8') as f:
                self.results['refinement'] = json.load(f)
            print(f"âœ… Raffinement: {latest_refinement}")
        
        # RÃ©sultats gÃ©omÃ©triques
        geometric_files = list(Path('.').glob('parallel_analysis_result_*.json'))
        if geometric_files:
            latest_geometric = max(geometric_files, key=os.path.getctime)
            with open(latest_geometric, 'r', encoding='utf-8') as f:
                self.results['geometric'] = json.load(f)
            print(f"âœ… GÃ©omÃ©trique: {latest_geometric}")
        
        # Registre processus
        if os.path.exists('registre_processus_actifs.json'):
            with open('registre_processus_actifs.json', 'r', encoding='utf-8') as f:
                self.processes = json.load(f)
            print("âœ… Registre processus chargÃ©")
    
    def evaluate_ambiguity_analysis(self):
        """Ã‰value rÃ©sultats analyse ambiguÃ¯tÃ©s"""
        if 'ambiguity' not in self.results:
            return {'score': 0, 'status': 'missing'}
        
        data = self.results['ambiguity']
        conflicts = data.get('total_conflicts', 0)
        coverage = len(data.get('quality_analyses', {}))
        
        if conflicts > 150 and coverage > 150:
            score = 0.9  # Excellent
            status = "ğŸ¯ EXCELLENT - DÃ©tection complÃ¨te"
        elif conflicts > 100:
            score = 0.7  # Bon
            status = "âœ… BON - Couverture satisfaisante"
        else:
            score = 0.4  # Moyen
            status = "âš ï¸ MOYEN - Couverture limitÃ©e"
        
        return {
            'score': score,
            'status': status,
            'conflicts': conflicts,
            'coverage': coverage,
            'value': 'Fondamental pour qualitÃ©'
        }
    
    def evaluate_refinement_process(self):
        """Ã‰value rÃ©sultats raffinement"""
        if 'refinement' not in self.results:
            return {'score': 0, 'status': 'missing'}
        
        data = self.results['refinement']
        refined_count = data.get('refinement_count', 0)
        concepts = data.get('concepts_raffines', {})
        
        avg_confidence = 0.0
        if concepts:
            confidences = [c.get('confidence_score', 0.5) for c in concepts.values()]
            avg_confidence = sum(confidences) / len(confidences)
        
        if refined_count >= 20 and avg_confidence > 0.6:
            score = 0.85
            status = "ğŸš€ TRÃˆS BON - Raffinement efficace"
        elif refined_count >= 10:
            score = 0.6
            status = "âœ… ACCEPTABLE - ProgrÃ¨s visible"
        else:
            score = 0.3
            status = "âš ï¸ LIMITÃ‰ - Peu d'impact"
        
        return {
            'score': score,
            'status': status,
            'refined_count': refined_count,
            'avg_confidence': avg_confidence,
            'value': 'AmÃ©lioration qualitative'
        }
    
    def evaluate_geometric_analysis(self):
        """Ã‰value rÃ©sultats analyse gÃ©omÃ©trique"""
        if 'geometric' not in self.results:
            return {'score': 0, 'status': 'missing'}
        
        data = self.results['geometric']
        processing_time = data.get('processing_time', 999)
        quality_metrics = data.get('quality_metrics', {})
        dhatu_coverage = quality_metrics.get('dhatu_coverage', 0)
        
        if processing_time < 1.0 and dhatu_coverage >= 5:
            score = 0.95  # RÃ©volutionnaire
            status = "ğŸ”º RÃ‰VOLUTIONNAIRE - Innovation majeure"
        elif processing_time < 5.0:
            score = 0.8   # TrÃ¨s prometteur
            status = "ğŸš€ TRÃˆS PROMETTEUR - Performance excellent"
        else:
            score = 0.5   # ExpÃ©rimental
            status = "ğŸ§ª EXPÃ‰RIMENTAL - Potentiel Ã  exploiter"
        
        return {
            'score': score,
            'status': status,
            'processing_time': processing_time,
            'dhatu_coverage': dhatu_coverage,
            'value': 'Innovation algorithimique'
        }
    
    def check_running_processes(self):
        """VÃ©rifie processus en cours"""
        try:
            # VÃ©rifier dashboard
            dashboard_check = subprocess.run(['pgrep', '-f', 'dashboard'], 
                                           capture_output=True, text=True)
            dashboard_active = dashboard_check.returncode == 0
            
            return {
                'dashboard': dashboard_active,
                'total_analyses_completed': len(self.results)
            }
        except:
            return {'dashboard': False, 'total_analyses_completed': 0}
    
    def calculate_overall_progress(self):
        """Calcule progression globale"""
        evaluations = {
            'ambiguity': self.evaluate_ambiguity_analysis(),
            'refinement': self.evaluate_refinement_process(),
            'geometric': self.evaluate_geometric_analysis()
        }
        
        total_score = 0
        max_score = 0
        
        for eval_name, eval_data in evaluations.items():
            score = eval_data.get('score', 0)
            total_score += score
            max_score += 1.0
        
        self.quality_score = (total_score / max_score) if max_score > 0 else 0
        
        return evaluations
    
    def generate_strategic_recommendations(self, evaluations):
        """GÃ©nÃ¨re recommandations stratÃ©giques"""
        recommendations = []
        
        # Analyse de la progression
        if self.quality_score > 0.8:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'CAPITALISER',
                'description': 'ğŸ¯ RÃ©sultats excellents - Documenter et prÃ©senter les innovations'
            })
        elif self.quality_score > 0.6:
            recommendations.append({
                'priority': 'MEDIUM', 
                'action': 'OPTIMISER',
                'description': 'ğŸ”§ Bons rÃ©sultats - Affiner et Ã©tendre les analyses'
            })
        else:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'REFOCALISER',
                'description': 'âš ï¸ RÃ©sultats mitigÃ©s - RÃ©viser approche ou objectifs'
            })
        
        # Recommandations spÃ©cifiques
        geometric_eval = evaluations.get('geometric', {})
        if geometric_eval.get('score', 0) > 0.9:
            recommendations.append({
                'priority': 'URGENT',
                'action': 'EXPLOITER_INNOVATION',
                'description': 'ğŸ”º Innovation gÃ©omÃ©trique exceptionnelle - Publier/breveter'
            })
        
        refinement_eval = evaluations.get('refinement', {})
        if refinement_eval.get('refined_count', 0) >= 20:
            recommendations.append({
                'priority': 'MEDIUM',
                'action': 'APPLIQUER_RAFFINEMENTS',
                'description': 'ğŸ“š Raffinements prÃªts - Retraiter corpus avec dictionnaire amÃ©liorÃ©'
            })
        
        # Ã‰tat systÃ¨me
        process_status = self.check_running_processes()
        if process_status['dashboard']:
            recommendations.append({
                'priority': 'LOW',
                'action': 'MONITORING',
                'description': 'ğŸ“Š Dashboard actif - SystÃ¨me stable pour nouvelles analyses'
            })
        
        return recommendations
    
    def should_continue_today(self, evaluations):
        """DÃ©termine si continuer aujourd'hui"""
        # Facteurs de dÃ©cision
        high_quality_results = self.quality_score > 0.7
        innovative_breakthrough = evaluations.get('geometric', {}).get('score', 0) > 0.9
        system_stable = self.check_running_processes()['dashboard']
        
        # Fatigue algorithmique (trop d'analyses similaires)
        analysis_diversity = len([e for e in evaluations.values() if e.get('score', 0) > 0.5])
        algorithm_fatigue = analysis_diversity < 2
        
        continue_recommendation = {
            'decision': False,
            'confidence': 0.0,
            'reasoning': []
        }
        
        if innovative_breakthrough:
            continue_recommendation['decision'] = True
            continue_recommendation['confidence'] += 0.4
            continue_recommendation['reasoning'].append('ğŸ”º Innovation majeure dÃ©tectÃ©e')
        
        if high_quality_results and system_stable:
            continue_recommendation['decision'] = True
            continue_recommendation['confidence'] += 0.3
            continue_recommendation['reasoning'].append('âœ… QualitÃ© Ã©levÃ©e + systÃ¨me stable')
        
        if algorithm_fatigue:
            continue_recommendation['confidence'] -= 0.2
            continue_recommendation['reasoning'].append('âš ï¸ DiversitÃ© algorithmique limitÃ©e')
        
        # Seuil de dÃ©cision
        if continue_recommendation['confidence'] >= 0.5:
            continue_recommendation['decision'] = True
        
        return continue_recommendation
    
    def generate_final_report(self):
        """GÃ©nÃ¨re rapport final avec recommandations"""
        evaluations = self.calculate_overall_progress()
        recommendations = self.generate_strategic_recommendations(evaluations)
        continuation = self.should_continue_today(evaluations)
        
        print(f"\nğŸ¯ Ã‰VALUATION GLOBALE")
        print("=" * 50)
        print(f"ğŸ“Š Score qualitÃ© global: {self.quality_score:.2f}/1.0")
        
        print(f"\nğŸ“ˆ RÃ‰SULTATS PAR ANALYSE:")
        for analysis_name, eval_data in evaluations.items():
            print(f"   {analysis_name.upper()}: {eval_data.get('status', 'N/A')}")
            print(f"      Score: {eval_data.get('score', 0):.2f} - {eval_data.get('value', 'N/A')}")
        
        print(f"\nğŸ¯ RECOMMANDATIONS STRATÃ‰GIQUES:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. [{rec['priority']}] {rec['action']}")
            print(f"      {rec['description']}")
        
        print(f"\nğŸ¤” CONTINUER AUJOURD'HUI ?")
        decision = "OUI" if continuation['decision'] else "NON"
        print(f"   DÃ‰CISION: {decision} (confiance: {continuation['confidence']:.2f})")
        print(f"   RAISONS:")
        for reason in continuation['reasoning']:
            print(f"      - {reason}")
        
        if continuation['decision']:
            print(f"\nğŸš€ PROCHAINE Ã‰TAPE RECOMMANDÃ‰E:")
            if self.quality_score > 0.8:
                print("   ğŸ“‹ Documenter innovations et prÃ©parer prÃ©sentation")
            else:
                print("   ğŸ”§ Optimiser analyses existantes ou explorer nouvelles approches")
        else:
            print(f"\nğŸ RECOMMANDATION:")
            print("   ğŸ’¤ Pause stratÃ©gique - DigÃ©rer rÃ©sultats et planifier prochaine session")
        
        return {
            'quality_score': self.quality_score,
            'evaluations': evaluations,
            'recommendations': recommendations,
            'continue_today': continuation
        }

def main():
    """Point d'entrÃ©e Ã©valuation"""
    print("ğŸ¯ Ã‰VALUATEUR PROGRESSION STRATEGIQUE")
    print("=" * 60)
    
    evaluator = ProgressionEvaluator()
    evaluator.load_analysis_results()
    
    final_assessment = evaluator.generate_final_report()
    
    # Sauvegarde Ã©valuation
    timestamp = int(time.time())
    output_file = f"evaluation_strategique_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_assessment, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ Ã‰valuation sauvegardÃ©e: {output_file}")
    
    return final_assessment

if __name__ == "__main__":
    main()