#!/usr/bin/env python3
"""
√âvaluateur de progression et recommandations strat√©giques
Analyse les r√©sultats obtenus et d√©termine la meilleure strat√©gie
"""

import json
import os
import time
from pathlib import Path
import subprocess

class ProgressionEvaluator:
    """√âvaluateur de progression des analyses PaniniFS"""
    
    def __init__(self):
        self.results = {}
        self.processes = {}
        self.recommendations = []
        self.quality_score = 0.0
        
    def load_analysis_results(self):
        """Charge tous les r√©sultats d'analyses disponibles"""
        print("üìä CHARGEMENT R√âSULTATS ANALYSES")
        print("=" * 40)
        
        # R√©sultats ambigu√Øt√©s
        ambiguity_files = list(Path('.').glob('analyse_ambiguites_dictionnaire_*.json'))
        if ambiguity_files:
            latest_ambiguity = max(ambiguity_files, key=os.path.getctime)
            with open(latest_ambiguity, 'r', encoding='utf-8') as f:
                self.results['ambiguity'] = json.load(f)
            print(f"‚úÖ Ambigu√Øt√©s: {latest_ambiguity}")
        
        # R√©sultats raffinement
        refinement_files = list(Path('.').glob('dictionnaire_raffine_*.json'))
        if refinement_files:
            latest_refinement = max(refinement_files, key=os.path.getctime)
            with open(latest_refinement, 'r', encoding='utf-8') as f:
                self.results['refinement'] = json.load(f)
            print(f"‚úÖ Raffinement: {latest_refinement}")
        
        # R√©sultats g√©om√©triques
        geometric_files = list(Path('.').glob('parallel_analysis_result_*.json'))
        if geometric_files:
            latest_geometric = max(geometric_files, key=os.path.getctime)
            with open(latest_geometric, 'r', encoding='utf-8') as f:
                self.results['geometric'] = json.load(f)
            print(f"‚úÖ G√©om√©trique: {latest_geometric}")
        
        # Registre processus
        if os.path.exists('registre_processus_actifs.json'):
            with open('registre_processus_actifs.json', 'r', encoding='utf-8') as f:
                self.processes = json.load(f)
            print("‚úÖ Registre processus charg√©")
    
    def evaluate_ambiguity_analysis(self):
        """√âvalue r√©sultats analyse ambigu√Øt√©s"""
        if 'ambiguity' not in self.results:
            return {'score': 0, 'status': 'missing'}
        
        data = self.results['ambiguity']
        conflicts = data.get('total_conflicts', 0)
        coverage = len(data.get('quality_analyses', {}))
        
        if conflicts > 150 and coverage > 150:
            score = 0.9  # Excellent
            status = "üéØ EXCELLENT - D√©tection compl√®te"
        elif conflicts > 100:
            score = 0.7  # Bon
            status = "‚úÖ BON - Couverture satisfaisante"
        else:
            score = 0.4  # Moyen
            status = "‚ö†Ô∏è MOYEN - Couverture limit√©e"
        
        return {
            'score': score,
            'status': status,
            'conflicts': conflicts,
            'coverage': coverage,
            'value': 'Fondamental pour qualit√©'
        }
    
    def evaluate_refinement_process(self):
        """√âvalue r√©sultats raffinement"""
        if 'refinement' not in self.results:
            return {'score': 0, 'status': 'missing'}
        
        data = self.results['refinement']
        refined_count = data.get('refinement_count', 0)
        concepts = data.get('concepts_raffines', {})
        
        avg_confidence = 0.0
        if concepts:
            confidences = [c.get('confidence_score', 0.5) for c in concepts.values()]
            avg_confidence = sum(confidences) / len(confidences)
        
        if refined_count >= 20 and avg_confidence > 0.6:
            score = 0.85
            status = "üöÄ TR√àS BON - Raffinement efficace"
        elif refined_count >= 10:
            score = 0.6
            status = "‚úÖ ACCEPTABLE - Progr√®s visible"
        else:
            score = 0.3
            status = "‚ö†Ô∏è LIMIT√â - Peu d'impact"
        
        return {
            'score': score,
            'status': status,
            'refined_count': refined_count,
            'avg_confidence': avg_confidence,
            'value': 'Am√©lioration qualitative'
        }
    
    def evaluate_geometric_analysis(self):
        """√âvalue r√©sultats analyse g√©om√©trique"""
        if 'geometric' not in self.results:
            return {'score': 0, 'status': 'missing'}
        
        data = self.results['geometric']
        processing_time = data.get('processing_time', 999)
        quality_metrics = data.get('quality_metrics', {})
        dhatu_coverage = quality_metrics.get('dhatu_coverage', 0)
        
        if processing_time < 1.0 and dhatu_coverage >= 5:
            score = 0.95  # R√©volutionnaire
            status = "üî∫ R√âVOLUTIONNAIRE - Innovation majeure"
        elif processing_time < 5.0:
            score = 0.8   # Tr√®s prometteur
            status = "üöÄ TR√àS PROMETTEUR - Performance excellent"
        else:
            score = 0.5   # Exp√©rimental
            status = "üß™ EXP√âRIMENTAL - Potentiel √† exploiter"
        
        return {
            'score': score,
            'status': status,
            'processing_time': processing_time,
            'dhatu_coverage': dhatu_coverage,
            'value': 'Innovation algorithimique'
        }
    
    def check_running_processes(self):
        """V√©rifie processus en cours"""
        try:
            # V√©rifier dashboard
            dashboard_check = subprocess.run(['pgrep', '-f', 'dashboard'], 
                                           capture_output=True, text=True)
            dashboard_active = dashboard_check.returncode == 0
            
            return {
                'dashboard': dashboard_active,
                'total_analyses_completed': len(self.results)
            }
        except:
            return {'dashboard': False, 'total_analyses_completed': 0}
    
    def calculate_overall_progress(self):
        """Calcule progression globale"""
        evaluations = {
            'ambiguity': self.evaluate_ambiguity_analysis(),
            'refinement': self.evaluate_refinement_process(),
            'geometric': self.evaluate_geometric_analysis()
        }
        
        total_score = 0
        max_score = 0
        
        for eval_name, eval_data in evaluations.items():
            score = eval_data.get('score', 0)
            total_score += score
            max_score += 1.0
        
        self.quality_score = (total_score / max_score) if max_score > 0 else 0
        
        return evaluations
    
    def generate_strategic_recommendations(self, evaluations):
        """G√©n√®re recommandations strat√©giques"""
        recommendations = []
        
        # Analyse de la progression
        if self.quality_score > 0.8:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'CAPITALISER',
                'description': 'üéØ R√©sultats excellents - Documenter et pr√©senter les innovations'
            })
        elif self.quality_score > 0.6:
            recommendations.append({
                'priority': 'MEDIUM', 
                'action': 'OPTIMISER',
                'description': 'üîß Bons r√©sultats - Affiner et √©tendre les analyses'
            })
        else:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'REFOCALISER',
                'description': '‚ö†Ô∏è R√©sultats mitig√©s - R√©viser approche ou objectifs'
            })
        
        # Recommandations sp√©cifiques
        geometric_eval = evaluations.get('geometric', {})
        if geometric_eval.get('score', 0) > 0.9:
            recommendations.append({
                'priority': 'URGENT',
                'action': 'EXPLOITER_INNOVATION',
                'description': 'üî∫ Innovation g√©om√©trique exceptionnelle - Publier/breveter'
            })
        
        refinement_eval = evaluations.get('refinement', {})
        if refinement_eval.get('refined_count', 0) >= 20:
            recommendations.append({
                'priority': 'MEDIUM',
                'action': 'APPLIQUER_RAFFINEMENTS',
                'description': 'üìö Raffinements pr√™ts - Retraiter corpus avec dictionnaire am√©lior√©'
            })
        
        # √âtat syst√®me
        process_status = self.check_running_processes()
        if process_status['dashboard']:
            recommendations.append({
                'priority': 'LOW',
                'action': 'MONITORING',
                'description': 'üìä Dashboard actif - Syst√®me stable pour nouvelles analyses'
            })
        
        return recommendations
    
    def should_continue_today(self, evaluations):
        """D√©termine si continuer aujourd'hui"""
        # Facteurs de d√©cision
        high_quality_results = self.quality_score > 0.7
        innovative_breakthrough = evaluations.get('geometric', {}).get('score', 0) > 0.9
        system_stable = self.check_running_processes()['dashboard']
        
        # Fatigue algorithmique (trop d'analyses similaires)
        analysis_diversity = len([e for e in evaluations.values() if e.get('score', 0) > 0.5])
        algorithm_fatigue = analysis_diversity < 2
        
        continue_recommendation = {
            'decision': False,
            'confidence': 0.0,
            'reasoning': []
        }
        
        if innovative_breakthrough:
            continue_recommendation['decision'] = True
            continue_recommendation['confidence'] += 0.4
            continue_recommendation['reasoning'].append('üî∫ Innovation majeure d√©tect√©e')
        
        if high_quality_results and system_stable:
            continue_recommendation['decision'] = True
            continue_recommendation['confidence'] += 0.3
            continue_recommendation['reasoning'].append('‚úÖ Qualit√© √©lev√©e + syst√®me stable')
        
        if algorithm_fatigue:
            continue_recommendation['confidence'] -= 0.2
            continue_recommendation['reasoning'].append('‚ö†Ô∏è Diversit√© algorithmique limit√©e')
        
        # Seuil de d√©cision
        if continue_recommendation['confidence'] >= 0.5:
            continue_recommendation['decision'] = True
        
        return continue_recommendation
    
    def generate_final_report(self):
        """G√©n√®re rapport final avec recommandations"""
        evaluations = self.calculate_overall_progress()
        recommendations = self.generate_strategic_recommendations(evaluations)
        continuation = self.should_continue_today(evaluations)
        
        print(f"\nüéØ √âVALUATION GLOBALE")
        print("=" * 50)
        print(f"üìä Score qualit√© global: {self.quality_score:.2f}/1.0")
        
        print(f"\nüìà R√âSULTATS PAR ANALYSE:")
        for analysis_name, eval_data in evaluations.items():
            print(f"   {analysis_name.upper()}: {eval_data.get('status', 'N/A')}")
            print(f"      Score: {eval_data.get('score', 0):.2f} - {eval_data.get('value', 'N/A')}")
        
        print(f"\nüéØ RECOMMANDATIONS STRAT√âGIQUES:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. [{rec['priority']}] {rec['action']}")
            print(f"      {rec['description']}")
        
        print(f"\nü§î CONTINUER AUJOURD'HUI ?")
        decision = "OUI" if continuation['decision'] else "NON"
        print(f"   D√âCISION: {decision} (confiance: {continuation['confidence']:.2f})")
        print(f"   RAISONS:")
        for reason in continuation['reasoning']:
            print(f"      - {reason}")
        
        if continuation['decision']:
            print(f"\nüöÄ PROCHAINE √âTAPE RECOMMAND√âE:")
            if self.quality_score > 0.8:
                print("   üìã Documenter innovations et pr√©parer pr√©sentation")
            else:
                print("   üîß Optimiser analyses existantes ou explorer nouvelles approches")
        else:
            print(f"\nüèÅ RECOMMANDATION:")
            print("   üí§ Pause strat√©gique - Dig√©rer r√©sultats et planifier prochaine session")
        
        return {
            'quality_score': self.quality_score,
            'evaluations': evaluations,
            'recommendations': recommendations,
            'continue_today': continuation
        }

def main():
    """Point d'entr√©e √©valuation"""
    print("üéØ √âVALUATEUR PROGRESSION STRATEGIQUE")
    print("=" * 60)
    
    evaluator = ProgressionEvaluator()
    evaluator.load_analysis_results()
    
    final_assessment = evaluator.generate_final_report()
    
    # Sauvegarde √©valuation
    timestamp = int(time.time())
    output_file = f"evaluation_strategique_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_assessment, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìÑ √âvaluation sauvegard√©e: {output_file}")
    
    return final_assessment

if __name__ == "__main__":
    main()