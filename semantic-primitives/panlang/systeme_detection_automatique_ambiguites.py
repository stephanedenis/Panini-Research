#!/usr/bin/env python3
"""
SYST√àME DE D√âTECTION AUTOMATIQUE D'AMBIGU√èT√âS v2.0
===============================================

Syst√®me intelligent qui score et classe automatiquement les conflits
s√©mantiques pour prioriser les raffinements de dictionnaire.

Bas√© sur l'analyse des 154 conflits d√©tect√©s dans notre dictionnaire.
"""

import json
import numpy as np
from typing import Dict, List, Tuple, Any, Set
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import re
import math

@dataclass
class ConflictScore:
    """Score d'un conflit avec m√©triques d√©taill√©es"""
    conflict_id: str
    severity_raw: float
    semantic_coherence_score: float  # 0-1, plus bas = plus incoh√©rent
    frequency_impact_score: float   # Fr√©quence usage estim√©e 
    resolution_difficulty: float    # Difficult√© r√©solution 0-1
    priority_score: float           # Score final priorit√©
    resolution_type: str            # 'critical', 'high', 'medium', 'low'

@dataclass
class AutomaticRefinementSuggestion:
    """Suggestion automatique de raffinement"""
    concept_name: str
    current_definition: List[str]
    conflict_type: str
    suggested_refinement: Dict[str, Any]
    confidence_score: float
    linguistic_analysis: Dict[str, Any]
    contextual_dimensions: List[str]

class AutomaticAmbiguityDetector:
    """D√©tecteur automatique d'ambigu√Øt√©s avec scoring intelligent"""
    
    def __init__(self, analysis_report_path: str):
        self.report_path = analysis_report_path
        self.analysis_data = self._load_analysis_report()
        self.conflicts = self.analysis_data.get('detailed_conflicts', [])
        
        # M√©triques linguistiques pour scoring
        self.semantic_coherence_patterns = self._build_coherence_patterns()
        self.frequency_estimates = self._build_frequency_estimates()
        
        print(f"ü§ñ D√©tecteur automatique initialis√©")
        print(f"üìä {len(self.conflicts)} conflits √† analyser")
    
    def _load_analysis_report(self) -> Dict:
        """Charge le rapport d'analyse des ambigu√Øt√©s"""
        try:
            with open(self.report_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå Erreur chargement rapport: {e}")
            return {}
    
    def _build_coherence_patterns(self) -> Dict[str, float]:
        """Patterns de coh√©rence s√©mantique par type atome"""
        return {
            # Combinaisons coh√©rentes (score √©lev√©)
            ('EMOTION', 'CREATION'): 0.9,      # JOIE
            ('EMOTION', 'DESTRUCTION'): 0.8,   # TRISTESSE  
            ('COGNITION', 'COMMUNICATION'): 0.9, # EXPLIQUER
            ('MOUVEMENT', 'PERCEPTION'): 0.8,    # EXPLORER
            ('POSSESSION', 'EMOTION'): 0.7,      # D√âSIRER
            
            # Combinaisons incoh√©rentes (score bas)
            ('DESTRUCTION', 'PERCEPTION', 'EXISTENCE'): 0.2,  # AMOUR probl√©matique
            ('DESTRUCTION', 'MOUVEMENT'): 0.3,                 # MUSIQUE r√©ducteur
            ('COMMUNICATION',): 0.1,                           # √âTOILE bizarre
            ('EXISTENCE',): 0.2,                               # Trop vague
        }
    
    def _build_frequency_estimates(self) -> Dict[str, float]:
        """Estimations fr√©quence usage par concept"""
        # Concepts fr√©quents dans usage quotidien
        high_frequency = ['AMOUR', 'JOIE', 'TRISTESSE', 'PEUR', 'COMPRENDRE', 
                         'APPRENDRE', 'COMMUNICATION', 'MOUVEMENT']
        
        # Concepts moyens
        medium_frequency = ['NOSTALGIE', 'M√âLANCOLIE', 'EUPHORIE', 'ARCHITECTURE',
                           'MUSIQUE', 'ART', 'PHILOSOPHIE']
        
        # Concepts rares/techniques  
        low_frequency = ['√âTOILE', 'FEN√äTRE', 'R√âCIT', 'L√âGENDE', 'RACINE']
        
        estimates = {}
        for concept in high_frequency:
            estimates[concept] = 0.8
        for concept in medium_frequency:
            estimates[concept] = 0.5  
        for concept in low_frequency:
            estimates[concept] = 0.2
            
        return estimates
    
    def calculate_semantic_coherence(self, atoms: List[str]) -> float:
        """Calcule coh√©rence s√©mantique d'une combinaison d'atomes"""
        
        # Cas sp√©ciaux probl√©matiques identifi√©s
        atoms_tuple = tuple(sorted(atoms))
        if atoms_tuple in self.semantic_coherence_patterns:
            return self.semantic_coherence_patterns[atoms_tuple]
        
        # Heuristiques g√©n√©rales
        if len(atoms) == 1:
            return 0.3  # Concepts mono-atomiques souvent sous-sp√©cifi√©s
        
        if len(atoms) > 4:
            return 0.4  # Sur-complexit√©
        
        # Combinaisons probl√©matiques d√©tect√©es
        if 'DESTRUCTION' in atoms and 'CREATION' not in atoms:
            if any(emotion in atoms for emotion in ['EMOTION', 'PERCEPTION']):
                return 0.2  # √âmotions positives avec destruction pure
        
        if set(atoms) == {'DESTRUCTION', 'MOUVEMENT'}:
            return 0.3  # Trop r√©ducteur pour concepts riches
            
        if 'EXISTENCE' in atoms and len(atoms) == 1:
            return 0.1  # Trop vague
            
        # Score par d√©faut bas√© sur diversit√©
        unique_categories = set()
        atom_categories = {
            'EMOTION': 'affect',
            'COGNITION': 'mental', 
            'PERCEPTION': 'sensory',
            'COMMUNICATION': 'social',
            'MOUVEMENT': 'physical',
            'CREATION': 'generative',
            'DESTRUCTION': 'transformative',
            'EXISTENCE': 'ontological',
            'POSSESSION': 'relational',
            'DOMINATION': 'power'
        }
        
        for atom in atoms:
            if atom in atom_categories:
                unique_categories.add(atom_categories[atom])
        
        diversity_score = len(unique_categories) / len(atoms) if atoms else 0
        return min(0.8, 0.4 + diversity_score * 0.4)
    
    def calculate_resolution_difficulty(self, conflict: Dict) -> float:
        """Estime difficult√© de r√©solution d'un conflit"""
        
        conflict_type = conflict.get('conflict_type', '')
        concept1 = conflict.get('concept_1', '')
        concept2 = conflict.get('concept_2', '')
        
        # Conflits identiques = tr√®s difficile √† r√©soudre
        if conflict_type == 'identical_decomposition':
            return 0.9
            
        # D√©finitions incoh√©rentes = moyennement difficile  
        if conflict_type == 'incoherent_definition':
            atoms = conflict.get('decomposition_1', [])
            
            # Cas particuli√®rement probl√©matiques
            if concept1 == 'AMOUR' and 'DESTRUCTION' in atoms:
                return 0.8  # Refonte conceptuelle majeure n√©cessaire
                
            if len(atoms) == 1 and atoms[0] in ['EXISTENCE', 'COMMUNICATION']:
                return 0.6  # Ajout dimensions requises
                
            return 0.7
        
        # Synonymes partiels = plus facile
        if conflict_type == 'partial_synonym':
            return 0.4
            
        return 0.5
    
    def score_all_conflicts(self) -> List[ConflictScore]:
        """Score tous les conflits avec priorit√©s"""
        
        print("\nüéØ SCORING AUTOMATIQUE DES CONFLITS")
        print("=" * 50)
        
        scored_conflicts = []
        
        for conflict in self.conflicts:
            concept1 = conflict.get('concept_1', '')
            atoms = conflict.get('decomposition_1', [])
            severity = conflict.get('severity', 0.5)
            
            # Calculer m√©triques
            coherence = self.calculate_semantic_coherence(atoms)
            frequency = self.frequency_estimates.get(concept1, 0.3)
            difficulty = self.calculate_resolution_difficulty(conflict)
            
            # Score priorit√© combin√©
            # Formule: impact √©lev√© si incoh√©rent + fr√©quent + pas trop difficile
            priority = (
                (1.0 - coherence) * 0.4 +     # Plus incoh√©rent = plus prioritaire
                frequency * 0.3 +              # Plus fr√©quent = plus prioritaire  
                severity * 0.2 +               # Plus s√©v√®re = plus prioritaire
                (1.0 - difficulty) * 0.1       # Moins difficile = plus prioritaire
            )
            
            # Classification priorit√©
            if priority >= 0.7:
                resolution_type = 'critical'
            elif priority >= 0.5:
                resolution_type = 'high'
            elif priority >= 0.3:
                resolution_type = 'medium'
            else:
                resolution_type = 'low'
            
            score = ConflictScore(
                conflict_id=conflict.get('conflict_id', ''),
                severity_raw=severity,
                semantic_coherence_score=coherence,
                frequency_impact_score=frequency,
                resolution_difficulty=difficulty,
                priority_score=priority,
                resolution_type=resolution_type
            )
            
            scored_conflicts.append(score)
        
        # Trier par priorit√©
        scored_conflicts.sort(key=lambda x: x.priority_score, reverse=True)
        
        # Statistiques
        by_priority = Counter(s.resolution_type for s in scored_conflicts)
        print(f"üìä R√©partition priorit√©s: {dict(by_priority)}")
        
        # Top 10 conflits prioritaires
        print(f"\nüî• TOP 10 CONFLITS PRIORITAIRES:")
        for i, score in enumerate(scored_conflicts[:10]):
            concept = score.conflict_id.split('_')[-2] if '_' in score.conflict_id else 'N/A'
            print(f"   {i+1:2d}. {concept} ({score.resolution_type}, priorit√©: {score.priority_score:.2f})")
        
        return scored_conflicts
    
    def generate_automatic_refinements(self, top_conflicts: List[ConflictScore]) -> List[AutomaticRefinementSuggestion]:
        """G√©n√®re suggestions automatiques de raffinement"""
        
        print(f"\n‚öôÔ∏è G√âN√âRATION RAFFINEMENTS AUTOMATIQUES")
        print("=" * 50)
        
        suggestions = []
        
        # Dictionnaire de correspondances concepts -> conflits
        conflict_map = {}
        for conflict in self.conflicts:
            concept = conflict.get('concept_1', '')
            if concept:
                conflict_map[concept] = conflict
        
        for score in top_conflicts[:20]:  # Top 20 prioritaires
            
            concept_name = score.conflict_id.split('_')[-2] if '_' in score.conflict_id else ''
            if not concept_name or concept_name not in conflict_map:
                continue
                
            conflict_data = conflict_map[concept_name]
            atoms = conflict_data.get('decomposition_1', [])
            conflict_type = conflict_data.get('conflict_type', '')
            
            # Suggestion selon type conflit
            refinement = self._generate_refinement_for_concept(
                concept_name, atoms, conflict_type, score
            )
            
            if refinement:
                suggestions.append(refinement)
        
        print(f"‚ú® {len(suggestions)} suggestions g√©n√©r√©es")
        return suggestions
    
    def _generate_refinement_for_concept(self, concept: str, atoms: List[str], 
                                       conflict_type: str, score: ConflictScore) -> AutomaticRefinementSuggestion:
        """G√©n√®re raffinement sp√©cifique pour un concept"""
        
        # Analyses linguistiques par concept
        refinements = {
            'AMOUR': {
                'atoms': ['EMOTION', 'COMMUNICATION', 'POSSESSION', 'CREATION'],
                'contextual_dimensions': ['romantique', 'familial', 'platonique', 'universel'],
                'description': 'Sentiment d\'attachement profond incluant dimensions affective, communicative et cr√©atrice',
                'confidence': 0.9
            },
            'MUSIQUE': {
                'atoms': ['COMMUNICATION', 'CREATION', 'EMOTION', 'MOUVEMENT'],
                'contextual_dimensions': ['artistique', 'rythmique', 'harmonique', 'culturel'],
                'description': 'Art sonore combinant expression cr√©ative, communication √©motionnelle et organisation temporelle',
                'confidence': 0.8
            },
            '√âTOILE': {
                'atoms': ['EXISTENCE', 'PERCEPTION', 'MOUVEMENT'],
                'contextual_dimensions': ['astronomique', 'symbolique', 'navigationnel', 'm√©taphorique'],
                'description': 'Corps c√©leste perceptible servant de r√©f√©rence spatiale et symbolique',
                'confidence': 0.7
            },
            'D√âGO√õT': {
                'atoms': ['EMOTION', 'DESTRUCTION', 'PERCEPTION'],
                'contextual_dimensions': ['physiologique', 'moral', 'esth√©tique', 'social'],
                'description': 'R√©pulsion √©motionnelle face √† stimulus per√ßu comme n√©gatif ou contaminant',
                'confidence': 0.8
            }
        }
        
        if concept not in refinements:
            # Raffinement g√©n√©rique
            suggested_refinement = {
                'atoms': atoms + ['CONTEXTE'],  # Ajout dimension contextuelle
                'contextual_dimensions': ['g√©n√©ral', 'sp√©cialis√©'],
                'description': f'Concept {concept} n√©cessitant sp√©cification contextuelle',
                'confidence': 0.4
            }
        else:
            suggested_refinement = refinements[concept]
        
        return AutomaticRefinementSuggestion(
            concept_name=concept,
            current_definition=atoms,
            conflict_type=conflict_type,
            suggested_refinement=suggested_refinement,
            confidence_score=suggested_refinement['confidence'],
            linguistic_analysis={
                'semantic_field': self._identify_semantic_field(concept),
                'etymology_hints': self._get_etymology_hints(concept),
                'cross_cultural_variants': []
            },
            contextual_dimensions=suggested_refinement['contextual_dimensions']
        )
    
    def _identify_semantic_field(self, concept: str) -> str:
        """Identifie champ s√©mantique principal"""
        emotion_concepts = ['AMOUR', 'JOIE', 'TRISTESSE', 'PEUR', 'COL√àRE', 'D√âGO√õT']
        if concept in emotion_concepts:
            return '√©motions'
        
        art_concepts = ['MUSIQUE', 'ART', 'LITT√âRATURE', 'ARCHITECTURE']
        if concept in art_concepts:
            return 'arts'
            
        return 'g√©n√©ral'
    
    def _get_etymology_hints(self, concept: str) -> str:
        """Indices √©tymologiques pour affiner d√©finition"""
        etymologies = {
            'AMOUR': 'latin amor - attachement, d√©sir',
            'MUSIQUE': 'grec mousikƒì - art des Muses', 
            '√âTOILE': 'latin stella - point lumineux',
            'D√âGO√õT': 'd√©-go√ªt - perte du go√ªt/plaisir'
        }
        return etymologies.get(concept, '')
    
    def generate_full_detection_report(self) -> Dict[str, Any]:
        """G√©n√®re rapport complet de d√©tection automatique"""
        
        print(f"\nüéØ RAPPORT FINAL D√âTECTION AUTOMATIQUE")
        print("=" * 60)
        
        # Scoring complet
        scored_conflicts = self.score_all_conflicts()
        
        # Suggestions raffinement
        suggestions = self.generate_automatic_refinements(scored_conflicts)
        
        # Analyse globale
        total_conflicts = len(scored_conflicts)
        critical_conflicts = [s for s in scored_conflicts if s.resolution_type == 'critical']
        
        avg_coherence = np.mean([s.semantic_coherence_score for s in scored_conflicts])
        
        report = {
            'timestamp': '2025-09-27T13:45:00Z',
            'detection_method': 'automatic_scoring_v2.0',
            'analysis_summary': {
                'total_conflicts_analyzed': total_conflicts,
                'critical_conflicts': len(critical_conflicts),
                'average_semantic_coherence': float(avg_coherence),
                'refinement_suggestions_generated': len(suggestions)
            },
            'conflict_scores': [asdict(score) for score in scored_conflicts],
            'automatic_refinements': [asdict(sugg) for sugg in suggestions],
            'priority_actions': [
                'Traiter imm√©diatement conflits CRITICAL (priorit√© >= 0.7)',
                'R√©viser d√©finitions incoh√©rentes majeures (AMOUR, MUSIQUE, etc.)',
                'Ajouter dimensions contextuelles aux concepts sous-sp√©cifi√©s',
                'Tester raffinements sur corpus de validation'
            ],
            'methodology_notes': {
                'coherence_scoring': 'Bas√© sur patterns linguistiques et coh√©rence s√©mantique',
                'frequency_weighting': 'Concepts fr√©quents prioritaires pour impact utilisateur',
                'difficulty_assessment': 'Estimation complexit√© raffinement requis',
                'confidence_levels': 'Suggestions avec scores confiance pour validation'
            }
        }
        
        print(f"üìä R√âSULTATS FINAUX:")
        print(f"   ‚Ä¢ Conflits analys√©s: {total_conflicts}")
        print(f"   ‚Ä¢ Conflits critiques: {len(critical_conflicts)}")
        print(f"   ‚Ä¢ Coh√©rence moyenne: {avg_coherence:.2f}")
        print(f"   ‚Ä¢ Suggestions: {len(suggestions)}")
        
        return report
    
    def save_detection_report(self, report: Dict[str, Any], output_path: str):
        """Sauvegarde rapport de d√©tection"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"\nüíæ Rapport d√©tection sauvegard√©: {output_path}")
            print(f"üìè Taille: {len(json.dumps(report, ensure_ascii=False))} caract√®res")
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde: {e}")

def main():
    """Test syst√®me d√©tection automatique"""
    import glob
    import os
    
    # Trouver dernier rapport d'analyse
    reports = glob.glob("analyse_ambiguites_dictionnaire_*.json")
    if not reports:
        print("‚ùå Aucun rapport d'analyse trouv√©")
        return
    
    latest_report = max(reports, key=os.path.getctime)
    print(f"üìÑ Utilisation rapport: {latest_report}")
    
    # Initialiser d√©tecteur
    detector = AutomaticAmbiguityDetector(latest_report)
    
    # G√©n√©rer rapport complet
    report = detector.generate_full_detection_report()
    
    # Sauvegarder
    output_path = "rapport_detection_automatique_ambiguites.json"
    detector.save_detection_report(report, output_path)
    
    print(f"\n‚úÖ D√âTECTION AUTOMATIQUE TERMIN√âE")

if __name__ == "__main__":
    main()