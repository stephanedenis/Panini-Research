#!/usr/bin/env python3
"""
PANLANG LITE - EXTRACTEUR RAPIDE DE PRIMITIVES
==============================================

Version optimisÃ©e pour extraire les primitives essentielles
sans dÃ©compresser tous les gros fichiers en mÃªme temps.
"""

import bz2
import gzip
import json
import re
from pathlib import Path
from typing import Dict, List
import sqlite3
import time

class PanLangLiteProcessor:
    """Processeur lÃ©ger pour PanLang"""
    
    def __init__(self, dumps_dir: str = "wikipedia_dumps"):
        self.dumps_dir = Path(dumps_dir)
        self.output_dir = Path("panlang_primitives")
        self.output_dir.mkdir(exist_ok=True)
        
        self.db_path = self.output_dir / "panlang_primitives.db"
        self.init_database()
        
    def init_database(self):
        """Initialise la base de donnÃ©es SQLite"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS primitives (
            id INTEGER PRIMARY KEY,
            terme_original TEXT,
            langue_source TEXT,
            domaine TEXT,
            contexte TEXT,
            certitude_score REAL,
            extraction_date TEXT
        )
        """)
        
        conn.commit()
        conn.close()
    
    def extract_sanskrit_dhatus_compressed(self) -> List[Dict]:
        """Extrait dhÄtu directement du fichier compressÃ©"""
        print("ğŸ•‰ï¸  EXTRACTION DHÄ€TU SANSKRIT (sans dÃ©compression)")
        print("-" * 50)
        
        sanskrit_file = self.dumps_dir / "sawiki-latest-pages-articles.xml.bz2"
        dhatus = []
        
        if not sanskrit_file.exists():
            print("âŒ Fichier Sanskrit non trouvÃ©")
            return dhatus
            
        try:
            with bz2.open(sanskrit_file, 'rt', encoding='utf-8', errors='ignore') as f:
                chunk_size = 1000000  # 1MB par chunk
                chunk_count = 0
                dhatu_patterns = [
                    r'à¤§à¤¾à¤¤à¥[:\s]*([^\s\nà¥¤]+)',
                    r'dhatu[:\s]*([a-zA-Z]+)',
                    r'verb.*root[:\s]*([a-zA-Z]+)'
                ]
                
                while True:
                    chunk = f.read(chunk_size)
                    if not chunk:
                        break
                        
                    chunk_count += 1
                    
                    # Recherche dhÄtu dans le chunk
                    for pattern in dhatu_patterns:
                        matches = re.findall(pattern, chunk, re.IGNORECASE)
                        for match in matches:
                            if len(match.strip()) > 1:  # Ã‰viter les faux positifs
                                dhatu = {
                                    "terme": match.strip(),
                                    "langue": "sa",
                                    "domaine": "dhatu_racine",
                                    "contexte": f"Sanskrit chunk {chunk_count}",
                                    "certitude": 0.9
                                }
                                dhatus.append(dhatu)
                    
                    if chunk_count % 10 == 0:
                        print(f"   ğŸ“„ Chunk {chunk_count}, dhÄtu trouvÃ©s: {len(dhatus)}")
                    
                    # Limite pour Ã©viter saturation mÃ©moire
                    if chunk_count > 100 or len(dhatus) > 500:
                        break
                        
        except Exception as e:
            print(f"âš ï¸  Erreur extraction Sanskrit: {e}")
            
        print(f"âœ… DhÄtu extraits: {len(dhatus)}")
        return dhatus
    
    def extract_french_taxonomies_compressed(self) -> List[Dict]:
        """Extrait taxonomies franÃ§aises du fichier compressÃ©"""
        print("ğŸ‡«ğŸ‡· EXTRACTION TAXONOMIES FRANÃ‡AISES")
        print("-" * 40)
        
        french_file = self.dumps_dir / "frwiki-latest-pages-articles.xml.bz2"
        taxonomies = []
        
        if not french_file.exists():
            print("âŒ Fichier FranÃ§ais non trouvÃ©")
            return taxonomies
            
        try:
            with bz2.open(french_file, 'rt', encoding='utf-8', errors='ignore') as f:
                chunk_size = 2000000  # 2MB par chunk
                chunk_count = 0
                
                while True:
                    chunk = f.read(chunk_size)
                    if not chunk:
                        break
                        
                    chunk_count += 1
                    
                    # Recherche Taxobox
                    taxobox_matches = re.finditer(
                        r'\{\{Taxobox.*?rÃ¨gne\s*=\s*([^|\n}]+).*?classe\s*=\s*([^|\n}]+)', 
                        chunk, re.DOTALL | re.IGNORECASE
                    )
                    
                    for match in taxobox_matches:
                        regne = match.group(1).strip()
                        classe = match.group(2).strip()
                        
                        if regne and classe:
                            taxonomie = {
                                "terme": f"{regne}â†’{classe}",
                                "langue": "fr",
                                "domaine": "taxonomie_biologique",
                                "contexte": f"RÃ¨gne: {regne}, Classe: {classe}",
                                "certitude": 0.8
                            }
                            taxonomies.append(taxonomie)
                    
                    if chunk_count % 5 == 0:
                        print(f"   ğŸ“„ Chunk {chunk_count}, taxonomies: {len(taxonomies)}")
                    
                    # Limite
                    if chunk_count > 50 or len(taxonomies) > 200:
                        break
                        
        except Exception as e:
            print(f"âš ï¸  Erreur extraction FranÃ§ais: {e}")
            
        print(f"âœ… Taxonomies extraites: {len(taxonomies)}")
        return taxonomies
    
    def extract_english_concepts_compressed(self) -> List[Dict]:
        """Extrait concepts anglais essentiels"""
        print("ğŸ‡ºğŸ‡¸ EXTRACTION CONCEPTS ANGLAIS")
        print("-" * 35)
        
        english_file = self.dumps_dir / "enwiki-latest-pages-articles.xml.bz2"
        concepts = []
        
        if not english_file.exists():
            print("âŒ Fichier Anglais non trouvÃ©")
            return concepts
            
        try:
            with bz2.open(english_file, 'rt', encoding='utf-8', errors='ignore') as f:
                chunk_size = 3000000  # 3MB par chunk
                chunk_count = 0
                
                patterns = [
                    (r'etymology.*?from\s+([A-Za-z]+)', "etymologie"),
                    (r'chemical\s+formula.*?([A-Z][a-z]*[0-9]*)', "chimie"),
                    (r'kingdom\s*=\s*([^|\n}]+)', "biologie")
                ]
                
                while True:
                    chunk = f.read(chunk_size)
                    if not chunk:
                        break
                        
                    chunk_count += 1
                    
                    for pattern, domaine in patterns:
                        matches = re.findall(pattern, chunk, re.IGNORECASE)
                        for match in matches[:10]:  # Limite par chunk
                            concept = {
                                "terme": match.strip(),
                                "langue": "en", 
                                "domaine": domaine,
                                "contexte": f"English {domaine} chunk {chunk_count}",
                                "certitude": 0.7
                            }
                            concepts.append(concept)
                    
                    if chunk_count % 10 == 0:
                        print(f"   ğŸ“„ Chunk {chunk_count}, concepts: {len(concepts)}")
                    
                    # Limite pour Ã©viter surcharge
                    if chunk_count > 30 or len(concepts) > 300:
                        break
                        
        except Exception as e:
            print(f"âš ï¸  Erreur extraction Anglais: {e}")
            
        print(f"âœ… Concepts extraits: {len(concepts)}")
        return concepts
    
    def save_all_primitives(self, primitives_lists: List[List[Dict]]):
        """Sauvegarde toutes les primitives"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        total_saved = 0
        for primitives in primitives_lists:
            for primitive in primitives:
                cursor.execute("""
                INSERT INTO primitives (terme_original, langue_source, domaine, contexte, certitude_score, extraction_date)
                VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    primitive["terme"],
                    primitive["langue"],
                    primitive["domaine"], 
                    primitive["contexte"],
                    primitive["certitude"],
                    time.strftime("%Y-%m-%d %H:%M:%S")
                ))
                total_saved += 1
        
        conn.commit()
        conn.close()
        
        print(f"ğŸ’¾ SauvegardÃ©: {total_saved} primitives totales")
        return total_saved
    
    def generate_panlang_lite_report(self) -> Dict:
        """GÃ©nÃ¨re le rapport PanLang Lite"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Statistiques
        cursor.execute("SELECT COUNT(*) FROM primitives")
        total = cursor.fetchone()[0]
        
        cursor.execute("SELECT domaine, COUNT(*) FROM primitives GROUP BY domaine")
        domaines = dict(cursor.fetchall())
        
        cursor.execute("SELECT langue_source, COUNT(*) FROM primitives GROUP BY langue_source")
        langues = dict(cursor.fetchall())
        
        conn.close()
        
        rapport = {
            "titre": "PanLang Lite - Primitives Essentielles",
            "description": "Extraction rapide des primitives fondamentales",
            "total_primitives": total,
            "domaines": domaines,
            "langues": langues,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "base_donnees": str(self.db_path)
        }
        
        # Sauvegarde
        with open(self.output_dir / "panlang_lite_report.json", "w", encoding="utf-8") as f:
            json.dump(rapport, f, indent=2, ensure_ascii=False)
            
        return rapport

def main():
    """CrÃ©ation PanLang Lite - Version optimisÃ©e"""
    print("ğŸš€ PANLANG LITE - EXTRACTION RAPIDE DE PRIMITIVES")
    print("=" * 55)
    print("Approche: Extraction directe sur fichiers compressÃ©s")
    print("Objectif: Primitives essentielles sans dÃ©compression massive")
    print()
    
    processor = PanLangLiteProcessor()
    
    # Extraction par langue (sans dÃ©compresser tout)
    primitives_all = []
    
    # 1. Sanskrit - PrioritÃ© absolue (racines dhÄtu)
    dhatus = processor.extract_sanskrit_dhatus_compressed()
    primitives_all.append(dhatus)
    
    # 2. FranÃ§ais - Classifications taxonomiques
    taxonomies_fr = processor.extract_french_taxonomies_compressed()
    primitives_all.append(taxonomies_fr)
    
    # 3. Anglais - Concepts scientifiques
    concepts_en = processor.extract_english_concepts_compressed()
    primitives_all.append(concepts_en)
    
    # Sauvegarde
    total_primitives = processor.save_all_primitives(primitives_all)
    
    # Rapport final
    rapport = processor.generate_panlang_lite_report()
    
    print("\nğŸ“Š RAPPORT PANLANG LITE")
    print("=" * 25)
    print(f"ğŸŒŸ Total primitives: {rapport['total_primitives']}")
    print(f"ğŸŒ Langues: {list(rapport['langues'].keys())}")
    print(f"ğŸ”¬ Domaines: {list(rapport['domaines'].keys())}")
    print()
    
    for domaine, count in rapport["domaines"].items():
        print(f"   ğŸ“‹ {domaine}: {count} primitives")
    
    for langue, count in rapport["langues"].items():
        print(f"   ğŸŒ {langue}: {count} termes")
    
    print(f"\nğŸ’¾ Base de donnÃ©es: {rapport['base_donnees']}")
    print(f"ğŸ“„ Rapport: {processor.output_dir}/panlang_lite_report.json")
    print("\nğŸ¯ PanLang Lite - Fondations Ã©tablies pour la langue Ã©rudite!")
    print("   â†’ Racines sanskrites dhÄtu intÃ©grÃ©es")
    print("   â†’ Taxonomies biologiques franÃ§aises") 
    print("   â†’ Concepts scientifiques anglais")
    print("   â†’ Base solide pour dÃ©veloppement PanLang complet")

if __name__ == "__main__":
    main()