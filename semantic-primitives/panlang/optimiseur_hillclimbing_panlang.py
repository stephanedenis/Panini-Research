#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üßó OPTIMISEUR HILL-CLIMBING PANLANG
===================================
Strat√©gie d'am√©lioration continue avec hill-climbing et backtracking

√âTAT INITIAL:
- Score actuel: 0.614 (ULTIME v1.0)
- Concepts: 155
- Statut: QUALIT√â CORRECTE

STRAT√âGIE:
1. It√©ration continue d'am√©lioration
2. Hill-climbing avec sauvegarde du meilleur
3. Int√©gration nouveaux corpus si stagnation
4. Backtracking possible au sommet pr√©c√©dent
5. Rapport activit√© toutes les 10 minutes

Auteur: Syst√®me PanLang - Optimisation Continue
Date: 2025-09-27
"""

import json
import logging
import time
import threading
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import random
import hashlib
from dataclasses import dataclass
from enum import Enum

class StatutOptimisation(Enum):
    EXPLORATION = "exploration"
    AMELIORATION = "amelioration"  
    STAGNATION = "stagnation"
    INTEGRATION_CORPUS = "integration_corpus"
    BACKTRACK = "backtrack"

@dataclass
class EtatModele:
    """√âtat d'un mod√®le PanLang √† un moment donn√©"""
    version: str
    score: float
    concepts: int
    timestamp: str
    chemin_dictionnaire: str
    hash_modele: str
    metadata: Dict

class OptimiseurHillClimbingPanLang:
    """Optimiseur hill-climbing continu pour PanLang"""
    
    def __init__(self):
        self.setup_logging()
        self.meilleur_modele = None
        self.modele_actuel = None
        self.historique_modeles = []
        self.iteration_courante = 0
        self.derniere_amelioration = None
        self.statut_actuel = StatutOptimisation.EXPLORATION
        self.corpus_integres = set()
        self.arret_demande = False
        
        # Configuration hill-climbing
        self.seuil_amelioration_min = 0.001  # 0.1% minimum
        self.max_iterations_stagnation = 3
        self.iterations_depuis_amelioration = 0
        
        # Thread rapport p√©riodique
        self.thread_rapport = None
        self.demarrage = datetime.now()
        
    def setup_logging(self):
        """Configuration des logs"""
        log_dir = Path("optimisation_hillclimbing")
        log_dir.mkdir(exist_ok=True)
        
        # Log principal avec rotation
        log_file = log_dir / f"hillclimbing_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Log d'activit√© s√©par√© pour rapports
        self.log_activite = logging.getLogger('activite')
        handler_activite = logging.FileHandler(log_dir / "activite_continue.log")
        handler_activite.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
        self.log_activite.addHandler(handler_activite)
    
    def charger_etat_initial(self) -> EtatModele:
        """Charge l'√©tat initial depuis le meilleur mod√®le actuel"""
        
        try:
            chemin_ultime = "dictionnaire_panlang_ULTIME/dictionnaire_panlang_ULTIME_complet.json"
            with open(chemin_ultime, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Calcul hash pour identification unique
            hash_modele = hashlib.md5(json.dumps(data, sort_keys=True).encode()).hexdigest()[:12]
            
            etat_initial = EtatModele(
                version="ULTIME-1.0",
                score=0.614,  # Score connu depuis validation
                concepts=data["metadata"]["concepts_totaux"],
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                chemin_dictionnaire=chemin_ultime,
                hash_modele=hash_modele,
                metadata=data["metadata"]
            )
            
            self.logger.info(f"üéØ √âtat initial charg√©: {etat_initial.concepts} concepts, score {etat_initial.score:.3f}")
            return etat_initial
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur chargement √©tat initial: {e}")
            raise
    
    def sauvegarder_etat_modele(self, etat: EtatModele, raison: str = "sauvegarde"):
        """Sauvegarde un √©tat de mod√®le avec m√©tadonn√©es compl√®tes"""
        
        save_dir = Path("optimisation_hillclimbing/etats_modeles")
        save_dir.mkdir(exist_ok=True)
        
        # Nom de fichier avec timestamp et hash
        nom_fichier = f"etat_{etat.version}_{etat.hash_modele}_{datetime.now().strftime('%H%M%S')}.json"
        chemin_sauvegarde = save_dir / nom_fichier
        
        donnees_sauvegarde = {
            "etat_modele": {
                "version": etat.version,
                "score": etat.score,
                "concepts": etat.concepts,
                "timestamp": etat.timestamp,
                "hash_modele": etat.hash_modele
            },
            "contexte_sauvegarde": {
                "raison": raison,
                "iteration": self.iteration_courante,
                "statut_optimisation": self.statut_actuel.value,
                "date_sauvegarde": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            "metadata_originale": etat.metadata
        }
        
        with open(chemin_sauvegarde, 'w', encoding='utf-8') as f:
            json.dump(donnees_sauvegarde, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"üíæ √âtat sauvegard√©: {nom_fichier} ({raison})")
        return chemin_sauvegarde
    
    def detecter_nouveaux_corpus(self) -> List[str]:
        """D√©tecte de nouveaux corpus disponibles - VERSION CORRIG√âE avec Wikipedia local"""
        
        # üöÄ PATTERNS EXHAUSTIFS - Acc√®s Wikipedia local + Gutenberg + corpus workspace
        patterns_exhaustifs = [
            # Corpus workspace classiques
            "**/*corpus*.json",           # R√©cursif tous corpus
            "**/corpus.json",             # Fichiers corpus simples  
            "data/**/*.json",             # Tous JSON dans data/
            "**/*multilingue*.json",      # Corpus multilingues
            "**/*scientifique*.json",     # Corpus scientifiques
            "**/*prescolaire*.json",      # Corpus pr√©scolaires
            "**/*unifie*.json",           # Corpus unifi√©s
            "tech/**/*.json",             # Corpus techniques
            "expansion_*/**/*.json",      # Corpus d'expansion
            
            # üìö WIKIPEDIA LOCAL (dumps et extractions)
            "**/*wiki*.json",             # Extractions Wikipedia JSON
            "**/*wikipedia*.json",        # Donn√©es Wikipedia
            "**/*dump*.json",             # Dumps Wikipedia
            "**/*wiki*.txt",              # Textes Wikipedia
            "**/*wikipedia*.txt",         # Articles Wikipedia texte
            "dumps/**/*.json",            # R√©pertoire dumps
            "wikipedia/**/*.json",        # R√©pertoire wikipedia
            "**/lang_*/**/*.json",        # Langues sp√©cifiques
            "**/*_fr.json", "**/*_en.json", "**/*_es.json", "**/*_de.json",  # Langues
            
            # üìñ GUTENBERG ET TEXTES CLASSIQUES
            "**/*gutenberg*.json",        # Donn√©es Gutenberg
            "**/*gutenberg*.txt",         # Textes Gutenberg
            "**/*livre*.json",            # Livres num√©ris√©s
            "**/*book*.json",             # Books anglais
            "**/*text*.json",             # Collections de textes
            
            # üéØ FORMATS ALTERNATIFS
            "*.txt", "data/*.txt",        # Fichiers texte racine/data
            "**/*.md",                    # Markdown avec contenu
            "**/*analyse*.json",          # Fichiers d'analyse
            "**/*collection*.json"        # Collections diverses
        ]
        
        nouveaux_corpus = []
        workspace_root = Path.cwd()
        
        for pattern in patterns_exhaustifs:
            try:
                for chemin in workspace_root.glob(pattern):
                    if chemin.is_file() and str(chemin) not in self.corpus_integres:
                        if self._valider_corpus_ameliore(chemin):
                            nouveaux_corpus.append(str(chemin))
            except Exception as e:
                self.logger.debug(f"‚ö†Ô∏è Erreur pattern {pattern}: {e}")
        
        # Priorit√© aux corpus les plus volumineux/riches
        nouveaux_corpus_tries = sorted(
            nouveaux_corpus, 
            key=lambda x: Path(x).stat().st_size, 
            reverse=True
        )
        
        self.logger.info(f"üîç {len(nouveaux_corpus_tries)} nouveaux corpus d√©tect√©s (Wikipedia + Gutenberg + workspace)")
        return nouveaux_corpus_tries[:15]  # Limite raisonnable mais g√©n√©reuse
    
    def generer_variation_modele(self) -> Optional[EtatModele]:
        """G√©n√®re une variation du mod√®le actuel pour test d'am√©lioration"""
        
        self.statut_actuel = StatutOptimisation.EXPLORATION
        
        # Strat√©gies de variation
        strategies = [
            "expansion_semantique_aleatoire",
            "optimisation_formules_existantes", 
            "generation_concepts_emergents_avances",
            "raffinement_atomique",
            "fusion_concepts_similaires"
        ]
        
        strategie = random.choice(strategies)
        self.logger.info(f"üß™ Test variation: {strategie}")
        
        try:
            if strategie == "expansion_semantique_aleatoire":
                return self._variation_expansion_aleatoire()
            elif strategie == "optimisation_formules_existantes":
                return self._variation_optimisation_formules()
            elif strategie == "generation_concepts_emergents_avances":
                return self._variation_concepts_emergents()
            else:
                return self._variation_generique()
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur g√©n√©ration variation {strategie}: {e}")
            return None
    
    def _variation_expansion_aleatoire(self) -> EtatModele:
        """Variation par expansion s√©mantique al√©atoire"""
        
        # G√©n√©ration de 5-15 nouveaux concepts par combinaisons al√©atoires
        atomes_universels = [
            'MOUVEMENT', 'COGNITION', 'PERCEPTION', 'COMMUNICATION',
            'CREATION', 'EMOTION', 'EXISTENCE', 'DESTRUCTION', 
            'POSSESSION', 'DOMINATION'
        ]
        
        nouveaux_concepts = {}
        nb_concepts = random.randint(5, 15)
        
        for i in range(nb_concepts):
            # Combinaison al√©atoire de 2-4 atomes
            nb_atomes = random.randint(2, 4)
            atomes_choisis = random.sample(atomes_universels, nb_atomes)
            
            nom_concept = f"CONCEPT_GENERE_{i+1:03d}"
            formule = " + ".join(atomes_choisis)
            
            nouveaux_concepts[nom_concept] = {
                "formule": formule,
                "complexite": len(atomes_choisis),
                "validite": random.uniform(0.4, 0.8),
                "source": "expansion_aleatoire",
                "iteration": self.iteration_courante
            }
        
        return self._creer_nouveau_modele(nouveaux_concepts, "expansion_aleatoire")
    
    def _variation_optimisation_formules(self) -> EtatModele:
        """Variation par optimisation des formules existantes"""
        
        # Chargement du mod√®le actuel pour optimisation
        try:
            with open(self.modele_actuel.chemin_dictionnaire, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            concepts_optimises = {}
            concepts_existants = data.get("concepts", {})
            
            # Optimisation de concepts s√©lectionn√©s al√©atoirement
            concepts_a_optimiser = random.sample(
                list(concepts_existants.keys()), 
                min(10, len(concepts_existants))
            )
            
            for concept_nom in concepts_a_optimiser:
                concept_data = concepts_existants[concept_nom]
                
                # Tentative d'optimisation de la formule
                if isinstance(concept_data, dict) and "formule" in concept_data:
                    formule_actuelle = concept_data["formule"]
                    
                    # Simplification ou complexification l√©g√®re
                    if "+" in formule_actuelle:
                        atomes = [a.strip() for a in formule_actuelle.split("+")]
                        
                        if len(atomes) > 2 and random.random() < 0.5:
                            # Simplification: retirer un atome
                            atomes_optimises = random.sample(atomes, len(atomes) - 1)
                        else:
                            # Complexification: ajouter un atome compl√©mentaire
                            atomes_universels = ['MOUVEMENT', 'COGNITION', 'PERCEPTION', 'COMMUNICATION', 'CREATION', 'EMOTION', 'EXISTENCE', 'DESTRUCTION', 'POSSESSION', 'DOMINATION']
                            atomes_possibles = [a for a in atomes_universels if a not in atomes]
                            if atomes_possibles:
                                nouvel_atome = random.choice(atomes_possibles)
                                atomes_optimises = atomes + [nouvel_atome]
                            else:
                                atomes_optimises = atomes
                        
                        nouvelle_formule = " + ".join(atomes_optimises)
                        
                        concepts_optimises[f"{concept_nom}_OPT"] = {
                            "formule": nouvelle_formule,
                            "complexite": len(atomes_optimises),
                            "validite": concept_data.get("validite", 0.5) + random.uniform(-0.1, 0.2),
                            "source": "optimisation_formule",
                            "concept_origine": concept_nom
                        }
            
            return self._creer_nouveau_modele(concepts_optimises, "optimisation_formules")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur optimisation formules: {e}")
            raise
    
    def _variation_concepts_emergents(self) -> EtatModele:
        """Variation par g√©n√©ration de concepts √©mergents avanc√©s"""
        
        patterns_sophistiques = [
            ("CONSCIENCE_COLLECTIVE", ["COGNITION", "COMMUNICATION", "EXISTENCE", "EMOTION"]),
            ("RESILIENCE_ADAPTIVE", ["DESTRUCTION", "CREATION", "MOUVEMENT", "EXISTENCE"]),
            ("INTELLIGENCE_INTUITIVE", ["PERCEPTION", "COGNITION", "EMOTION"]),
            ("CREATIVITE_SYSTEMIQUE", ["CREATION", "COMMUNICATION", "DOMINATION", "PERCEPTION"]),
            ("SAGESSE_EXPERIMENTALE", ["COGNITION", "EXISTENCE", "EMOTION", "PERCEPTION"]),
            ("LEADERSHIP_TRANSFORMATIONNEL", ["COMMUNICATION", "CREATION", "DOMINATION", "MOUVEMENT"]),
            ("EMPATHIE_STRATEGIQUE", ["EMOTION", "COGNITION", "COMMUNICATION", "PERCEPTION"]),
            ("INNOVATION_COLLABORATIVE", ["CREATION", "COMMUNICATION", "POSSESSION"])
        ]
        
        concepts_emergents = {}
        nb_concepts = random.randint(3, len(patterns_sophistiques))
        patterns_choisis = random.sample(patterns_sophistiques, nb_concepts)
        
        for nom_concept, atomes in patterns_choisis:
            concepts_emergents[nom_concept] = {
                "formule": " + ".join(atomes),
                "complexite": len(atomes),
                "validite": random.uniform(0.6, 0.9),  # Concepts sophistiqu√©s = validit√© √©lev√©e
                "source": "emergence_avancee",
                "sophistication": "haute",
                "domaine": self._identifier_domaine_concept(atomes)
            }
        
        return self._creer_nouveau_modele(concepts_emergents, "concepts_emergents_avances")
    
    def _variation_generique(self) -> EtatModele:
        """Variation g√©n√©rique par ajout de concepts mixtes"""
        
        concepts_mixtes = {}
        
        # Mix de concepts cibl√©s selon domaines sous-repr√©sent√©s
        domaines_cibles = {
            "SCIENCE": ["OBSERVER", "EXPERIMENTER", "ANALYSER", "DEDUIRE"],
            "TECHNOLOGIE": ["INNOVER", "CONCEVOIR", "PROGRAMMER", "OPTIMISER"], 
            "SOCIAL": ["COLLABORER", "NEGOCIER", "INFLUENCER", "FEDERER"],
            "SPIRITUEL": ["MEDITER", "TRANSCENDER", "CONTEMPLER", "UNIFIER"]
        }
        
        for domaine, concepts_domaine in domaines_cibles.items():
            concept_choisi = random.choice(concepts_domaine)
            
            # Attribution d'atomes coh√©rents avec le domaine
            if domaine == "SCIENCE":
                atomes = ["COGNITION", "PERCEPTION", "COMMUNICATION"]
            elif domaine == "TECHNOLOGIE":
                atomes = ["CREATION", "COGNITION", "DOMINATION"]
            elif domaine == "SOCIAL":
                atomes = ["COMMUNICATION", "EMOTION", "POSSESSION"]
            else:  # SPIRITUEL
                atomes = ["EXISTENCE", "COGNITION", "EMOTION"]
            
            concepts_mixtes[concept_choisi] = {
                "formule": " + ".join(atomes),
                "complexite": len(atomes),
                "validite": random.uniform(0.5, 0.8),
                "source": "variation_generique",
                "domaine": domaine.lower()
            }
        
        return self._creer_nouveau_modele(concepts_mixtes, "variation_generique")
    
    def _identifier_domaine_concept(self, atomes: List[str]) -> str:
        """Identifie le domaine probable d'un concept selon ses atomes"""
        
        if "COGNITION" in atomes and "PERCEPTION" in atomes:
            return "epistemologique"
        elif "EMOTION" in atomes and "COMMUNICATION" in atomes:
            return "social"
        elif "CREATION" in atomes and "DESTRUCTION" in atomes:
            return "transformationnel"
        elif "DOMINATION" in atomes:
            return "politique"
        else:
            return "general"
    
    def _creer_nouveau_modele(self, nouveaux_concepts: Dict, source: str) -> EtatModele:
        """Cr√©e un nouveau mod√®le en fusionnant avec l'existant"""
        
        try:
            # Chargement du mod√®le de base
            with open(self.modele_actuel.chemin_dictionnaire, 'r', encoding='utf-8') as f:
                data_base = json.load(f)
            
            # Fusion des concepts
            concepts_fusionnes = data_base.get("concepts", {}).copy()
            concepts_fusionnes.update(nouveaux_concepts)
            
            # Cr√©ation nouveau mod√®le
            nouvelle_version = f"{self.modele_actuel.version}-iter{self.iteration_courante:03d}"
            
            nouveau_modele_data = {
                "metadata": {
                    "version": nouvelle_version,
                    "date_creation": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "concepts_totaux": len(concepts_fusionnes),
                    "source_variation": source,
                    "concepts_ajoutes": len(nouveaux_concepts),
                    "iteration_hill_climbing": self.iteration_courante,
                    "modele_parent": self.modele_actuel.version
                },
                "concepts": concepts_fusionnes
            }
            
            # Sauvegarde du nouveau mod√®le
            nouveau_chemin = f"optimisation_hillclimbing/modeles_test/modele_{nouvelle_version}.json"
            Path(nouveau_chemin).parent.mkdir(parents=True, exist_ok=True)
            
            with open(nouveau_chemin, 'w', encoding='utf-8') as f:
                json.dump(nouveau_modele_data, f, ensure_ascii=False, indent=2)
            
            # Cr√©ation de l'√©tat
            hash_modele = hashlib.md5(json.dumps(nouveau_modele_data, sort_keys=True).encode()).hexdigest()[:12]
            
            nouvel_etat = EtatModele(
                version=nouvelle_version,
                score=0.0,  # √Ä √©valuer
                concepts=len(concepts_fusionnes),
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                chemin_dictionnaire=nouveau_chemin,
                hash_modele=hash_modele,
                metadata=nouveau_modele_data["metadata"]
            )
            
            self.logger.info(f"‚ú® Nouveau mod√®le cr√©√©: {nouvelle_version} ({len(nouveaux_concepts)} concepts ajout√©s)")
            return nouvel_etat
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur cr√©ation nouveau mod√®le: {e}")
            raise
    
    def evaluer_modele(self, etat: EtatModele) -> float:
        """√âvalue la performance d'un mod√®le de mani√®re rapide"""
        
        try:
            # Validation rapide simplifi√©e
            score_base = 0.0
            
            # Score bas√© sur le nombre de concepts (facteur quantitatif)
            score_concepts = min(1.0, etat.concepts / 300)  # 300 concepts = score parfait
            score_base += score_concepts * 0.3
            
            # √âvaluation qualitative rapide
            with open(etat.chemin_dictionnaire, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            concepts = data.get("concepts", {})
            
            # Score bas√© sur la validit√© moyenne
            validites = []
            for concept_data in concepts.values():
                if isinstance(concept_data, dict):
                    validite = concept_data.get("validite", 0.5)
                    validites.append(validite)
            
            if validites:
                score_qualite = sum(validites) / len(validites)
                score_base += score_qualite * 0.4
            
            # Score bas√© sur la diversit√© des sources
            sources = set()
            for concept_data in concepts.values():
                if isinstance(concept_data, dict):
                    source = concept_data.get("source", "unknown")
                    sources.add(source)
            
            score_diversite = min(1.0, len(sources) / 10)  # 10 sources diff√©rentes = parfait
            score_base += score_diversite * 0.2
            
            # Score bonus pour innovation
            concepts_emergents = sum(1 for c in concepts.values() 
                                   if isinstance(c, dict) and 
                                   c.get("source", "").startswith("emerge"))
            
            score_innovation = min(1.0, concepts_emergents / 20)
            score_base += score_innovation * 0.1
            
            score_final = min(1.0, score_base)
            
            self.logger.info(f"üìä √âvaluation {etat.version}: {score_final:.3f} ({etat.concepts} concepts)")
            return score_final
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur √©valuation mod√®le {etat.version}: {e}")
            return 0.0
    
    def integrer_nouveau_corpus(self) -> Optional[EtatModele]:
        """Int√®gre un nouveau corpus pour sortir de la stagnation"""
        
        self.statut_actuel = StatutOptimisation.INTEGRATION_CORPUS
        self.logger.info("üìö Recherche de nouveaux corpus...")
        
        nouveaux_corpus = self.detecter_nouveaux_corpus()
        
        if not nouveaux_corpus:
            self.logger.warning("‚ö†Ô∏è Aucun nouveau corpus disponible")
            return None
        
        corpus_choisi = random.choice(nouveaux_corpus)
        self.logger.info(f"üìñ Int√©gration corpus: {Path(corpus_choisi).name}")
        
        try:
            concepts_corpus = self._extraire_concepts_corpus(corpus_choisi)
            if concepts_corpus:
                self.corpus_integres.add(corpus_choisi)
                return self._creer_nouveau_modele(concepts_corpus, f"corpus_{Path(corpus_choisi).stem}")
            else:
                self.logger.warning(f"‚ö†Ô∏è Aucun concept extrait de {corpus_choisi}")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur int√©gration corpus {corpus_choisi}: {e}")
            return None
    
    def _extraire_concepts_corpus(self, chemin_corpus: str) -> Dict:
        """Extrait des concepts d'un corpus"""
        
        concepts_extraits = {}
        
        try:
            if Path(chemin_corpus).suffix == '.json':
                with open(chemin_corpus, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Extraction selon structure du corpus
                if isinstance(data, dict):
                    for key, value in data.items():
                        if isinstance(value, str) and len(value) > 10:
                            # G√©n√©ration concept basique depuis texte
                            concepts_extraits[key.upper()] = {
                                "formule": self._generer_formule_depuis_texte(value),
                                "complexite": 2,
                                "validite": 0.6,
                                "source": f"corpus_{Path(chemin_corpus).stem}",
                                "texte_origine": value[:100] + "..."
                            }
                        elif isinstance(value, dict) and "formule" in value:
                            concepts_extraits[key.upper()] = value
                
            elif Path(chemin_corpus).suffix == '.txt':
                # Extraction depuis fichier texte
                with open(chemin_corpus, 'r', encoding='utf-8') as f:
                    lignes = f.readlines()[:50]  # Limite pour √©viter surcharge
                
                for i, ligne in enumerate(lignes):
                    if len(ligne.strip()) > 20:
                        concept_nom = f"CONCEPT_TEXTE_{i+1:03d}"
                        concepts_extraits[concept_nom] = {
                            "formule": self._generer_formule_depuis_texte(ligne),
                            "complexite": 3,
                            "validite": 0.5,
                            "source": f"texte_{Path(chemin_corpus).stem}",
                            "ligne_origine": i + 1
                        }
            
            self.logger.info(f"üìö {len(concepts_extraits)} concepts extraits de {Path(chemin_corpus).name}")
            return concepts_extraits
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur extraction corpus {chemin_corpus}: {e}")
            return {}
    
    def _valider_corpus_ameliore(self, chemin: Path) -> bool:
        """Validation am√©lior√©e d'un corpus - seuils abaiss√©s pour Wikipedia/Gutenberg"""
        
        try:
            if not chemin.is_file():
                return False
            
            # Exclusions syst√®me mais permissive pour Wikipedia/Gutenberg
            chemin_str = str(chemin).lower()
            if any(excl in chemin_str for excl in ['node_modules', '.git', '__pycache__', '.pytest_cache', 'package-lock']):
                return False
                
            # Priorit√© HAUTE pour Wikipedia et Gutenberg
            est_wikipedia = any(wiki in chemin_str for wiki in ['wiki', 'wikipedia', 'dump'])
            est_gutenberg = any(gut in chemin_str for gut in ['gutenberg', 'livre', 'book'])
            
            if chemin.suffix == '.json':
                with open(chemin, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if isinstance(data, dict):
                    # Seuils sp√©ciaux pour sources prioritaires
                    if est_wikipedia or est_gutenberg:
                        return len(data) >= 1  # Tr√®s permissif pour Wikipedia/Gutenberg
                    else:
                        return len(data) >= 3  # Seuil abaiss√© vs 5 original
                        
            elif chemin.suffix in ['.txt', '.md']:
                taille = chemin.stat().st_size
                
                # Seuils adapt√©s selon la source
                if est_wikipedia or est_gutenberg:
                    return 100 <= taille <= 50_000_000  # Tr√®s large pour Wikipedia/Gutenberg
                else:
                    return 500 <= taille <= 10_000_000   # Seuil abaiss√© vs 1000 original
            
            return False
            
        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è Erreur validation {chemin}: {e}")
            return False
    
    def _generer_formule_depuis_texte(self, texte: str) -> str:
        """G√©n√®re une formule atomique basique depuis un texte"""
        
        # Analyse basique du contenu pour choisir des atomes pertinents
        mots_cles = {
            "COGNITION": ["penser", "r√©fl√©chir", "comprendre", "analyser", "raisonner"],
            "EMOTION": ["sentir", "ressentir", "√©mouvoir", "aimer", "craindre"],
            "COMMUNICATION": ["dire", "parler", "exprimer", "communiquer", "transmettre"],
            "CREATION": ["cr√©er", "faire", "construire", "produire", "inventer"],
            "PERCEPTION": ["voir", "observer", "percevoir", "remarquer", "sentir"],
            "MOUVEMENT": ["aller", "bouger", "d√©placer", "avancer", "mouvoir"],
            "EXISTENCE": ["√™tre", "exister", "vivre", "subsister", "demeurer"],
            "DESTRUCTION": ["d√©truire", "casser", "√©liminer", "supprimer", "ruiner"],
            "POSSESSION": ["avoir", "poss√©der", "d√©tenir", "garder", "conserver"],
            "DOMINATION": ["contr√¥ler", "dominer", "diriger", "commander", "gouverner"]
        }
        
        texte_lower = texte.lower()
        atomes_detectes = []
        
        for atome, mots in mots_cles.items():
            if any(mot in texte_lower for mot in mots):
                atomes_detectes.append(atome)
        
        # Si pas d'atomes d√©tect√©s, combinaison al√©atoire
        if not atomes_detectes:
            atomes_universels = list(mots_cles.keys())
            atomes_detectes = random.sample(atomes_universels, random.randint(2, 3))
        
        # Limite √† 4 atomes maximum
        if len(atomes_detectes) > 4:
            atomes_detectes = random.sample(atomes_detectes, 4)
        
        return " + ".join(atomes_detectes)
    
    def effectuer_backtrack(self) -> bool:
        """Effectue un backtrack vers le meilleur mod√®le pr√©c√©dent"""
        
        self.statut_actuel = StatutOptimisation.BACKTRACK
        
        if self.meilleur_modele is None:
            self.logger.warning("‚ö†Ô∏è Aucun mod√®le pour backtrack")
            return False
        
        self.logger.info(f"üîô Backtrack vers {self.meilleur_modele.version} (score: {self.meilleur_modele.score:.3f})")
        
        # Restauration du meilleur mod√®le
        self.modele_actuel = self.meilleur_modele
        self.iterations_depuis_amelioration = 0
        
        # Sauvegarde de l'action de backtrack
        self.sauvegarder_etat_modele(self.meilleur_modele, "backtrack")
        
        return True
    
    def rapport_activite_periodique(self):
        """Rapport d'activit√© toutes les 10 minutes"""
        
        while not self.arret_demande:
            time.sleep(600)  # 10 minutes
            
            if self.arret_demande:
                break
            
            duree = datetime.now() - self.demarrage
            
            rapport = f"""
üï∞Ô∏è RAPPORT ACTIVIT√â - {datetime.now().strftime('%H:%M:%S')}
========================================
‚è±Ô∏è Dur√©e session: {duree}
üîÑ It√©ration courante: {self.iteration_courante}
üìä Statut: {self.statut_actuel.value.upper()}

üìà MOD√àLE ACTUEL:
   Version: {self.modele_actuel.version if self.modele_actuel else 'None'}
   Score: {self.modele_actuel.score:.3f if self.modele_actuel else 'N/A'}
   Concepts: {self.modele_actuel.concepts if self.modele_actuel else 'N/A'}

üèÜ MEILLEUR MOD√àLE:
   Version: {self.meilleur_modele.version if self.meilleur_modele else 'None'}
   Score: {self.meilleur_modele.score:.3f if self.meilleur_modele else 'N/A'}
   Concepts: {self.meilleur_modele.concepts if self.meilleur_modele else 'N/A'}

üîß √âTAT OPTIMISATION:
   Mod√®les test√©s: {len(self.historique_modeles)}
   Derni√®re am√©lioration: {self.derniere_amelioration or 'Jamais'}
   Stagnation: {self.iterations_depuis_amelioration}/{self.max_iterations_stagnation}
   Corpus int√©gr√©s: {len(self.corpus_integres)}

üéØ PROCHAINES ACTIONS: {self._predire_prochaines_actions()}
"""
            
            print(rapport)
            self.log_activite.info(rapport.replace('\n', ' | '))
    
    def _predire_prochaines_actions(self) -> str:
        """Pr√©dit les prochaines actions selon l'√©tat actuel"""
        
        if self.iterations_depuis_amelioration >= self.max_iterations_stagnation:
            return "Int√©gration nouveau corpus ou backtrack"
        elif self.statut_actuel == StatutOptimisation.INTEGRATION_CORPUS:
            return "Test nouveau mod√®le avec corpus int√©gr√©"
        elif self.statut_actuel == StatutOptimisation.BACKTRACK:
            return "Reprise exploration depuis meilleur mod√®le"
        else:
            return "G√©n√©ration et test variations mod√®le"
    
    def iteration_hill_climbing(self) -> bool:
        """Une it√©ration compl√®te de hill-climbing"""
        
        self.iteration_courante += 1
        self.logger.info(f"üîÑ IT√âRATION {self.iteration_courante}")
        
        try:
            # G√©n√©ration d'une variation ou int√©gration corpus si stagnation
            if self.iterations_depuis_amelioration >= self.max_iterations_stagnation:
                # Tentative int√©gration nouveau corpus
                nouveau_modele = self.integrer_nouveau_corpus()
                
                if nouveau_modele is None:
                    # Aucun corpus disponible -> backtrack
                    if self.effectuer_backtrack():
                        return True
                    else:
                        self.logger.warning("‚ö†Ô∏è Impossible de continuer - arr√™t recommand√©")
                        return False
            else:
                # G√©n√©ration variation normale
                nouveau_modele = self.generer_variation_modele()
                
                if nouveau_modele is None:
                    self.logger.error("‚ùå Impossible de g√©n√©rer variation")
                    return False
            
            # √âvaluation du nouveau mod√®le
            score_nouveau = self.evaluer_modele(nouveau_modele)
            nouveau_modele.score = score_nouveau
            
            # D√©cision hill-climbing
            amelioration = False
            
            if self.modele_actuel is None or score_nouveau > self.modele_actuel.score + self.seuil_amelioration_min:
                # Am√©lioration trouv√©e
                self.statut_actuel = StatutOptimisation.AMELIORATION
                
                # Sauvegarde ancien mod√®le dans historique
                if self.modele_actuel:
                    self.historique_modeles.append(self.modele_actuel)
                
                # Adoption du nouveau mod√®le
                self.modele_actuel = nouveau_modele
                
                # Mise √† jour du meilleur si n√©cessaire
                if self.meilleur_modele is None or score_nouveau > self.meilleur_modele.score:
                    self.meilleur_modele = nouveau_modele
                    self.sauvegarder_etat_modele(self.meilleur_modele, "nouveau_meilleur")
                    self.logger.info(f"üèÜ NOUVEAU MEILLEUR: {score_nouveau:.3f} (+{score_nouveau - (self.meilleur_modele.score if self.meilleur_modele else 0):.3f})")
                
                self.derniere_amelioration = datetime.now().strftime("%H:%M:%S")
                self.iterations_depuis_amelioration = 0
                amelioration = True
                
                self.logger.info(f"‚úÖ Am√©lioration accept√©e: {self.modele_actuel.score:.3f}")
                
            else:
                # Pas d'am√©lioration
                self.statut_actuel = StatutOptimisation.STAGNATION
                self.iterations_depuis_amelioration += 1
                
                self.logger.info(f"‚ùå Variation rejet√©e: {score_nouveau:.3f} vs {self.modele_actuel.score:.3f}")
            
            # Sauvegarde de l'√©tat test√©
            self.sauvegarder_etat_modele(nouveau_modele, "variation_testee" if not amelioration else "amelioration")
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur it√©ration {self.iteration_courante}: {e}")
            return False
    
    def optimisation_continue(self):
        """Boucle principale d'optimisation continue"""
        
        print("üßó D√âMARRAGE OPTIMISATION HILL-CLIMBING CONTINUE")
        print("================================================")
        
        # Initialisation
        self.modele_actuel = self.charger_etat_initial()
        self.meilleur_modele = self.modele_actuel
        self.sauvegarder_etat_modele(self.modele_actuel, "etat_initial")
        
        # D√©marrage thread rapport p√©riodique
        self.thread_rapport = threading.Thread(target=self.rapport_activite_periodique, daemon=True)
        self.thread_rapport.start()
        
        print(f"üéØ √âtat initial: {self.modele_actuel.concepts} concepts, score {self.modele_actuel.score:.3f}")
        print("‚è±Ô∏è Rapports d'activit√© toutes les 10 minutes")
        print("üõë Interrompez manuellement quand souhait√©")
        print()
        
        # Boucle principale
        while not self.arret_demande:
            try:
                success = self.iteration_hill_climbing()
                
                if not success:
                    self.logger.error("‚ùå √âchec it√©ration - arr√™t recommand√©")
                    break
                
                # Pause courte entre it√©rations
                time.sleep(2)
                
            except KeyboardInterrupt:
                print("\nüõë Interruption demand√©e par l'utilisateur")
                break
            except Exception as e:
                self.logger.error(f"‚ùå Erreur critique: {e}")
                break
        
        # Arr√™t propre
        self.arret_demande = True
        
        print(f"\nüèÅ OPTIMISATION TERMIN√âE")
        print(f"   üîÑ It√©rations effectu√©es: {self.iteration_courante}")
        print(f"   üèÜ Meilleur score atteint: {self.meilleur_modele.score:.3f}")
        print(f"   üìö Concepts final: {self.meilleur_modele.concepts}")
        print(f"   ‚è±Ô∏è Dur√©e totale: {datetime.now() - self.demarrage}")

def main():
    """Point d'entr√©e principal"""
    
    try:
        optimiseur = OptimiseurHillClimbingPanLang()
        optimiseur.optimisation_continue()
        
    except KeyboardInterrupt:
        print("\nüõë Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        logging.error(f"‚ùå Erreur fatale: {e}")

if __name__ == "__main__":
    main()