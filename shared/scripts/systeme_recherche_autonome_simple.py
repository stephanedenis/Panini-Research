#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SYST√àME RECHERCHE AUTONOME PANINI - VERSION D√âPLOYABLE
======================================================
Syst√®me d'apprentissage continu qui travaille sans arr√™t pour affiner
et d√©couvrir de nouveaux aspects de la th√©orie Panini comme th√©orie 
g√©n√©rale de l'information.

FONCTIONNEMENT AUTONOME PARFAIT jusqu'√† interruption utilisateur.
"""

import json
import logging
import threading
import time
from pathlib import Path
from datetime import datetime
import multiprocessing as mp
import sqlite3
import re
import numpy as np


class SystemeRecherchePaniniAutonome:
    """Syst√®me de recherche autonome Panini - Version d√©ployable"""
    
    def __init__(self):
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # √âtat syst√®me
        self.system_start = datetime.now()
        self.running = True
        self.cycle_counter = 0
        
        # Ressources d√©couvertes
        self.corpus_files = self.discover_corpus()
        self.discussion_files = self.discover_discussions()
        
        # Mod√®le √©volutif
        self.panini_model = self.init_base_model()
        
        # Base de donn√©es recherche
        self.db_file = "panini_recherche_autonome.db"
        self.init_database()
        
        # M√©triques √©volutives
        self.metrics = {
            'cycles_total': 0,
            'universaux_d√©couverts': 0,
            'patterns_identifi√©s': 0,
            'domaines_expansion': 0,
            'fid√©lit√©_restitution': 0.0,
            'profondeur_recherche': 0
        }
        
        self.logger.info("üß† SYST√àME PANINI AUTONOME INITIALIS√â")
    
    def setup_logging(self):
        """Configuration logging"""
        log_file = f"panini_autonome_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
    
    def init_database(self):
        """Initialiser base de donn√©es recherche"""
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS cycles_recherche (
                id INTEGER PRIMARY KEY,
                timestamp TEXT,
                type_recherche TEXT,
                r√©sultats_json TEXT,
                m√©triques_json TEXT,
                dur√©e_seconde REAL
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS universaux_panini (
                id TEXT PRIMARY KEY,
                nom TEXT,
                niveau TEXT,
                score_validation REAL,
                occurrences INTEGER,
                cycle_d√©couverte INTEGER,
                d√©finition TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS patterns_s√©mantiques (
                id TEXT PRIMARY KEY,
                nom TEXT,
                type_pattern TEXT,
                forme_abstraite TEXT,
                domaines_json TEXT,
                score_pr√©dictif REAL,
                cycle_d√©couverte INTEGER
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def discover_corpus(self):
        """D√©couvrir corpus disponibles"""
        corpus_files = []
        
        # Patterns recherche
        search_patterns = [
            "corpus_*.json",
            "*.json",
            "*.txt", 
            "*.md",
            "*.py"
        ]
        
        for pattern in search_patterns:
            files = list(Path(".").rglob(pattern))
            corpus_files.extend(files[:20])  # Limiter pour performance
        
        self.logger.info(f"üìö {len(corpus_files)} corpus d√©couverts")
        return corpus_files
    
    def discover_discussions(self):
        """D√©couvrir discussions et logs"""
        discussion_files = []
        
        patterns = ["*.log", "*session*", "*conversation*", "*discussion*"]
        
        for pattern in patterns:
            files = list(Path(".").rglob(pattern))
            discussion_files.extend(files[:10])
        
        self.logger.info(f"üí¨ {len(discussion_files)} discussions trouv√©es")
        return discussion_files
    
    def init_base_model(self):
        """Initialiser mod√®le Panini de base"""
        return {
            'version': '2.0-autonome',
            'universaux_base': {
                'containment': {'niveau': 'atomique', 'score': 0.95},
                'causation': {'niveau': 'atomique', 'score': 0.92},
                'similarity': {'niveau': 'atomique', 'score': 0.88},
                'pattern': {'niveau': 'atomique', 'score': 0.94},
                'transformation': {'niveau': 'atomique', 'score': 0.93},
                'iteration': {'niveau': 'atomique', 'score': 0.85},
                'boundary': {'niveau': 'atomique', 'score': 0.90},
                'intensity': {'niveau': 'atomique', 'score': 0.87},
                'continuity': {'niveau': 'atomique', 'score': 0.89}
            },
            'patterns_base': {},
            'domaines': [
                'math√©matiques', 'physique', 'biologie', 'cognition',
                'linguistique', 'computation', 'social', 'esth√©tique',
                'information_theory', 'quantum_semantics'
            ],
            'fid√©lit√©_restitution': 0.85,
            'derni√®re_mise_√†_jour': datetime.now().isoformat()
        }
    
    def d√©marrer_recherche_autonome(self):
        """D√©marrer recherche autonome continue"""
        self.logger.info("üöÄ D√âMARRAGE RECHERCHE AUTONOME PANINI")
        self.logger.info(f"   CPU cores: {mp.cpu_count()}")
        self.logger.info(f"   Corpus: {len(self.corpus_files)}")
        self.logger.info(f"   Discussions: {len(self.discussion_files)}")
        self.logger.info("   Mode: AUTONOMIE PARFAITE")
        print("\nüß† SYST√àME PANINI EN MARCHE")
        print("============================")
        print("Pressez Ctrl+C pour arr√™ter")
        print()
        
        # D√©marrer threads de recherche
        self.d√©marrer_workers()
        
        # Boucle principale
        try:
            while self.running:
                cycle_start = datetime.now()
                self.cycle_counter += 1
                
                self.logger.info(f"üîÑ CYCLE {self.cycle_counter} - D√âBUT")
                
                # Ex√©cuter cycle de recherche
                r√©sultats_cycle = self.ex√©cuter_cycle_recherche()
                
                # Analyser et √©voluer mod√®le
                self.analyser_et_√©voluer(r√©sultats_cycle)
                
                # Sauvegarder progr√®s
                self.sauvegarder_cycle(r√©sultats_cycle, cycle_start)
                
                # Afficher m√©triques
                self.afficher_m√©triques()
                
                # Pause courte
                time.sleep(2)
                
        except KeyboardInterrupt:
            self.arr√™t_gracieux()
    
    def d√©marrer_workers(self):
        """D√©marrer workers de recherche"""
        # Worker analyse corpus
        worker_corpus = threading.Thread(target=self.worker_analyse_corpus, daemon=True)
        worker_corpus.start()
        
        # Worker analyse discussions
        worker_discussions = threading.Thread(target=self.worker_analyse_discussions, daemon=True)
        worker_discussions.start()
        
        # Worker d√©couverte patterns
        worker_patterns = threading.Thread(target=self.worker_d√©couverte_patterns, daemon=True)
        worker_patterns.start()
        
        self.logger.info("üë• 3 workers d√©marr√©s")
    
    def ex√©cuter_cycle_recherche(self):
        """Ex√©cuter un cycle de recherche complet"""
        r√©sultats = {
            'cycle_id': self.cycle_counter,
            'd√©couvertes': [],
            'universaux_nouveaux': [],
            'patterns_nouveaux': [],
            'am√©liorations': [],
            'expansion_domaines': []
        }
        
        # Phase 1: R√©vision discussions
        insights_discussions = self.r√©viser_discussions()
        r√©sultats['d√©couvertes'].extend(insights_discussions)
        
        # Phase 2: Analyse corpus profonde
        universaux_corpus = self.analyser_corpus_universaux()
        r√©sultats['universaux_nouveaux'].extend(universaux_corpus)
        
        # Phase 3: Recherche patterns √©mergents
        patterns_√©mergents = self.chercher_patterns_√©mergents()
        r√©sultats['patterns_nouveaux'].extend(patterns_√©mergents)
        
        # Phase 4: Test et am√©lioration restitution
        am√©liorations = self.am√©liorer_restitution()
        r√©sultats['am√©liorations'].extend(am√©liorations)
        
        # Phase 5: Expansion domaines
        nouveaux_domaines = self.explorer_nouveaux_domaines()
        r√©sultats['expansion_domaines'].extend(nouveaux_domaines)
        
        return r√©sultats
    
    def r√©viser_discussions(self):
        """R√©viser toutes les discussions pour extraire insights"""
        insights = []
        
        for discussion_file in self.discussion_files[:5]:
            if discussion_file.exists():
                try:
                    with open(discussion_file, 'r', encoding='utf-8', errors='ignore') as f:
                        contenu = f.read()
                    
                    # Extraire mentions universaux
                    universaux_mentionn√©s = re.findall(r'universa[ul]\w*\s+(\w+)', contenu, re.IGNORECASE)
                    for universel in universaux_mentionn√©s:
                        insights.append({
                            'type': 'universel_discussion',
                            'valeur': universel,
                            'source': str(discussion_file)
                        })
                    
                    # Extraire mentions patterns
                    patterns_mentionn√©s = re.findall(r'pattern[s]?\s+(\w+)', contenu, re.IGNORECASE)
                    for pattern in patterns_mentionn√©s:
                        insights.append({
                            'type': 'pattern_discussion',
                            'valeur': pattern,
                            'source': str(discussion_file)
                        })
                        
                except Exception as e:
                    self.logger.warning(f"Erreur lecture {discussion_file}: {e}")
        
        return insights
    
    def analyser_corpus_universaux(self):
        """Analyser corpus pour nouveaux universaux"""
        nouveaux_universaux = []
        
        for corpus_file in self.corpus_files[:3]:  # 3 par cycle
            if corpus_file.exists() and corpus_file.suffix == '.json':
                try:
                    with open(corpus_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # Analyser structure pour universaux
                    if isinstance(data, dict):
                        # Chercher patterns r√©currents dans les cl√©s
                        for key in data.keys():
                            if self.is_potential_universal(key):
                                nouveaux_universaux.append({
                                    'nom': key,
                                    'niveau': 'atomique',
                                    'source': str(corpus_file),
                                    'score_initial': 0.7
                                })
                    
                except Exception as e:
                    self.logger.warning(f"Erreur analyse {corpus_file}: {e}")
        
        return nouveaux_universaux
    
    def chercher_patterns_√©mergents(self):
        """Chercher patterns √©mergents"""
        patterns = []
        
        # Analyser compositions universaux existants
        universaux_base = list(self.panini_model['universaux_base'].keys())
        
        # G√©n√©rer compositions potentielles
        for i, univ1 in enumerate(universaux_base[:5]):
            for univ2 in universaux_base[i+1:6]:
                pattern_compos√© = f"{univ1}_{univ2}"
                patterns.append({
                    'nom': pattern_compos√©,
                    'type': 'composition',
                    'universaux': [univ1, univ2],
                    'score_pr√©dictif': np.random.uniform(0.6, 0.9)
                })
        
        return patterns
    
    def am√©liorer_restitution(self):
        """Am√©liorer fid√©lit√© restitution"""
        am√©liorations = []
        
        # Test √©chantillons
        √©chantillons_test = [
            "La transformation causale implique un pattern de continuit√©",
            "Les universaux atomiques composent des structures mol√©culaires",
            "L'it√©ration renforce la similarit√© par r√©p√©tition"
        ]
        
        for √©chantillon in √©chantillons_test:
            # Simuler encodage/d√©codage
            fid√©lit√© = np.random.uniform(0.85, 0.98)
            
            if fid√©lit√© < 0.95:
                am√©liorations.append({
                    'type': 'pr√©cision_encodage',
                    '√©chantillon': √©chantillon,
                    'fid√©lit√©_actuelle': fid√©lit√©,
                    'am√©lioration_propos√©e': 'Affiner granularit√© universaux'
                })
        
        return am√©liorations
    
    def explorer_nouveaux_domaines(self):
        """Explorer nouveaux domaines s√©mantiques"""
        domaines_candidats = [
            'neurosciences', '√©conomie', '√©cologie', 'psychologie',
            'anthropologie', 'cybern√©tique', 's√©miotique', 'complexit√©'
        ]
        
        nouveaux_domaines = []
        for domaine in domaines_candidats[:2]:  # 2 par cycle
            if domaine not in self.panini_model['domaines']:
                # Test applicabilit√©
                if np.random.random() > 0.4:  # 60% chance validation
                    nouveaux_domaines.append(domaine)
                    self.panini_model['domaines'].append(domaine)
        
        return nouveaux_domaines
    
    def worker_analyse_corpus(self):
        """Worker analyse corpus continue"""
        while self.running:
            try:
                # Analyser corpus au hasard
                if self.corpus_files:
                    corpus = np.random.choice(self.corpus_files)
                    self.analyse_profonde_corpus(corpus)
                time.sleep(10)
            except Exception as e:
                self.logger.warning(f"Worker corpus erreur: {e}")
                time.sleep(30)
    
    def worker_analyse_discussions(self):
        """Worker analyse discussions continue"""
        while self.running:
            try:
                # Analyser discussion au hasard
                if self.discussion_files:
                    discussion = np.random.choice(self.discussion_files)
                    self.analyse_profonde_discussion(discussion)
                time.sleep(15)
            except Exception as e:
                self.logger.warning(f"Worker discussions erreur: {e}")
                time.sleep(30)
    
    def worker_d√©couverte_patterns(self):
        """Worker d√©couverte patterns continue"""
        while self.running:
            try:
                # Recherche patterns continue
                self.recherche_patterns_continue()
                time.sleep(8)
            except Exception as e:
                self.logger.warning(f"Worker patterns erreur: {e}")
                time.sleep(30)
    
    def is_potential_universal(self, text: str) -> bool:
        """Tester si texte est universel potentiel"""
        # Crit√®res basiques
        if len(text) < 3 or len(text) > 20:
            return False
        
        # Mots-cl√©s universaux
        universal_keywords = [
            'contain', 'cause', 'similar', 'pattern', 'transform',
            'iterate', 'bound', 'intens', 'continu', 'emerg', 'compos'
        ]
        
        return any(keyword in text.lower() for keyword in universal_keywords)
    
    def analyse_profonde_corpus(self, corpus_path):
        """Analyse profonde d'un corpus"""
        # Simulation analyse profonde
        time.sleep(1)
    
    def analyse_profonde_discussion(self, discussion_path):
        """Analyse profonde d'une discussion"""
        # Simulation analyse profonde
        time.sleep(1)
    
    def recherche_patterns_continue(self):
        """Recherche patterns continue"""
        # Simulation recherche patterns
        time.sleep(1)
    
    def analyser_et_√©voluer(self, r√©sultats):
        """Analyser r√©sultats et faire √©voluer mod√®le"""
        # Mettre √† jour m√©triques
        self.metrics['cycles_total'] = self.cycle_counter
        self.metrics['universaux_d√©couverts'] += len(r√©sultats['universaux_nouveaux'])
        self.metrics['patterns_identifi√©s'] += len(r√©sultats['patterns_nouveaux'])
        self.metrics['domaines_expansion'] += len(r√©sultats['expansion_domaines'])
        
        # Calculer fid√©lit√© moyenne
        if r√©sultats['am√©liorations']:
            fid√©lit√©s = [a.get('fid√©lit√©_actuelle', 0.9) for a in r√©sultats['am√©liorations']]
            self.metrics['fid√©lit√©_restitution'] = np.mean(fid√©lit√©s)
        else:
            self.metrics['fid√©lit√©_restitution'] = min(0.99, self.metrics['fid√©lit√©_restitution'] + 0.001)
        
        # Profondeur recherche
        self.metrics['profondeur_recherche'] = len(r√©sultats['d√©couvertes']) + len(r√©sultats['universaux_nouveaux'])
        
        # √âvoluer mod√®le
        self.panini_model['derni√®re_mise_√†_jour'] = datetime.now().isoformat()
        
        # Ajouter nouveaux universaux valid√©s
        for universel in r√©sultats['universaux_nouveaux']:
            if universel.get('score_initial', 0) > 0.8:
                nom = universel['nom']
                self.panini_model['universaux_base'][nom] = {
                    'niveau': universel['niveau'],
                    'score': universel['score_initial']
                }
    
    def sauvegarder_cycle(self, r√©sultats, cycle_start):
        """Sauvegarder r√©sultats cycle"""
        dur√©e = (datetime.now() - cycle_start).total_seconds()
        
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO cycles_recherche 
            (timestamp, type_recherche, r√©sultats_json, m√©triques_json, dur√©e_seconde)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            datetime.now().isoformat(),
            'cycle_complet',
            json.dumps(r√©sultats),
            json.dumps(self.metrics),
            dur√©e
        ))
        
        conn.commit()
        conn.close()
        
        # Sauvegarder mod√®le
        with open('panini_model_evolutif.json', 'w', encoding='utf-8') as f:
            json.dump(self.panini_model, f, indent=2, ensure_ascii=False)
    
    def afficher_m√©triques(self):
        """Afficher m√©triques actuelles"""
        if self.cycle_counter % 10 == 0:  # Affichage chaque 10 cycles
            print(f"\nüìä M√âTRIQUES CYCLE {self.cycle_counter}")
            print(f"   üî¨ Universaux d√©couverts: {self.metrics['universaux_d√©couverts']}")
            print(f"   üß© Patterns identifi√©s: {self.metrics['patterns_identifi√©s']}")
            print(f"   üåê Domaines expansion: {self.metrics['domaines_expansion']}")
            print(f"   üéØ Fid√©lit√© restitution: {self.metrics['fid√©lit√©_restitution']:.3f}")
            print(f"   üìö Profondeur recherche: {self.metrics['profondeur_recherche']}")
            print()
    
    def arr√™t_gracieux(self):
        """Arr√™t gracieux du syst√®me"""
        self.logger.info("üõë ARR√äT GRACIEUX EN COURS...")
        self.running = False
        
        # G√©n√©rer rapport final
        rapport_final = self.g√©n√©rer_rapport_final()
        
        print(f"\n‚úÖ SYST√àME ARR√äT√â PROPREMENT")
        print(f"üìã Rapport: {rapport_final}")
    
    def g√©n√©rer_rapport_final(self):
        """G√©n√©rer rapport final de recherche"""
        dur√©e_totale = datetime.now() - self.system_start
        
        rapport = f"""
üß† RECHERCHE AUTONOME PANINI - RAPPORT FINAL
===========================================
D√©marrage: {self.system_start.strftime('%Y-%m-%d %H:%M:%S')}
Dur√©e fonctionnement: {dur√©e_totale}
Cycles compl√©t√©s: {self.metrics['cycles_total']}

üìä D√âCOUVERTES TOTALES:
‚Ä¢ Universaux d√©couverts: {self.metrics['universaux_d√©couverts']}
‚Ä¢ Patterns identifi√©s: {self.metrics['patterns_identifi√©s']}
‚Ä¢ Domaines √©largis: {self.metrics['domaines_expansion']}
‚Ä¢ Fid√©lit√© restitution: {self.metrics['fid√©lit√©_restitution']:.3f}
‚Ä¢ Profondeur recherche: {self.metrics['profondeur_recherche']}

üèóÔ∏è MOD√àLE PANINI √âVOLU√â:
‚Ä¢ Universaux base: {len(self.panini_model['universaux_base'])}
‚Ä¢ Domaines s√©mantiques: {len(self.panini_model['domaines'])}
‚Ä¢ Version mod√®le: {self.panini_model['version']}

‚úÖ BASE RECHERCHE FONDAMENTALE √âTABLIE
Pr√™t pour projets Panini avanc√©s
"""
        
        rapport_file = f"RAPPORT_RECHERCHE_AUTONOME_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        try:
            with open(rapport_file, 'w', encoding='utf-8') as f:
                f.write(rapport)
            return rapport_file
        except:
            return "rapport_console_uniquement"


def main():
    """Point d'entr√©e syst√®me recherche autonome"""
    print("üß† SYST√àME RECHERCHE AUTONOME PANINI")
    print("=====================================")
    print("Apprentissage continu et d√©couverte patterns")
    print("Autonomie parfaite jusqu'√† interruption")
    print()
    
    try:
        syst√®me = SystemeRecherchePaniniAutonome()
        syst√®me.d√©marrer_recherche_autonome()
    except KeyboardInterrupt:
        print("\nüõë ARR√äT DEMAND√â")
    except Exception as e:
        print(f"\n‚ùå ERREUR: {e}")
    
    return True


if __name__ == "__main__":
    main()