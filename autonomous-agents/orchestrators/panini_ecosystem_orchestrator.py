#!/usr/bin/env python3
"""
Panini Ecosystem Orchestrator - Configuration Compl√®te

Orchestration multi-agent pour TOUT l'√©cosyst√®me Panini :
- 15 GitHub Projects actifs
- 4 repositories (Panini, PaniniFS-Research, OntoWave, dhatu-*)
- 4 agents (Humain, Copilot, Colab Pro, Autonomous)
- Assignation optimale cross-project

Auteur: St√©phane Denis + Autonomous System
Timestamp: 2025-10-01T14:40:00Z
"""

import os
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any
from multi_agent_orchestrator import (
    MultiAgentOrchestrator,
    AgentProfile,
    AgentType,
    Task,
    TaskType
)


class PaniniEcosystemOrchestrator(MultiAgentOrchestrator):
    """Orchestrateur sp√©cialis√© pour √©cosyst√®me Panini."""
    
    def __init__(self, workspace_root: str):
        """Initialise avec projets Panini."""
        super().__init__(workspace_root)
        
        # Projets GitHub identifi√©s (10 ACTIFS + 5 ARCHIVED)
        self.github_projects = {
            # ACTIFS (10 projets prioritaires)
            15: "Panini - Th√©orie Information Universelle",
            14: "OntoWave Roadmap",
            13: "PaniniFS Research Strategy 2025",
            12: "[RESEARCH] dhatu-multimodal-learning",
            11: "[RESEARCH] dhatu-linguistics-engine",
            9: "[INTERFACES] dhatu-dashboard",
            5: "[TOOLS] dhatu-pattern-analyzer",
            4: "[CORE] dhatu-gpu-accelerator",
            2: "[CORE] dhatu-corpus-manager",
            1: "[CORE] dhatu-universal-compressor",
            # ARCHIVED (5 projets - backlog pr√©serv√©)
            # 10: "[INTERFACES] dhatu-api-gateway" - ARCHIVED (backlog_10_*)
            # 8: "[TOOLS] dhatu-evolution-simulator" - ARCHIVED (backlog_08_*)
            # 7: "[TOOLS] dhatu-space-visualizer" - ARCHIVED (backlog_07_*)
            # 6: "[TOOLS] dhatu-creative-generator" - ARCHIVED (backlog_06_*)
            # 3: "[CORE] dhatu-web-framework" - ARCHIVED (backlog_03_*)
        }
        
        # Repositories
        self.repositories = {
            "Panini": "https://github.com/stephanedenis/Panini",
            "PaniniFS-Research": "https://github.com/stephanedenis/PaniniFS-Research",
            "OntoWave": "https://github.com/stephanedenis/OntoWave",
            "dhatu-multimodal": "https://github.com/stephanedenis/dhatu-multimodal-learning"
        }
        
        # Mapping projets ‚Üí repos (10 actifs seulement)
        self.project_to_repo = {
            15: "PaniniFS-Research",
            14: "OntoWave",
            13: "PaniniFS-Research",
            12: "dhatu-multimodal",
            11: "Panini",
            9: "Panini",
            5: "Panini",
            4: "Panini",
            2: "Panini",
            1: "Panini"
        }
        
        # Cat√©gories projets (10 actifs)
        self.project_categories = {
            "CORE": [1, 2, 4],          # Infrastructure fondamentale
            "TOOLS": [5],                # Outils d√©veloppement
            "INTERFACES": [9],           # APIs et dashboards
            "RESEARCH": [11, 12, 13, 15],  # Recherche fondamentale
            "ROADMAP": [14]              # Strat√©gie
        }
        
        # Initialisation t√¢ches par projet
        self._initialize_panini_tasks()
    
    def _initialize_panini_tasks(self):
        """Cr√©e t√¢ches initiales pour chaque projet actif."""
        
        # PROJECT #15 - Th√©orie Information Universelle (ACTIF)
        self.add_task(Task(
            "panini_15_pr_improvements",
            "Am√©liorer compliance PRs #15-18 (sym√©tries + patterns)",
            TaskType.REFACTORING,
            priority=9,
            requires_human_review=True
        ))
        
        self.add_task(Task(
            "panini_15_iso8601_fixes",
            "Corriger 14 violations ISO 8601 dans docs legacy",
            TaskType.REFACTORING,
            priority=7
        ))
        
        # PIPELINE CORPUS: T√¢che m√®re consolid√©e
        self.add_task(Task(
            "panini_corpus_pipeline_master",
            "Pipeline Corpus Complet: Expansion ‚Üí Validation ‚Üí Multimodal",
            TaskType.DATA_ANALYSIS,
            priority=9,
            estimated_duration=14400,  # Total pipeline
            dependencies=[]
        ))
        
        # Subtask 1: Expansion (commence imm√©diatement)
        self.add_task(Task(
            "panini_15_corpus_expansion",
            "√âtendre corpus multi-format √† 100+ contenus",
            TaskType.DATA_ANALYSIS,
            priority=8,
            estimated_duration=7200,
            dependencies=["panini_corpus_pipeline_master"]
        ))
        
        # PROJECT #4 - GPU Accelerator (CORE)
        self.add_task(Task(
            "panini_4_gpu_dhatu_training",
            "Entra√Æner mod√®les dhƒÅtu sur GPU T4/V100",
            TaskType.ML_TRAINING,
            priority=9,
            requires_gpu=True,
            estimated_duration=3600
        ))
        
        self.add_task(Task(
            "panini_4_embeddings_multilingue",
            "G√©n√©rer embeddings multilingues 10+ langues",
            TaskType.GPU_COMPUTE,
            priority=8,
            requires_gpu=True,
            estimated_duration=1800
        ))
        
        # PROJECT #2 - Corpus Manager (CORE)
        # Subtask 2: Validation (apr√®s expansion)
        self.add_task(Task(
            "panini_2_corpus_validation",
            "Valider int√©grit√© corpus 100k+ documents",
            TaskType.VALIDATION,
            priority=7,
            estimated_duration=300,
            dependencies=["panini_15_corpus_expansion"]
        ))
        
        self.add_task(Task(
            "panini_2_metadata_extraction",
            "Extraire m√©tadonn√©es traducteurs 100+ profils",
            TaskType.EXTRACTION,
            priority=8,
            estimated_duration=600
        ))
        
        # PROJECT #9 - Dashboard (INTERFACE)
        self.add_task(Task(
            "panini_9_dashboard_deploy",
            "D√©ployer dashboard GitHub Pages multi-projets",
            TaskType.DOCUMENTATION,
            priority=8,
            requires_human_review=True
        ))
        
        self.add_task(Task(
            "panini_9_realtime_metrics",
            "Impl√©menter m√©triques temps r√©el WebSocket",
            TaskType.REFACTORING,
            priority=6,
            estimated_duration=3600
        ))
        
        # PROJECT #11 - Linguistics Engine (RESEARCH)
        self.add_task(Task(
            "panini_11_symmetry_validation",
            "Valider sym√©tries compose/decompose 50+ dhƒÅtu",
            TaskType.VALIDATION,
            priority=9,
            estimated_duration=1800
        ))
        
        self.add_task(Task(
            "panini_11_compression_empirical",
            "Tester compression empirique cross-lingue",
            TaskType.DATA_ANALYSIS,
            priority=8,
            requires_gpu=True,
            estimated_duration=3600
        ))
        
        # PROJECT #12 - Multimodal Learning (RESEARCH)
        # Subtask 3: Multimodal (apr√®s validation)
        self.add_task(Task(
            "panini_12_multimodal_corpus",
            "Cr√©er corpus audio/vid√©o/texte align√©",
            TaskType.DATA_ANALYSIS,
            priority=7,
            estimated_duration=7200,
            dependencies=["panini_2_corpus_validation"]
        ))
        
        # PROJECT #5 - Pattern Analyzer (TOOL)
        self.add_task(Task(
            "panini_5_bias_detection",
            "D√©tecter patterns biais culturels/temporels",
            TaskType.DATA_ANALYSIS,
            priority=7,
            estimated_duration=900
        ))
        
        # PROJECT #14 - OntoWave Roadmap (ROADMAP)
        self.add_task(Task(
            "panini_14_roadmap_update",
            "Mettre √† jour roadmap Q1 2025 avec r√©sultats",
            TaskType.DOCUMENTATION,
            priority=6,
            requires_human_review=True
        ))
        
        # PROJECT #1 - Universal Compressor (CORE CRITIQUE)
        # Gap strat√©gique combl√©: 4 t√¢ches high-priority
        self.add_task(Task(
            "panini_1_compressor_architecture",
            "Architecture compresseur universel linguistique v1.0",
            TaskType.ARCHITECTURE,
            priority=9,
            requires_human_review=True,
            estimated_duration=7200
        ))
        
        self.add_task(Task(
            "panini_1_algorithm_validation",
            "Valider algorithme compression/d√©compression 100+ dhƒÅtu",
            TaskType.VALIDATION,
            priority=8,
            estimated_duration=900
        ))
        
        self.add_task(Task(
            "panini_1_compression_benchmarks",
            "Benchmarks compression rates vs gzip/bzip2/lz4",
            TaskType.DATA_ANALYSIS,
            priority=8,
            estimated_duration=1800
        ))
        
        self.add_task(Task(
            "panini_1_api_documentation",
            "Documentation API compresseur + exemples utilisation",
            TaskType.DOCUMENTATION,
            priority=7,
            estimated_duration=3600
        ))
        
        # PROJECT #13 - PaniniFS Research Strategy (RESEARCH)
        # Gap strat√©gique combl√©: 3 t√¢ches strat√©giques
        self.add_task(Task(
            "panini_13_strategy_q4_update",
            "Update strat√©gie recherche Q4 2025 + roadmap Q1 2026",
            TaskType.RESEARCH,
            priority=8,
            requires_human_review=True,
            estimated_duration=7200
        ))
        
        self.add_task(Task(
            "panini_13_mission_analysis",
            "Analyser r√©sultats 7 missions compl√©t√©es - m√©triques",
            TaskType.DATA_ANALYSIS,
            priority=7,
            estimated_duration=1800
        ))
        
        self.add_task(Task(
            "panini_13_next_missions",
            "Identifier prochaines 5 missions prioritaires Q4-Q1",
            TaskType.RESEARCH,
            priority=8,
            requires_human_review=True,
            estimated_duration=3600
        ))
    
    def assign_all_pending_tasks(self) -> Dict[str, Any]:
        """Assigne toutes les t√¢ches pending automatiquement."""
        results = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'assigned': [],
            'failed': [],
            'summary': {}
        }
        
        pending_tasks = [
            task for task in self.tasks.values()
            if task.status == 'pending'
        ]
        
        print(f"\nüéØ Assignation automatique de {len(pending_tasks)} t√¢ches")
        print("=" * 70)
        
        for task in pending_tasks:
            agent_id = self.assign_optimal_agent(task.task_id)
            if agent_id:
                results['assigned'].append({
                    'task_id': task.task_id,
                    'task_title': task.title,
                    'agent_id': agent_id,
                    'agent_name': self.agents[agent_id].name
                })
            else:
                results['failed'].append({
                    'task_id': task.task_id,
                    'task_title': task.title,
                    'reason': 'No capable agent available'
                })
        
        # R√©sum√© par agent
        agent_workloads = {}
        for agent_id, agent in self.agents.items():
            agent_workloads[agent.name] = len(agent.current_tasks)
        
        results['summary'] = {
            'total_assigned': len(results['assigned']),
            'total_failed': len(results['failed']),
            'agent_workloads': agent_workloads
        }
        
        print(f"\n‚úÖ Assign√©es: {len(results['assigned'])}")
        print(f"‚ùå √âchecs: {len(results['failed'])}")
        print(f"\nüìä Charge par agent:")
        for agent_name, workload in agent_workloads.items():
            print(f"  {agent_name}: {workload} t√¢ches")
        
        return results
    
    def generate_ecosystem_report(self) -> Dict[str, Any]:
        """G√©n√®re rapport complet √©cosyst√®me Panini."""
        report = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'ecosystem': {
                'projects': len(self.github_projects),
                'repositories': len(self.repositories),
                'categories': len(self.project_categories)
            },
            'tasks': {
                'total': len(self.tasks),
                'by_status': {},
                'by_project': {},
                'by_category': {}
            },
            'agents': {},
            'recommendations': []
        }
        
        # Tasks by status
        for status in ['pending', 'assigned', 'in_progress', 'completed']:
            report['tasks']['by_status'][status] = sum(
                1 for t in self.tasks.values() if t.status == status
            )
        
        # Tasks by project (via task_id prefix panini_XX)
        for task_id, task in self.tasks.items():
            if task_id.startswith('panini_'):
                # Skip special tasks (e.g. panini_corpus_pipeline_master)
                try:
                    project_num = int(task_id.split('_')[1])
                    project_name = self.github_projects.get(project_num, 'Unknown')
                    if project_name not in report['tasks']['by_project']:
                        report['tasks']['by_project'][project_name] = 0
                    report['tasks']['by_project'][project_name] += 1
                except ValueError:
                    # Special task (e.g. corpus_pipeline_master)
                    pass
        
        # Tasks by category
        for category, projects in self.project_categories.items():
            count = 0
            for task_id in self.tasks:
                if task_id.startswith('panini_'):
                    try:
                        project_num = int(task_id.split('_')[1])
                        if project_num in projects:
                            count += 1
                    except ValueError:
                        # Skip special tasks
                        pass
            report['tasks']['by_category'][category] = count
        
        # Agents
        for agent_id, agent in self.agents.items():
            report['agents'][agent.name] = {
                'workload': len(agent.current_tasks),
                'completed': agent.completed_tasks,
                'available': agent.is_available(),
                'cost_per_task': agent.cost_per_task
            }
        
        # Recommendations
        if report['tasks']['by_status']['pending'] > 5:
            report['recommendations'].append(
                f"‚ö†Ô∏è  {report['tasks']['by_status']['pending']} t√¢ches pending - "
                "Consid√©rer augmenter capacit√© agents"
            )
        
        gpu_tasks = sum(
            1 for t in self.tasks.values()
            if t.requires_gpu and t.status in ['pending', 'assigned']
        )
        if gpu_tasks > 2:
            report['recommendations'].append(
                f"üéÆ {gpu_tasks} t√¢ches GPU waiting - "
                "Prioriser Colab Pro sessions"
            )
        
        human_review = sum(
            1 for t in self.tasks.values()
            if t.requires_human_review and t.status != 'completed'
        )
        if human_review > 0:
            report['recommendations'].append(
                f"üë§ {human_review} t√¢ches requi√®rent review humaine - "
                "Bloquer 30-60min pour review"
            )
        
        return report
    
    def export_ecosystem_state(self) -> Path:
        """Export √©tat complet √©cosyst√®me."""
        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H-%M-%SZ')
        output_file = (
            self.workspace_root / 
            f'panini_ecosystem_state_{timestamp}.json'
        )
        
        state = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'ecosystem': {
                'projects': self.github_projects,
                'repositories': self.repositories,
                'project_to_repo': self.project_to_repo,
                'categories': self.project_categories
            },
            'agents': {
                agent_id: agent.to_dict()
                for agent_id, agent in self.agents.items()
            },
            'tasks': {
                task_id: task.to_dict()
                for task_id, task in self.tasks.items()
            },
            'assignments': self.assignment_log,
            'report': self.generate_ecosystem_report()
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ √âtat √©cosyst√®me export√©: {output_file.name}")
        return output_file


def main():
    """D√©mo orchestrateur √©cosyst√®me Panini."""
    workspace = "/home/stephane/GitHub/PaniniFS-Research"
    
    print("\n" + "=" * 70)
    print("üåê PANINI ECOSYSTEM ORCHESTRATOR")
    print("=" * 70 + "\n")
    
    orchestrator = PaniniEcosystemOrchestrator(workspace)
    
    print(f"üìä √âcosyst√®me charg√©:")
    print(f"  - {len(orchestrator.github_projects)} GitHub Projects")
    print(f"  - {len(orchestrator.repositories)} Repositories")
    print(f"  - {len(orchestrator.tasks)} T√¢ches initiales")
    print(f"  - {len(orchestrator.agents)} Agents disponibles")
    
    # Assignation automatique
    print("\n" + "-" * 70)
    results = orchestrator.assign_all_pending_tasks()
    
    # Rapport √©cosyst√®me
    print("\n" + "-" * 70)
    print("üìà RAPPORT √âCOSYST√àME PANINI")
    print("-" * 70 + "\n")
    
    report = orchestrator.generate_ecosystem_report()
    
    print(f"Projets: {report['ecosystem']['projects']}")
    print(f"Repositories: {report['ecosystem']['repositories']}")
    print(f"\nT√¢ches par status:")
    for status, count in report['tasks']['by_status'].items():
        print(f"  {status}: {count}")
    
    print(f"\nT√¢ches par cat√©gorie:")
    for category, count in report['tasks']['by_category'].items():
        print(f"  {category}: {count}")
    
    if report['recommendations']:
        print(f"\nüí° Recommandations:")
        for rec in report['recommendations']:
            print(f"  {rec}")
    
    # Export
    print("\n" + "-" * 70)
    output = orchestrator.export_ecosystem_state()
    
    print(f"\n‚úÖ Orchestrateur √©cosyst√®me Panini pr√™t !")
    print(f"üìä Utilisez le rapport pour prioriser votre travail")


if __name__ == '__main__':
    main()
