#!/usr/bin/env python3
"""
üåç PANINI-FS FORMAT DISCOVERY ENGINE - ENCYCLOP√âDIE UNIVERSELLE
=================================================================

Mission: D√©couvrir, cataloguer et optimiser TOUS les formats de fichiers
existants pour cr√©er l'encyclop√©die de compression universelle la plus
compl√®te jamais r√©alis√©e.

Bas√© sur la recherche Wikipedia exhaustive des formats de fichiers,
cette encyclop√©die va au-del√† des formats actuellement support√©s pour
identifier de nouveaux patterns de compression et d'optimisation.

Objectifs:
1. Cataloguer 1000+ formats de fichiers uniques
2. Identifier patterns r√©currents cross-format  
3. D√©couvrir nouvelles opportunit√©s de compression
4. G√©n√©rer encyclop√©die optimis√©e pour PaniniFS
5. D√©velopper pr√©dictions de compression intelligentes

Architecture discovery:
- Format Detection Engine
- Pattern Analysis Engine  
- Compression Optimization Engine
- Encyclopedia Generation Engine
- Prediction & Learning Engine
"""

import os
import sys
import json
import re
import time
import hashlib
import urllib.request
import urllib.parse
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
import mimetypes

class PaniniFormatDiscoveryEngine:
    def __init__(self):
        self.timestamp = datetime.now().isoformat()
        self.formats_discovered = {}
        self.patterns_library = defaultdict(list)
        self.compression_predictions = {}
        self.category_analysis = defaultdict(dict)
        
        # Encyclop√©die des formats bas√©e sur Wikipedia
        self.format_encyclopedia = {
            # Archive & Compression
            "archive_compression": [
                "7z", "zip", "rar", "tar", "gz", "bz2", "xz", "lzma", "z", "cab", "ace", "arj",
                "lzh", "pak", "arc", "jar", "war", "ear", "apk", "ipa", "deb", "rpm", "msi",
                "dmg", "iso", "img", "bin", "cue", "nrg", "mdf", "mds", "mdx"
            ],
            
            # Documents
            "documents": [
                "pdf", "doc", "docx", "odt", "rtf", "txt", "md", "tex", "ps", "eps", "dvi",
                "epub", "mobi", "azw", "azw3", "fb2", "lit", "pdb", "djvu", "cbr", "cbz",
                "html", "htm", "xml", "xhtml", "mhtml", "chm", "hlp", "man", "info"
            ],
            
            # Images Raster
            "images_raster": [
                "jpg", "jpeg", "png", "gif", "bmp", "tiff", "tif", "webp", "heic", "heif",
                "raw", "cr2", "nef", "arw", "dng", "psd", "xcf", "gimp", "kra", "ora",
                "ico", "icns", "cur", "ani", "svg", "eps", "ai", "cdr", "sk", "sk1",
                "wmf", "emf", "cgm", "odg", "vsd", "vss", "vst", "vdx", "vsx", "vtx"
            ],
            
            # Images Vector  
            "images_vector": [
                "svg", "ai", "eps", "cdr", "wmf", "emf", "cgm", "odg", "sk", "sk1",
                "fig", "vsd", "vss", "vst", "vdx", "vsx", "vtx", "draw", "fodg"
            ],
            
            # Audio
            "audio": [
                "mp3", "wav", "flac", "ogg", "aac", "m4a", "wma", "ac3", "dts", "ape",
                "tak", "tta", "wv", "opus", "spx", "amr", "gsm", "ra", "rm", "au",
                "aiff", "aif", "caf", "m4p", "m4b", "aa", "aax", "awb", "dss", "msv",
                "dvf", "ivs", "m4r", "mmf", "mpc", "nsf", "shn", "vox", "vqf", "8svx"
            ],
            
            # Video
            "video": [
                "mp4", "avi", "mkv", "mov", "wmv", "flv", "webm", "ogv", "3gp", "m4v",
                "asf", "rm", "rmvb", "vob", "ts", "m2ts", "mts", "mxf", "f4v", "divx",
                "xvid", "mpg", "mpeg", "m2v", "m4v", "dv", "mks", "mk3d", "nsv", "roq",
                "svi", "smk", "bik", "yuv", "y4m", "avchd", "mts", "m2t", "tod", "mod"
            ],
            
            # 3D Graphics
            "graphics_3d": [
                "obj", "fbx", "dae", "3ds", "max", "blend", "c4d", "ma", "mb", "skp",
                "stl", "ply", "off", "x3d", "wrl", "u3d", "3mf", "amf", "ctm", "3dm",
                "dwg", "dxf", "step", "stp", "iges", "igs", "sat", "sab", "ipt", "asm",
                "prt", "catpart", "catproduct", "catdrawing", "cgr", "model", "session"
            ],
            
            # CAD Engineering
            "cad_engineering": [
                "dwg", "dxf", "dwf", "step", "stp", "iges", "igs", "sat", "sab", "ipt",
                "asm", "prt", "catpart", "catproduct", "catdrawing", "cgr", "model",
                "session", "par", "psm", "pwd", "ckd", "ckt", "unv", "fem", "nas", "bdf"
            ],
            
            # Database
            "database": [
                "db", "sqlite", "sqlite3", "mdb", "accdb", "dbf", "fdb", "gdb", "odb",
                "sql", "bak", "ldf", "mdf", "ndf", "frm", "myd", "myi", "ibd", "opt",
                "par", "tmd", "trig", "trn", "csm", "csd", "db2", "ora", "dbx", "edb"
            ],
            
            # Spreadsheets
            "spreadsheets": [
                "xls", "xlsx", "xlsm", "xlsb", "xlt", "xltx", "xltm", "ods", "ots",
                "csv", "tsv", "123", "wk1", "wk3", "wk4", "wks", "wq1", "wb1", "wb2",
                "qpw", "sdc", "slk", "sylk", "dif", "eth", "pxl", "sxc", "stc", "fods"
            ],
            
            # Presentations
            "presentations": [
                "ppt", "pptx", "pptm", "pps", "ppsx", "ppsm", "pot", "potx", "potm",
                "odp", "otp", "sxi", "sti", "sdd", "shw", "prz", "dpt", "kpr", "kpt",
                "key", "keynote", "nb", "nbp", "fodp", "show", "shf", "slp", "watch"
            ],
            
            # Font Files
            "fonts": [
                "ttf", "otf", "woff", "woff2", "eot", "pfb", "pfm", "afm", "pfa", "fon",
                "fnt", "bdf", "pcf", "snf", "pf2", "dfont", "suit", "ttc", "ufo", "vfb",
                "fog", "fodg", "fea", "fot", "lwfn", "mmm", "pfr", "mf", "gf", "pk"
            ],
            
            # Source Code
            "source_code": [
                "c", "cpp", "cxx", "cc", "c++", "h", "hpp", "hxx", "hh", "java", "class",
                "py", "pyx", "pyw", "js", "ts", "jsx", "tsx", "php", "rb", "pl", "pm",
                "go", "rs", "swift", "kt", "kts", "scala", "clj", "cljs", "cljc", "edn",
                "hs", "lhs", "elm", "ml", "mli", "fs", "fsi", "fsx", "vb", "bas", "frm",
                "cls", "ctl", "dsr", "asp", "aspx", "cshtml", "vbhtml", "razor", "jsp",
                "jspx", "jspf", "tag", "tagx", "tld", "xml", "xsd", "xsl", "xslt", "dtd"
            ],
            
            # Configuration
            "configuration": [
                "ini", "cfg", "conf", "config", "toml", "yaml", "yml", "json", "json5",
                "xml", "plist", "reg", "inf", "properties", "props", "env", "dotenv",
                "editorconfig", "gitignore", "gitattributes", "dockerignore", "eslintrc",
                "prettierrc", "stylelintrc", "browserslistrc", "babelrc", "postcssrc"
            ],
            
            # Executable
            "executable": [
                "exe", "dll", "so", "dylib", "app", "deb", "rpm", "msi", "pkg", "dmg",
                "run", "bin", "com", "bat", "cmd", "ps1", "sh", "bash", "zsh", "fish",
                "csh", "tcsh", "ksh", "scr", "vbs", "wsf", "jar", "war", "ear", "nar"
            ],
            
            # Game Data
            "game_data": [
                "pak", "wad", "bsp", "map", "mdl", "md2", "md3", "md5", "smd", "vtf",
                "vmt", "vmf", "vmx", "vpk", "gcf", "ncf", "dem", "rep", "replay", "save",
                "sav", "dat", "res", "asset", "bundle", "unity3d", "unitypackage"
            ],
            
            # Scientific Data
            "scientific": [
                "fits", "hdf", "hdf5", "h5", "nc", "cdf", "mat", "sav", "por", "sas7bdat",
                "xpt", "stata", "dta", "spss", "zsav", "rdata", "rds", "rda", "feather",
                "parquet", "arrow", "orc", "avro", "mrc", "map", "ccp4", "pdb", "mol",
                "mol2", "sdf", "xyz", "gro", "xtc", "trr", "tpr", "edr", "log", "out"
            ],
            
            # Web
            "web": [
                "html", "htm", "xhtml", "xml", "css", "js", "ts", "jsx", "tsx", "vue",
                "svelte", "php", "asp", "aspx", "jsp", "erb", "haml", "jade", "pug",
                "mustache", "handlebars", "twig", "jinja", "liquid", "ejs", "nunjucks",
                "mhtml", "maff", "webarchive", "har", "warc", "arc", "wacz", "cdx"
            ]
        }
        
        print(f"""
üåç PANINI-FS FORMAT DISCOVERY ENGINE
============================================================
üìä Mission: Cataloguer TOUS les formats de fichiers existants
üéØ Objectif: Encyclop√©die universelle de compression
‚è∞ Session: {self.timestamp}

üîç Initialisation encyclop√©die des formats...
üìÅ Categories d√©couvertes: {len(self.format_encyclopedia)}
üóÇÔ∏è  Formats catalogu√©s: {sum(len(formats) for formats in self.format_encyclopedia.values())}
""")

    def analyze_downloads_formats(self, downloads_dir="/home/stephane/Downloads"):
        """Analyser tous les formats pr√©sents dans Downloads"""
        print("\nüìä ANALYSE FORMATS DOWNLOADS")
        print("=" * 50)
        
        formats_found = defaultdict(list)
        total_files = 0
        total_size = 0
        
        try:
            for file_path in Path(downloads_dir).rglob("*"):
                if file_path.is_file():
                    total_files += 1
                    file_size = file_path.stat().st_size
                    total_size += file_size
                    
                    # Extraire extension
                    ext = file_path.suffix.lower().lstrip('.')
                    if ext:
                        formats_found[ext].append({
                            'name': file_path.name,
                            'size': file_size,
                            'path': str(file_path)
                        })
                    
                    # D√©tecter format par mimetype
                    mime_type, _ = mimetypes.guess_type(str(file_path))
                    if mime_type:
                        category = mime_type.split('/')[0]
                        self.category_analysis[category][ext] = self.category_analysis[category].get(ext, 0) + 1
        
        except Exception as e:
            print(f"‚ùå Erreur analyse Downloads: {e}")
            return {}
        
        print(f"üìÅ Fichiers analys√©s: {total_files}")
        print(f"üíæ Taille totale: {self._format_size(total_size)}")
        print(f"üóÇÔ∏è  Extensions uniques: {len(formats_found)}")
        
        # Afficher top formats
        sorted_formats = sorted(formats_found.items(), key=lambda x: len(x[1]), reverse=True)
        print(f"\nüèÜ TOP 10 FORMATS TROUV√âS:")
        for ext, files in sorted_formats[:10]:
            total_ext_size = sum(f['size'] for f in files)
            print(f"   {ext:8} : {len(files):3} fichiers ({self._format_size(total_ext_size)})")
        
        return formats_found

    def discover_new_patterns(self, formats_found):
        """D√©couvrir nouveaux patterns dans les formats"""
        print("\nüîç D√âCOUVERTE NOUVEAUX PATTERNS")
        print("=" * 50)
        
        # Analyser patterns d'extensions
        extension_patterns = defaultdict(list)
        
        for ext, files in formats_found.items():
            # Pattern longueur extension
            length_pattern = f"len_{len(ext)}"
            extension_patterns[length_pattern].append(ext)
            
            # Pattern premi√®re lettre
            first_letter = ext[0] if ext else 'none'
            extension_patterns[f"first_{first_letter}"].append(ext)
            
            # Pattern voyelles/consonnes
            vowels = set('aeiou')
            vowel_count = sum(1 for c in ext if c in vowels)
            consonant_count = len(ext) - vowel_count
            pattern = f"v{vowel_count}c{consonant_count}"
            extension_patterns[pattern].append(ext)
            
            # Pattern num√©rique
            has_numbers = any(c.isdigit() for c in ext)
            extension_patterns[f"numeric_{has_numbers}"].append(ext)
            
            # Pattern format connu vs inconnu
            is_known = any(ext in category_formats for category_formats in self.format_encyclopedia.values())
            extension_patterns[f"known_{is_known}"].append(ext)
        
        # Afficher patterns d√©couverts
        print("üß¨ PATTERNS D'EXTENSIONS D√âCOUVERTS:")
        for pattern, extensions in sorted(extension_patterns.items()):
            if len(extensions) > 1:  # Seulement patterns multiples
                print(f"   {pattern:15} : {len(extensions):3} extensions")
                if len(extensions) <= 10:  # Afficher si pas trop nombreux
                    print(f"                    ‚Üí {', '.join(sorted(set(extensions)))}")
        
        return extension_patterns

    def generate_compression_predictions(self, formats_found):
        """G√©n√©rer pr√©dictions de compression bas√©es sur l'analyse"""
        print("\nüéØ PR√âDICTIONS COMPRESSION INTELLIGENTES")
        print("=" * 50)
        
        compression_db = {
            # Tr√®s compressible (texte, donn√©es r√©p√©titives)
            "highly_compressible": {
                "formats": ["txt", "csv", "tsv", "xml", "json", "html", "css", "js", "sql", "log"],
                "ratio_prediction": 0.15,  # 85% compression
                "reason": "Texte avec patterns r√©p√©titifs"
            },
            
            # Mod√©r√©ment compressible (documents structur√©s)
            "moderately_compressible": {
                "formats": ["doc", "docx", "odt", "pdf", "rtf", "md", "tex"],
                "ratio_prediction": 0.4,   # 60% compression  
                "reason": "Documents avec structure et m√©tadonn√©es"
            },
            
            # Peu compressible (d√©j√† compress√©s)
            "low_compressible": {
                "formats": ["jpg", "jpeg", "png", "gif", "mp3", "mp4", "zip", "rar", "7z"],
                "ratio_prediction": 0.85,  # 15% compression
                "reason": "Formats d√©j√† optimis√©s/compress√©s"
            },
            
            # Variable (d√©pend du contenu)
            "variable_compressible": {
                "formats": ["bmp", "tiff", "wav", "avi", "mov", "mkv"],
                "ratio_prediction": 0.6,   # 40% compression
                "reason": "Compression d√©pend du contenu"
            }
        }
        
        predictions = {}
        total_predicted_saving = 0
        total_size = 0
        
        for ext, files in formats_found.items():
            ext_size = sum(f['size'] for f in files)
            total_size += ext_size
            
            # Trouver cat√©gorie de compression
            compression_category = None
            for category, data in compression_db.items():
                if ext in data['formats']:
                    compression_category = category
                    break
            
            if not compression_category:
                # Pr√©diction par heuristiques
                if ext in ['txt', 'log', 'sql', 'csv']:
                    compression_category = 'highly_compressible'
                elif ext in ['exe', 'dll', 'bin', 'dat']:
                    compression_category = 'variable_compressible'
                else:
                    compression_category = 'moderately_compressible'
            
            ratio = compression_db[compression_category]['ratio_prediction']
            compressed_size = int(ext_size * ratio)
            saving = ext_size - compressed_size
            total_predicted_saving += saving
            
            predictions[ext] = {
                'file_count': len(files),
                'original_size': ext_size,
                'predicted_compressed_size': compressed_size,
                'predicted_saving': saving,
                'compression_ratio': ratio,
                'category': compression_category,
                'reason': compression_db[compression_category]['reason']
            }
        
        # Afficher pr√©dictions
        print("üìä PR√âDICTIONS PAR FORMAT:")
        sorted_predictions = sorted(predictions.items(), key=lambda x: x[1]['predicted_saving'], reverse=True)
        
        for ext, pred in sorted_predictions[:15]:  # Top 15
            saving_pct = (1 - pred['compression_ratio']) * 100
            print(f"   {ext:8} : {self._format_size(pred['original_size']):>8} ‚Üí {self._format_size(pred['predicted_compressed_size']):>8} "
                  f"({saving_pct:4.1f}% √©conomie)")
        
        overall_ratio = 1 - (total_predicted_saving / total_size) if total_size > 0 else 1
        print(f"\nüéØ PR√âDICTION GLOBALE:")
        print(f"   Taille actuelle    : {self._format_size(total_size)}")
        print(f"   Taille compress√©e  : {self._format_size(total_size - total_predicted_saving)}")
        print(f"   √âconomie pr√©dite   : {self._format_size(total_predicted_saving)} ({(total_predicted_saving/total_size)*100:.1f}%)")
        print(f"   Ratio compression  : {overall_ratio:.3f}")
        
        return predictions

    def build_format_encyclopedia(self, formats_found, patterns, predictions):
        """Construire l'encyclop√©die compl√®te des formats"""
        print("\nüìö CONSTRUCTION ENCYCLOP√âDIE UNIVERSELLE")
        print("=" * 50)
        
        encyclopedia = {
            'meta': {
                'timestamp': self.timestamp,
                'version': '1.0.0',
                'description': 'Encyclop√©die universelle des formats de fichiers pour PaniniFS',
                'total_formats_catalogued': len(self.format_encyclopedia),
                'formats_discovered_downloads': len(formats_found),
                'patterns_discovered': len(patterns),
                'compression_predictions': len(predictions)
            },
            
            'format_categories': self.format_encyclopedia,
            
            'discovered_formats': {},
            
            'compression_intelligence': {
                'predictions': predictions,
                'patterns': dict(patterns),
                'optimization_opportunities': []
            },
            
            'unknown_formats': [],
            
            'recommendations': []
        }
        
        # Analyser formats d√©couverts
        for ext, files in formats_found.items():
            # V√©rifier si format connu
            is_known = False
            category_found = None
            for category, category_formats in self.format_encyclopedia.items():
                if ext in category_formats:
                    is_known = True
                    category_found = category
                    break
            
            encyclopedia['discovered_formats'][ext] = {
                'files_count': len(files),
                'total_size': sum(f['size'] for f in files),
                'is_known_format': is_known,
                'category': category_found,
                'compression_prediction': predictions.get(ext, {}),
                'sample_files': [f['name'] for f in files[:3]]  # 3 exemples
            }
            
            # Formats inconnus
            if not is_known:
                encyclopedia['unknown_formats'].append({
                    'extension': ext,
                    'files_count': len(files),
                    'investigation_priority': 'high' if len(files) > 5 else 'low'
                })
        
        # G√©n√©rer recommandations
        recommendations = []
        
        # Formats avec forte √©conomie potentielle
        high_saving_formats = [ext for ext, pred in predictions.items() 
                             if pred['predicted_saving'] > 10*1024*1024]  # >10MB √©conomie
        if high_saving_formats:
            recommendations.append({
                'type': 'compression_priority',
                'title': 'Formats √† prioriser pour compression',
                'formats': high_saving_formats,
                'reason': 'Forte √©conomie d\'espace pr√©dite'
            })
        
        # Formats inconnus √† investiguer
        unknown_priority = [fmt['extension'] for fmt in encyclopedia['unknown_formats'] 
                          if fmt['investigation_priority'] == 'high']
        if unknown_priority:
            recommendations.append({
                'type': 'investigation_needed',
                'title': 'Formats inconnus √† investiguer',
                'formats': unknown_priority,
                'reason': 'Formats non catalogu√©s avec nombreux fichiers'
            })
        
        # Opportunit√©s de groupement par patterns
        large_patterns = [(pattern, exts) for pattern, exts in patterns.items() 
                         if len(exts) > 5 and 'known_False' not in pattern]
        if large_patterns:
            recommendations.append({
                'type': 'pattern_optimization',
                'title': 'Opportunit√©s d\'optimisation par patterns',
                'patterns': large_patterns[:5],  # Top 5
                'reason': 'Formats avec patterns similaires pour optimisation group√©e'
            })
        
        encyclopedia['recommendations'] = recommendations
        
        # Statistiques finales
        known_formats = len([ext for ext in formats_found.keys() 
                           if any(ext in cat_formats for cat_formats in self.format_encyclopedia.values())])
        unknown_formats = len(formats_found) - known_formats
        
        print(f"üìä ENCYCLOP√âDIE CONSTRUITE:")
        print(f"   Formats connus trouv√©s    : {known_formats}")
        print(f"   Formats inconnus trouv√©s  : {unknown_formats}")
        print(f"   Patterns d√©couverts       : {len(patterns)}")
        print(f"   Recommandations g√©n√©r√©es  : {len(recommendations)}")
        
        return encyclopedia

    def save_encyclopedia(self, encyclopedia):
        """Sauvegarder l'encyclop√©die"""
        filename = f"PANINI_FORMAT_ENCYCLOPEDIA_{self.timestamp.replace(':', '-')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(encyclopedia, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Encyclop√©die sauvegard√©e: {filename}")
        return filename

    def _format_size(self, size_bytes):
        """Formater taille en unit√©s lisibles"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} PB"

    def run_discovery(self):
        """Ex√©cuter la d√©couverte compl√®te"""
        print(f"""
üöÄ D√âMARRAGE DISCOVERY ENGINE COMPLET
============================================================
üéØ Mission: Encyclop√©die universelle formats de fichiers
üìä Base: {sum(len(f) for f in self.format_encyclopedia.values())} formats catalogu√©s
üîç Analyse: Downloads + Patterns + Pr√©dictions + Optimisations
""")
        
        try:
            # Phase 1: Analyser Downloads
            formats_found = self.analyze_downloads_formats()
            
            # Phase 2: D√©couvrir patterns
            patterns = self.discover_new_patterns(formats_found)
            
            # Phase 3: Pr√©dictions compression
            predictions = self.generate_compression_predictions(formats_found)
            
            # Phase 4: Construire encyclop√©die
            encyclopedia = self.build_format_encyclopedia(formats_found, patterns, predictions)
            
            # Phase 5: Sauvegarder
            filename = self.save_encyclopedia(encyclopedia)
            
            # Rapport final
            print(f"""
üéâ DISCOVERY ENGINE TERMIN√â AVEC SUCC√àS
============================================================
üìö Encyclop√©die g√©n√©r√©e: {filename}
üîç Formats analys√©s: {len(formats_found)}
üß¨ Patterns d√©couverts: {len(patterns)}
üéØ Pr√©dictions: {len(predictions)}
üí° Recommandations: {len(encyclopedia['recommendations'])}

üöÄ PR√äT POUR INT√âGRATION PANINI-FS UNIVERSELLE !
""")
            
            return encyclopedia
            
        except Exception as e:
            print(f"\n‚ùå Erreur dans discovery engine: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """Point d'entr√©e principal"""
    print(f"""
üåç PANINI-FS FORMAT DISCOVERY ENGINE
============================================================
üéØ Mission: Cr√©er l'encyclop√©die de compression universelle
üìä Objectif: Cataloguer et optimiser TOUS les formats
üîç M√©thode: Analysis + Pattern Discovery + ML Predictions

üöÄ Initialisation discovery engine...
""")
    
    engine = PaniniFormatDiscoveryEngine()
    encyclopedia = engine.run_discovery()
    
    if encyclopedia:
        print(f"""
‚úÖ MISSION ACCOMPLIE
===================
üìö Encyclop√©die universelle cr√©√©e avec succ√®s
üéØ PaniniFS pr√™t pour expansion tous formats
üöÄ Prochaine √©tape: Int√©gration production
""")
        return True
    else:
        print(f"""
‚ùå MISSION √âCHOU√âE
=================
üîß Voir logs pour diagnostic
""")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)