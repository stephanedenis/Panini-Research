{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6178328f",
   "metadata": {},
   "source": [
    "# üöÄ PaniniFS - Mode Cloud Autonome\n",
    "\n",
    "**100% Cloud Native** - Clonage automatique des repos GitHub\n",
    "\n",
    "## üéØ Workflow Autonome\n",
    "\n",
    "1. **Auto-d√©tection** : Mode Colab vs Local\n",
    "2. **Clonage repos** : Tous les repos GitHub automatiquement\n",
    "3. **Scan optimis√©** : Limites strictes pour performance\n",
    "4. **Embeddings** : Pipeline complet temps r√©el\n",
    "5. **Recherche** : Interface interactive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e609e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß SETUP AUTONOME - D√©tection environnement et installation\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# D√©tection mode Cloud (Colab/Kaggle/etc)\n",
    "IS_CLOUD = 'google.colab' in sys.modules or '/kaggle/' in os.environ.get('PATH', '') or 'COLAB_GPU' in os.environ\n",
    "print(f\"üåç Mode d√©tect√©: {'‚òÅÔ∏è CLOUD' if IS_CLOUD else 'üñ•Ô∏è LOCAL'}\")\n",
    "\n",
    "if IS_CLOUD:\n",
    "    # Installation d√©pendances cloud\n",
    "    print(\"üì¶ Installation d√©pendances cloud...\")\n",
    "    !pip install sentence-transformers torch --quiet\n",
    "    BASE_PATH = Path('/content')\n",
    "else:\n",
    "    BASE_PATH = Path('/home/stephane/GitHub')\n",
    "\n",
    "print(f\"üìÅ R√©pertoire de travail: {BASE_PATH}\")\n",
    "os.chdir(BASE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ CLONAGE AUTOMATIQUE DES REPOS (Publics + Priv√©s Intelligents)\n",
    "def clone_repos_cloud_smart():\n",
    "    \"\"\"Clone intelligemment les repos - public garanti + priv√©s optionnels\"\"\"\n",
    "    \n",
    "    # Configuration repos avec priorit√©s\n",
    "    repos_config = [\n",
    "        # Repo principal (public garanti)\n",
    "        {\n",
    "            'name': 'PaniniFS-1',\n",
    "            'url': 'https://github.com/stephanedenis/PaniniFS.git',\n",
    "            'priority': 'CRITICAL',\n",
    "            'public': True\n",
    "        },\n",
    "        # Repos secondaires (possiblement priv√©s)\n",
    "        {\n",
    "            'name': 'Pensine',\n",
    "            'url': 'https://github.com/stephanedenis/Pensine.git',\n",
    "            'priority': 'OPTIONAL',\n",
    "            'public': False\n",
    "        },\n",
    "        {\n",
    "            'name': 'totoro-automation',\n",
    "            'url': 'https://github.com/stephanedenis/totoro-automation.git',\n",
    "            'priority': 'OPTIONAL',\n",
    "            'public': False\n",
    "        },\n",
    "        {\n",
    "            'name': 'hexagonal-demo',\n",
    "            'url': 'https://github.com/stephanedenis/hexagonal-demo.git',\n",
    "            'priority': 'OPTIONAL',\n",
    "            'public': False\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    cloned_repos = []\n",
    "    failed_repos = []\n",
    "    \n",
    "    for repo in repos_config:\n",
    "        repo_name = repo['name']\n",
    "        repo_url = repo['url']\n",
    "        repo_path = BASE_PATH / repo_name\n",
    "        \n",
    "        if repo_path.exists():\n",
    "            print(f\"‚úÖ {repo_name} d√©j√† pr√©sent\")\n",
    "            cloned_repos.append(repo_name)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            print(f\"üì• Clonage {repo_name}...\")\n",
    "            result = subprocess.run(\n",
    "                ['git', 'clone', repo_url, str(repo_path)], \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                timeout=30  # Timeout r√©duit\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ {repo_name} clon√© avec succ√®s\")\n",
    "                cloned_repos.append(repo_name)\n",
    "            else:\n",
    "                error_msg = result.stderr.strip()\n",
    "                if repo['priority'] == 'CRITICAL':\n",
    "                    print(f\"‚ùå CRITIQUE: √âchec {repo_name}: {error_msg}\")\n",
    "                    raise Exception(f\"Repo critique {repo_name} inaccessible\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è {repo_name} non accessible (possiblement priv√©)\")\n",
    "                    failed_repos.append({'name': repo_name, 'reason': 'auth_required'})\n",
    "                    \n",
    "        except subprocess.TimeoutExpired:\n",
    "            if repo['priority'] == 'CRITICAL':\n",
    "                print(f\"‚ùå CRITIQUE: Timeout {repo_name}\")\n",
    "                raise Exception(f\"Repo critique {repo_name} timeout\")\n",
    "            else:\n",
    "                print(f\"‚è±Ô∏è Timeout {repo_name} - skip\")\n",
    "                failed_repos.append({'name': repo_name, 'reason': 'timeout'})\n",
    "        except Exception as e:\n",
    "            if repo['priority'] == 'CRITICAL':\n",
    "                print(f\"‚ùå CRITIQUE: Erreur {repo_name}: {e}\")\n",
    "                raise\n",
    "            else:\n",
    "                print(f\"‚ùå Erreur optionnelle {repo_name}: {e}\")\n",
    "                failed_repos.append({'name': repo_name, 'reason': 'error'})\n",
    "    \n",
    "    return cloned_repos, failed_repos\n",
    "\n",
    "# Ex√©cution clonage intelligent\n",
    "if IS_CLOUD:\n",
    "    start_time = time.time()\n",
    "    available_repos, failed_repos = clone_repos_cloud_smart()\n",
    "    clone_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nüéØ Clonage termin√© en {clone_time:.2f}s\")\n",
    "    print(f\"‚úÖ {len(available_repos)} repos disponibles: {', '.join(available_repos)}\")\n",
    "    \n",
    "    if failed_repos:\n",
    "        print(f\"‚ö†Ô∏è {len(failed_repos)} repos non disponibles:\")\n",
    "        for failed in failed_repos:\n",
    "            reason = \"Authentification requise\" if failed['reason'] == 'auth_required' else failed['reason']\n",
    "            print(f\"  - {failed['name']}: {reason}\")\n",
    "        print(\"üí° Le syst√®me fonctionnera avec les repos publics disponibles\")\n",
    "    \n",
    "    # Validation critique\n",
    "    if 'PaniniFS-1' not in available_repos:\n",
    "        print(\"‚ùå ERREUR CRITIQUE: PaniniFS-1 non disponible\")\n",
    "        print(\"üí° V√©rifiez la connexion r√©seau ou les permissions\")\n",
    "        raise Exception(\"Repo critique manquant\")\n",
    "    else:\n",
    "        print(\"‚úÖ Repo principal PaniniFS-1 disponible - Workflow garanti\")\n",
    "        \n",
    "else:\n",
    "    # Mode local - utilise les repos existants\n",
    "    available_repos = ['PaniniFS-1']\n",
    "    # V√©rification optionnelle des autres repos locaux\n",
    "    local_optional_repos = ['Pensine', 'totoro-automation', 'hexagonal-demo']\n",
    "    for repo in local_optional_repos:\n",
    "        if (Path('/home/stephane/GitHub') / repo).exists():\n",
    "            available_repos.append(repo)\n",
    "    \n",
    "    print(f\"üì¶ Mode local - {len(available_repos)} repos configur√©s: {', '.join(available_repos)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç SCAN SOURCES CLOUD-OPTIMIS√â (Adaptatif)\n",
    "def scan_sources_cloud_adaptive():\n",
    "    \"\"\"Scan adaptatif - optimis√© m√™me pour un seul repo\"\"\"\n",
    "    \n",
    "    # Limites adaptatives selon nombre de repos\n",
    "    num_repos = len(available_repos)\n",
    "    \n",
    "    if num_repos == 1:\n",
    "        # Mode mono-repo intensif\n",
    "        MAX_PY_FILES_PER_REPO = 60  # Plus de fichiers si un seul repo\n",
    "        MAX_MD_FILES_PER_REPO = 30\n",
    "        print(\"üéØ Mode mono-repo intensif activ√©\")\n",
    "    elif num_repos <= 2:\n",
    "        # Mode duo-repo √©quilibr√©\n",
    "        MAX_PY_FILES_PER_REPO = 40\n",
    "        MAX_MD_FILES_PER_REPO = 20\n",
    "        print(\"üéØ Mode multi-repo √©quilibr√© activ√©\")\n",
    "    else:\n",
    "        # Mode multi-repo conservateur\n",
    "        MAX_PY_FILES_PER_REPO = 25\n",
    "        MAX_MD_FILES_PER_REPO = 15\n",
    "        print(\"üéØ Mode multi-repo conservateur activ√©\")\n",
    "    \n",
    "    MAX_FILE_SIZE = 150 * 1024  # 150KB max (augment√©)\n",
    "    \n",
    "    all_sources = []\n",
    "    scan_stats = {'total_files': 0, 'total_size': 0, 'repos_scanned': 0}\n",
    "    \n",
    "    for repo_name in available_repos:\n",
    "        repo_path = BASE_PATH / repo_name\n",
    "        \n",
    "        if not repo_path.exists():\n",
    "            print(f\"‚ö†Ô∏è Repo {repo_name} non trouv√©\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"üîç Scan {repo_name}...\")\n",
    "        repo_sources = []\n",
    "        py_count, md_count = 0, 0\n",
    "        \n",
    "        try:\n",
    "            # Scan fichiers Python avec priorit√© sur certains dossiers\n",
    "            priority_dirs = ['src', 'Copilotage', 'scripts', 'core', 'lib']\n",
    "            \n",
    "            # Scan prioritaire\n",
    "            for priority_dir in priority_dirs:\n",
    "                priority_path = repo_path / priority_dir\n",
    "                if priority_path.exists():\n",
    "                    for py_file in priority_path.rglob('*.py'):\n",
    "                        if py_count >= MAX_PY_FILES_PER_REPO:\n",
    "                            break\n",
    "                        \n",
    "                        if py_file.stat().st_size > MAX_FILE_SIZE:\n",
    "                            continue\n",
    "                            \n",
    "                        try:\n",
    "                            content = py_file.read_text(encoding='utf-8', errors='replace')\n",
    "                            if len(content.strip()) > 50:\n",
    "                                repo_sources.append({\n",
    "                                    'repo': repo_name,\n",
    "                                    'path': str(py_file.relative_to(repo_path)),\n",
    "                                    'type': 'python',\n",
    "                                    'content': content[:8000],  # Plus de contenu pour mono-repo\n",
    "                                    'size': len(content),\n",
    "                                    'priority': True\n",
    "                                })\n",
    "                                py_count += 1\n",
    "                        except Exception:\n",
    "                            continue\n",
    "            \n",
    "            # Scan g√©n√©ral pour le reste\n",
    "            if py_count < MAX_PY_FILES_PER_REPO:\n",
    "                for py_file in repo_path.rglob('*.py'):\n",
    "                    if py_count >= MAX_PY_FILES_PER_REPO:\n",
    "                        break\n",
    "                    \n",
    "                    # Skip si d√©j√† trait√© dans prioritaire\n",
    "                    if any(str(py_file.relative_to(repo_path)).startswith(pdir) for pdir in priority_dirs):\n",
    "                        continue\n",
    "                        \n",
    "                    if py_file.stat().st_size > MAX_FILE_SIZE:\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        content = py_file.read_text(encoding='utf-8', errors='replace')\n",
    "                        if len(content.strip()) > 50:\n",
    "                            repo_sources.append({\n",
    "                                'repo': repo_name,\n",
    "                                'path': str(py_file.relative_to(repo_path)),\n",
    "                                'type': 'python',\n",
    "                                'content': content[:6000],\n",
    "                                'size': len(content),\n",
    "                                'priority': False\n",
    "                            })\n",
    "                            py_count += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            \n",
    "            # Scan fichiers Markdown avec priorit√©\n",
    "            priority_md_files = ['README.md', 'GUIDE.md', 'CHANGELOG.md', 'ROADMAP.md']\n",
    "            \n",
    "            # Markdown prioritaires\n",
    "            for md_name in priority_md_files:\n",
    "                md_file = repo_path / md_name\n",
    "                if md_file.exists() and md_count < MAX_MD_FILES_PER_REPO:\n",
    "                    if md_file.stat().st_size <= MAX_FILE_SIZE:\n",
    "                        try:\n",
    "                            content = md_file.read_text(encoding='utf-8', errors='replace')\n",
    "                            if len(content.strip()) > 50:\n",
    "                                repo_sources.append({\n",
    "                                    'repo': repo_name,\n",
    "                                    'path': str(md_file.relative_to(repo_path)),\n",
    "                                    'type': 'markdown',\n",
    "                                    'content': content[:5000],\n",
    "                                    'size': len(content),\n",
    "                                    'priority': True\n",
    "                                })\n",
    "                                md_count += 1\n",
    "                        except Exception:\n",
    "                            continue\n",
    "            \n",
    "            # Scan g√©n√©ral Markdown\n",
    "            for md_file in repo_path.rglob('*.md'):\n",
    "                if md_count >= MAX_MD_FILES_PER_REPO:\n",
    "                    break\n",
    "                    \n",
    "                # Skip si d√©j√† trait√©\n",
    "                if md_file.name in priority_md_files:\n",
    "                    continue\n",
    "                    \n",
    "                if md_file.stat().st_size > MAX_FILE_SIZE:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    content = md_file.read_text(encoding='utf-8', errors='replace')\n",
    "                    if len(content.strip()) > 50:\n",
    "                        repo_sources.append({\n",
    "                            'repo': repo_name,\n",
    "                            'path': str(md_file.relative_to(repo_path)),\n",
    "                            'type': 'markdown',\n",
    "                            'content': content[:4000],\n",
    "                            'size': len(content),\n",
    "                            'priority': False\n",
    "                        })\n",
    "                        md_count += 1\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur scan {repo_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        all_sources.extend(repo_sources)\n",
    "        scan_stats['repos_scanned'] += 1\n",
    "        scan_stats['total_files'] += len(repo_sources)\n",
    "        scan_stats['total_size'] += sum(s['size'] for s in repo_sources)\n",
    "        \n",
    "        # Statistiques d√©taill√©es\n",
    "        priority_count = sum(1 for s in repo_sources if s.get('priority', False))\n",
    "        print(f\"  üìÑ {len(repo_sources)} fichiers ({py_count} .py + {md_count} .md)\")\n",
    "        print(f\"  ‚≠ê {priority_count} fichiers prioritaires\")\n",
    "    \n",
    "    return all_sources, scan_stats\n",
    "\n",
    "# Ex√©cution scan adaptatif\n",
    "print(f\"\\nüìÅ SCAN SOURCES ADAPTATIF ({len(available_repos)} repos)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "sources, stats = scan_sources_cloud_adaptive()\n",
    "scan_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Scan termin√© en {scan_time:.2f}s\")\n",
    "print(f\"üéØ {stats['total_files']} sources consolid√©es\")\n",
    "print(f\"üìä {stats['repos_scanned']} repos scann√©s\")\n",
    "print(f\"üíæ {stats['total_size'] / 1024:.1f}KB total\")\n",
    "\n",
    "if len(sources) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è AUCUNE SOURCE TROUV√âE\")\n",
    "    print(\"üí° V√©rifiez la structure des repos ou les permissions\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ SOURCES PR√äTES POUR EMBEDDINGS\")\n",
    "    \n",
    "    # Analyse de la distribution\n",
    "    by_repo = {}\n",
    "    by_type = {'python': 0, 'markdown': 0}\n",
    "    \n",
    "    for source in sources:\n",
    "        repo = source['repo']\n",
    "        stype = source['type']\n",
    "        \n",
    "        if repo not in by_repo:\n",
    "            by_repo[repo] = {'python': 0, 'markdown': 0}\n",
    "        by_repo[repo][stype] += 1\n",
    "        by_type[stype] += 1\n",
    "    \n",
    "    print(\"\\nüìä DISTRIBUTION:\")\n",
    "    for repo, counts in by_repo.items():\n",
    "        total = counts['python'] + counts['markdown']\n",
    "        print(f\"  {repo}: {total} fichiers ({counts['python']} .py + {counts['markdown']} .md)\")\n",
    "    \n",
    "    print(f\"\\nüéØ TOTAL: {by_type['python']} Python + {by_type['markdown']} Markdown = {len(sources)} sources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ae7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† G√âN√âRATION EMBEDDINGS ADAPTATIFS\n",
    "if len(sources) > 0:\n",
    "    print(f\"\\nüß† G√âN√âRATION EMBEDDINGS ADAPTATIFS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        import torch\n",
    "        \n",
    "        # Configuration GPU/CPU automatique\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"üîß Device: {device}\")\n",
    "        \n",
    "        # Mod√®le optimis√©\n",
    "        print(\"üì• Chargement mod√®le all-MiniLM-L6-v2...\")\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "        \n",
    "        # Pr√©paration documents avec enrichissement contextuel\n",
    "        documents = []\n",
    "        metadata = []\n",
    "        \n",
    "        for source in sources:\n",
    "            # Enrichissement contextuel pour embeddings de qualit√©\n",
    "            doc_parts = [\n",
    "                f\"Repository: {source['repo']}\",\n",
    "                f\"File: {source['path']}\",\n",
    "                f\"Type: {source['type']}\",\n",
    "                f\"Priority: {'High' if source.get('priority', False) else 'Standard'}\"\n",
    "            ]\n",
    "            \n",
    "            # Ajout contexte sp√©cifique au type\n",
    "            if source['type'] == 'python':\n",
    "                doc_parts.append(\"Language: Python\")\n",
    "                if 'class ' in source['content'] or 'def ' in source['content']:\n",
    "                    doc_parts.append(\"Contains: Classes and Functions\")\n",
    "            elif source['type'] == 'markdown':\n",
    "                doc_parts.append(\"Format: Documentation\")\n",
    "                if source['path'].upper().startswith('README'):\n",
    "                    doc_parts.append(\"Contains: Project Documentation\")\n",
    "            \n",
    "            # Construction document enrichi\n",
    "            header = \" | \".join(doc_parts)\n",
    "            content = source['content']\n",
    "            \n",
    "            # Nettoyage contenu pour embeddings\n",
    "            content = content.replace('\\n\\n\\n', '\\n\\n')  # R√©duction espaces\n",
    "            content = content.replace('\\t', '  ')  # Normalisation indentation\n",
    "            \n",
    "            doc_text = f\"{header}\\n\\nContent:\\n{content}\"\n",
    "            documents.append(doc_text)\n",
    "            \n",
    "            metadata.append({\n",
    "                'repo': source['repo'],\n",
    "                'path': source['path'],\n",
    "                'type': source['type'],\n",
    "                'priority': source.get('priority', False),\n",
    "                'size': source['size']\n",
    "            })\n",
    "        \n",
    "        # Limitation adaptative pour performance\n",
    "        num_repos = len(available_repos)\n",
    "        if num_repos == 1:\n",
    "            MAX_DOCS = 200  # Plus de docs si mono-repo\n",
    "        elif num_repos <= 2:\n",
    "            MAX_DOCS = 150\n",
    "        else:\n",
    "            MAX_DOCS = 120\n",
    "        \n",
    "        if len(documents) > MAX_DOCS:\n",
    "            print(f\"‚ö° Limitation adaptative √† {MAX_DOCS} docs (performance cloud)\")\n",
    "            \n",
    "            # Priorisation intelligente\n",
    "            priority_docs = [(i, doc, meta) for i, (doc, meta) in enumerate(zip(documents, metadata)) if meta['priority']]\n",
    "            standard_docs = [(i, doc, meta) for i, (doc, meta) in enumerate(zip(documents, metadata)) if not meta['priority']]\n",
    "            \n",
    "            # S√©lection √©quilibr√©e\n",
    "            selected = []\n",
    "            selected.extend(priority_docs[:MAX_DOCS//2])  # 50% prioritaires\n",
    "            remaining = MAX_DOCS - len(selected)\n",
    "            selected.extend(standard_docs[:remaining])  # Reste standard\n",
    "            \n",
    "            # Tri par index original pour maintenir l'ordre\n",
    "            selected.sort(key=lambda x: x[0])\n",
    "            \n",
    "            documents = [item[1] for item in selected]\n",
    "            metadata = [item[2] for item in selected]\n",
    "            \n",
    "            print(f\"üìä S√©lection: {len([s for s in selected if s[2]['priority']])} prioritaires + {len([s for s in selected if not s[2]['priority']])} standard\")\n",
    "        \n",
    "        print(f\"üîÑ G√©n√©ration embeddings pour {len(documents)} documents...\")\n",
    "        print(f\"üìä R√©partition: {len([m for m in metadata if m['type'] == 'python'])} Python + {len([m for m in metadata if m['type'] == 'markdown'])} Markdown\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Configuration batch adaptative\n",
    "        if device == 'cuda':\n",
    "            batch_size = 64 if len(documents) > 100 else 32\n",
    "        else:\n",
    "            batch_size = 32 if len(documents) > 50 else 16\n",
    "        \n",
    "        print(f\"‚öôÔ∏è Batch size: {batch_size}\")\n",
    "        \n",
    "        # G√©n√©ration par batch avec monitoring\n",
    "        embeddings = model.encode(\n",
    "            documents, \n",
    "            batch_size=batch_size, \n",
    "            show_progress_bar=True,\n",
    "            convert_to_tensor=False,  # Numpy pour compatibilit√©\n",
    "            normalize_embeddings=True  # Normalisation pour cosine similarity\n",
    "        )\n",
    "        \n",
    "        emb_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Embeddings g√©n√©r√©s en {emb_time:.2f}s\")\n",
    "        print(f\"üìä {len(embeddings)} vecteurs de dimension {embeddings.shape[1]}\")\n",
    "        print(f\"‚ö° Performance: {len(documents)/emb_time:.1f} docs/sec\")\n",
    "        print(f\"üíæ Taille embeddings: {embeddings.nbytes / 1024 / 1024:.2f}MB\")\n",
    "        \n",
    "        # Validation qualit√© embeddings\n",
    "        if len(embeddings) > 1:\n",
    "            import numpy as np\n",
    "            # Test diversit√© (distance moyenne entre embeddings)\n",
    "            sample_size = min(50, len(embeddings))\n",
    "            sample_indices = np.random.choice(len(embeddings), sample_size, replace=False)\n",
    "            sample_embeddings = embeddings[sample_indices]\n",
    "            \n",
    "            from sklearn.metrics.pairwise import cosine_similarity\n",
    "            similarities = cosine_similarity(sample_embeddings)\n",
    "            avg_similarity = similarities.mean()\n",
    "            \n",
    "            print(f\"üéØ Qualit√©: Similarit√© moyenne = {avg_similarity:.3f} (optimal: 0.2-0.6)\")\n",
    "            \n",
    "            if avg_similarity > 0.8:\n",
    "                print(\"‚ö†Ô∏è Embeddings tr√®s similaires - documents possiblement redondants\")\n",
    "            elif avg_similarity < 0.1:\n",
    "                print(\"‚ö†Ô∏è Embeddings tr√®s diversifi√©s - v√©rifier coh√©rence corpus\")\n",
    "            else:\n",
    "                print(\"‚úÖ Qualit√© embeddings optimale\")\n",
    "        \n",
    "        embeddings_ready = True\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå D√©pendances manquantes: {e}\")\n",
    "        print(\"üí° Installation: !pip install sentence-transformers torch\")\n",
    "        embeddings_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur embeddings: {e}\")\n",
    "        embeddings_ready = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de sources - skip embeddings\")\n",
    "    embeddings_ready = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af985505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé RECHERCHE S√âMANTIQUE INTELLIGENTE + FALLBACK\n",
    "if embeddings_ready:\n",
    "    import numpy as np\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    def semantic_search_smart(query, top_k=5, min_score=0.1):\n",
    "        \"\"\"Recherche s√©mantique avec scoring intelligent\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # G√©n√©ration embedding query\n",
    "            query_embedding = model.encode([query], normalize_embeddings=True)\n",
    "            \n",
    "            # Calcul similarit√©\n",
    "            similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "            \n",
    "            # Filtrage par score minimum\n",
    "            valid_indices = [i for i, score in enumerate(similarities) if score >= min_score]\n",
    "            \n",
    "            if len(valid_indices) == 0:\n",
    "                print(f\"‚ö†Ô∏è Aucun r√©sultat avec score >= {min_score}\")\n",
    "                print(\"üí° Essayez une requ√™te plus g√©n√©rale\")\n",
    "                return []\n",
    "            \n",
    "            # Top r√©sultats\n",
    "            valid_similarities = similarities[valid_indices]\n",
    "            top_valid_indices = np.argsort(valid_similarities)[::-1][:top_k]\n",
    "            top_indices = [valid_indices[i] for i in top_valid_indices]\n",
    "            \n",
    "            results = []\n",
    "            for i, idx in enumerate(top_indices):\n",
    "                score = similarities[idx]\n",
    "                meta = metadata[idx]\n",
    "                doc = documents[idx]\n",
    "                \n",
    "                # Extraction preview intelligent\n",
    "                content_lines = doc.split('\\n')\n",
    "                content_start = next((i for i, line in enumerate(content_lines) if 'Content:' in line), 0) + 1\n",
    "                content_preview = '\\n'.join(content_lines[content_start:content_start+10])\n",
    "                \n",
    "                if len(content_preview) > 400:\n",
    "                    content_preview = content_preview[:400] + '...'\n",
    "                \n",
    "                # Score qualit√©\n",
    "                quality = \"üî• Excellent\" if score > 0.7 else \"‚úÖ Bon\" if score > 0.5 else \"üìù Pertinent\"\n",
    "                \n",
    "                results.append({\n",
    "                    'rank': i + 1,\n",
    "                    'score': float(score),\n",
    "                    'quality': quality,\n",
    "                    'repo': meta['repo'],\n",
    "                    'path': meta['path'],\n",
    "                    'type': meta['type'],\n",
    "                    'priority': meta['priority'],\n",
    "                    'size': meta['size'],\n",
    "                    'content_preview': content_preview\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur recherche: {e}\")\n",
    "            return []\n",
    "    \n",
    "    # Suggestions de repos publics alternatifs si peu de repos\n",
    "    def suggest_public_repos():\n",
    "        \"\"\"Suggestions de repos publics alternatifs\"\"\"\n",
    "        \n",
    "        public_alternatives = [\n",
    "            {\n",
    "                'name': 'python-projects',\n",
    "                'url': 'https://github.com/stephanedenis/python-projects.git',\n",
    "                'description': 'Projets Python publics'\n",
    "            },\n",
    "            {\n",
    "                'name': 'documentation',\n",
    "                'url': 'https://github.com/stephanedenis/documentation.git', \n",
    "                'description': 'Documentation publique'\n",
    "            },\n",
    "            {\n",
    "                'name': 'tutorials',\n",
    "                'url': 'https://github.com/stephanedenis/tutorials.git',\n",
    "                'description': 'Tutoriels et exemples'\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüí° SUGGESTION: Repos publics alternatifs disponibles:\")\n",
    "        for alt in public_alternatives:\n",
    "            print(f\"  üì¶ {alt['name']}: {alt['description']}\")\n",
    "            print(f\"     git clone {alt['url']}\")\n",
    "        \n",
    "        print(\"\\nüîß Pour ajouter un repo public:\")\n",
    "        print(\"!git clone https://github.com/username/repo.git repo-name\")\n",
    "        print(\"# Puis re-ex√©cuter les cellules de scan\")\n",
    "    \n",
    "    # Interface de recherche\n",
    "    print(f\"\\nüîé RECHERCHE S√âMANTIQUE INTELLIGENTE\")\n",
    "    print(\"=\" * 45)\n",
    "    print(f\"üìä Base: {len(embeddings)} documents de {len(available_repos)} repos\")\n",
    "    print(\"üéØ Exemples de requ√™tes:\")\n",
    "    print(\"  - 'filesystem implementation'\")\n",
    "    print(\"  - 'neural network training'\") \n",
    "    print(\"  - 'configuration management'\")\n",
    "    print(\"  - 'error handling patterns'\")\n",
    "    print(\"  - 'data processing pipeline'\")\n",
    "    \n",
    "    # Suggestions si peu de repos\n",
    "    if len(available_repos) == 1:\n",
    "        print(f\"\\nüìù Note: Fonctionnement avec repo unique ({available_repos[0]})\")\n",
    "        suggest_public_repos()\n",
    "    \n",
    "    # Test automatique avec requ√™te pertinente pour PaniniFS\n",
    "    test_queries = [\n",
    "        \"filesystem implementation\",\n",
    "        \"file system architecture\", \n",
    "        \"configuration management\",\n",
    "        \"autonomous system\"\n",
    "    ]\n",
    "    \n",
    "    best_query = None\n",
    "    best_results = []\n",
    "    \n",
    "    print(f\"\\nüß™ Test automatique - recherche de la meilleure requ√™te...\")\n",
    "    for query in test_queries:\n",
    "        results = semantic_search_smart(query, top_k=3, min_score=0.15)\n",
    "        if len(results) > len(best_results):\n",
    "            best_query = query\n",
    "            best_results = results\n",
    "    \n",
    "    if best_results:\n",
    "        print(f\"\\nüéØ Meilleure requ√™te: '{best_query}'\")\n",
    "        start_time = time.time()\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚ö° Recherche en {search_time:.3f}s\")\n",
    "        print(f\"üìä {len(best_results)} r√©sultats trouv√©s\")\n",
    "        \n",
    "        print(\"\\nüèÜ MEILLEURS R√âSULTATS:\")\n",
    "        for result in best_results[:3]:\n",
    "            print(f\"\\n{result['rank']}. {result['quality']} üìÅ {result['repo']}/{result['path']}\")\n",
    "            print(f\"   üéØ Score: {result['score']:.3f} | Type: {result['type']}\")\n",
    "            if result['priority']:\n",
    "                print(f\"   ‚≠ê Fichier prioritaire\")\n",
    "            print(f\"   üíæ Taille: {result['size']/1024:.1f}KB\")\n",
    "            print(f\"   üìù Preview: {result['content_preview'][:200]}...\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Aucun r√©sultat pertinent trouv√©\")\n",
    "        print(\"üí° Le corpus peut √™tre trop sp√©cialis√© ou les seuils trop hauts\")\n",
    "    \n",
    "    print(\"\\n‚úÖ SYST√àME DE RECHERCHE OP√âRATIONNEL\")\n",
    "    search_function_ready = True\n",
    "else:\n",
    "    search_function_ready = False\n",
    "    print(\"‚ö†Ô∏è Recherche non disponible - probl√®me embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä RAPPORT FINAL CLOUD AUTONOME\n",
    "print(\"\\nüéâ RAPPORT FINAL - MODE CLOUD AUTONOME\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "report = {\n",
    "    'mode': 'CLOUD' if IS_CLOUD else 'LOCAL',\n",
    "    'repos_clones': len(available_repos) if 'available_repos' in locals() else 0,\n",
    "    'sources_scannees': len(sources) if 'sources' in locals() else 0,\n",
    "    'embeddings_generes': len(embeddings) if 'embeddings_ready' else 0,\n",
    "    'recherche_active': search_function_ready if 'search_function_ready' in locals() else False,\n",
    "    'performance': {\n",
    "        'clonage': f\"{clone_time:.2f}s\" if 'clone_time' in locals() else 'N/A',\n",
    "        'scan': f\"{scan_time:.2f}s\" if 'scan_time' in locals() else 'N/A',\n",
    "        'embeddings': f\"{emb_time:.2f}s\" if 'emb_time' in locals() else 'N/A',\n",
    "        'recherche': f\"{search_time:.3f}s\" if 'search_time' in locals() else 'N/A'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üåç Mode: {report['mode']}\")\n",
    "print(f\"üì¶ Repos clon√©s: {report['repos_clones']}\")\n",
    "print(f\"üìÑ Sources scann√©es: {report['sources_scannees']}\")\n",
    "print(f\"üß† Embeddings g√©n√©r√©s: {report['embeddings_generes']}\")\n",
    "print(f\"üîé Recherche: {'‚úÖ ACTIVE' if report['recherche_active'] else '‚ùå INACTIVE'}\")\n",
    "\n",
    "print(\"\\n‚ö° PERFORMANCE:\")\n",
    "for step, time_val in report['performance'].items():\n",
    "    print(f\"  {step.capitalize()}: {time_val}\")\n",
    "\n",
    "# Calcul temps total\n",
    "total_time = 0\n",
    "if 'clone_time' in locals(): total_time += clone_time\n",
    "if 'scan_time' in locals(): total_time += scan_time\n",
    "if 'emb_time' in locals(): total_time += emb_time\n",
    "\n",
    "print(f\"\\nüèÅ TEMPS TOTAL: {total_time:.2f}s\")\n",
    "\n",
    "if report['recherche_active']:\n",
    "    print(\"\\nüéØ SYST√àME 100% OP√âRATIONNEL\")\n",
    "    print(\"üí° Utilisez: semantic_search_cloud('votre requ√™te')\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è SYST√àME PARTIELLEMENT OP√âRATIONNEL\")\n",
    "    print(\"üí° V√©rifiez les √©tapes pr√©c√©dentes\")\n",
    "\n",
    "print(\"\\nüöÄ MODE CLOUD AUTONOME COMPL√âT√â !\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c19084",
   "metadata": {},
   "source": [
    "# üéØ Utilisation Interactive\n",
    "\n",
    "## Recherche Personnalis√©e\n",
    "\n",
    "```python\n",
    "# Exemples de recherches\n",
    "results = semantic_search_cloud(\"neural network training\", top_k=5)\n",
    "results = semantic_search_cloud(\"configuration files\", top_k=3)\n",
    "results = semantic_search_cloud(\"error handling patterns\", top_k=5)\n",
    "```\n",
    "\n",
    "## Exploration des Repos\n",
    "\n",
    "```python\n",
    "# Voir les repos disponibles\n",
    "print(\"Repos disponibles:\", available_repos)\n",
    "\n",
    "# Statistiques par repo\n",
    "repo_stats = {}\n",
    "for source in sources:\n",
    "    repo = source['repo']\n",
    "    if repo not in repo_stats:\n",
    "        repo_stats[repo] = {'python': 0, 'markdown': 0}\n",
    "    repo_stats[repo][source['type']] += 1\n",
    "\n",
    "for repo, stats in repo_stats.items():\n",
    "    print(f\"{repo}: {stats['python']} .py + {stats['markdown']} .md\")\n",
    "```\n",
    "\n",
    "**‚úÖ Syst√®me Cloud Autonome Op√©rationnel !**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
