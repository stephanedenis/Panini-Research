#!/bin/bash
"""
üåå PLAN EXTERNALISATION TOTALE - AUTONOMIE POST-TOTORO
====================================================

Plan complet pour continuer l'√©volution autonome apr√®s extinction Totoro:
1. Migration Cloud (Google Colab + Drive)
2. Agents autonomes externalis√©s
3. Monitoring GitHub continu
4. Publications automatiques
5. Backup et synchronisation

OBJECTIF: 100% autonome sans d√©pendance hardware Totoro
"""

set -e

# Configuration
BASE_DIR="/home/stephane/GitHub/PaniniFS-1"
CLOUD_BACKUP_DIR="$BASE_DIR/cloud_backup"
EXTERNALIZATION_LOG="$BASE_DIR/externalization_$(date +%Y%m%d_%H%M%S).log"

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1" | tee -a "$EXTERNALIZATION_LOG"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1" | tee -a "$EXTERNALIZATION_LOG"
}

log_step() {
    echo -e "${PURPLE}[STEP]${NC} $1" | tee -a "$EXTERNALIZATION_LOG"
}

print_banner() {
    echo -e "${CYAN}"
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë  üåå EXTERNALISATION TOTALE PANINI - POST TOTORO              ‚ïë"
    echo "‚ïë                                                              ‚ïë"
    echo "‚ïë  üöÄ Migration Cloud Complete                                 ‚ïë"
    echo "‚ïë  ü§ñ Agents 100% Autonomes                                    ‚ïë"
    echo "‚ïë  üìä Monitoring Continu                                       ‚ïë"
    echo "‚ïë  üìö Publications Automatiques                                ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo -e "${NC}"
}

# Phase 1: Pr√©paration migration cloud
prepare_cloud_migration() {
    log_step "Phase 1: Pr√©paration migration cloud"
    
    # Cr√©ation structure backup
    mkdir -p "$CLOUD_BACKUP_DIR"/{agents,config,data,publications,credentials}
    
    # Copie agents critiques
    log_info "Sauvegarde agents autonomes..."
    cp -r Copilotage/agents/* "$CLOUD_BACKUP_DIR/agents/"
    cp -r Copilotage/scripts/* "$CLOUD_BACKUP_DIR/agents/"
    
    # Configuration essentielle
    log_info "Sauvegarde configuration..."
    cp *.toml "$CLOUD_BACKUP_DIR/config/" 2>/dev/null || true
    cp *report*.json "$CLOUD_BACKUP_DIR/data/" 2>/dev/null || true
    
    # Publications
    log_info "Sauvegarde publications..."
    cp *.md "$CLOUD_BACKUP_DIR/publications/" 2>/dev/null || true
    cp remarkable_study_pack/*.pdf "$CLOUD_BACKUP_DIR/publications/" 2>/dev/null || true
    
    log_success "Backup local cr√©√© dans $CLOUD_BACKUP_DIR"
}

# Phase 2: Configuration Google Drive autonome
setup_google_drive_autonomous() {
    log_step "Phase 2: Configuration Google Drive autonome"
    
    # V√©rification credentials existants
    if [ ! -f "gdrive_credentials/credentials.json" ]; then
        log_info "‚ö†Ô∏è Credentials Google Drive manquants"
        log_info "üîß Configuration manuelle requise:"
        echo "   1. Aller sur https://console.cloud.google.com/"
        echo "   2. Cr√©er projet 'PaniniFS-Autonomous'"
        echo "   3. Activer Google Drive API"
        echo "   4. Cr√©er credentials OAuth2"
        echo "   5. T√©l√©charger credentials.json"
        echo "   6. Placer dans gdrive_credentials/"
        
        # Template credentials pour autonomie
        cat > gdrive_credentials/credentials_template.json << 'EOF'
{
  "web": {
    "client_id": "YOUR_CLIENT_ID",
    "project_id": "paninifs-autonomous",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "client_secret": "YOUR_CLIENT_SECRET",
    "redirect_uris": ["http://localhost:8080/callback"]
  }
}
EOF
        
        log_info "Template cr√©√© dans gdrive_credentials/credentials_template.json"
    else
        log_success "Credentials Google Drive d√©tect√©s"
    fi
    
    # Test connection Google Drive
    log_info "Test connexion Google Drive..."
    if python3 -c "
import sys
sys.path.append('Copilotage/scripts')
try:
    from autonomous_gdrive_manager import DriveManager
    manager = DriveManager()
    print('‚úÖ Google Drive API fonctionnelle')
except Exception as e:
    print(f'‚ö†Ô∏è Erreur Google Drive: {e}')
    " 2>/dev/null; then
        log_success "Google Drive API op√©rationnelle"
    else
        log_info "‚ö†Ô∏è Configuration Google Drive requise pour autonomie totale"
    fi
}

# Phase 3: D√©ploiement agents cloud
deploy_cloud_agents() {
    log_step "Phase 3: D√©ploiement agents cloud"
    
    # Cr√©ation script d√©ploiement Colab
    cat > "$CLOUD_BACKUP_DIR/deploy_to_colab.py" << 'EOF'
#!/usr/bin/env python3
"""
üöÄ D√âPLOIEMENT AGENTS COLAB AUTONOMES
"""
import os
import json
from google.colab import files, drive
import subprocess

def setup_colab_environment():
    """Setup environnement Colab pour agents autonomes"""
    print("üîß Setup environnement Colab...")
    
    # Installation d√©pendances
    !pip install -q google-api-python-client google-auth-httplib2 google-auth-oauthlib
    !pip install -q requests beautifulsoup4 aiohttp schedule
    !pip install -q GitPython pygithub
    
    # Mount Drive
    drive.mount('/content/drive')
    
    # Cr√©ation structure
    os.makedirs('/content/panini_agents', exist_ok=True)
    os.chdir('/content/panini_agents')
    
    print("‚úÖ Environnement Colab pr√™t")

def deploy_agents():
    """D√©ploie agents depuis Drive"""
    print("ü§ñ D√©ploiement agents...")
    
    # Copy agents depuis Drive
    !cp -r /content/drive/MyDrive/Panini/agents/* /content/panini_agents/
    
    # Lancement orchestrateur
    subprocess.Popen(['python3', 'continuous_improvement_orchestrator.py'])
    
    print("‚úÖ Agents d√©ploy√©s et actifs")

if __name__ == "__main__":
    setup_colab_environment()
    deploy_agents()
EOF
    
    # Script monitoring GitHub autonome
    cat > "$CLOUD_BACKUP_DIR/github_autonomous_monitor.py" << 'EOF'
#!/usr/bin/env python3
"""
üëÅÔ∏è MONITORING GITHUB AUTONOME
"""
import requests
import time
import json
from datetime import datetime

class GitHubAutonomousMonitor:
    def __init__(self):
        self.repos = [
            'stephanedenis/PaniniFS',
            'stephanedenis/Panini-DevOps'
        ]
        
    def monitor_continuous(self):
        """Monitoring continu GitHub"""
        while True:
            try:
                for repo in self.repos:
                    self.check_workflows(repo)
                    self.check_issues(repo)
                
                time.sleep(300)  # Check toutes les 5 min
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur monitoring: {e}")
                time.sleep(600)
                
    def check_workflows(self, repo):
        """V√©rifie workflows GitHub"""
        url = f"https://api.github.com/repos/{repo}/actions/runs"
        response = requests.get(url)
        
        if response.status_code == 200:
            data = response.json()
            failed_runs = [run for run in data['workflow_runs'] 
                          if run['conclusion'] == 'failure']
            
            if failed_runs:
                print(f"üö® {len(failed_runs)} workflows failed pour {repo}")
                
    def check_issues(self, repo):
        """V√©rifie issues GitHub"""
        url = f"https://api.github.com/repos/{repo}/issues"
        response = requests.get(url)
        
        if response.status_code == 200:
            issues = response.json()
            open_issues = [i for i in issues if i['state'] == 'open']
            
            if len(open_issues) > 5:
                print(f"‚ö†Ô∏è {len(open_issues)} issues ouvertes pour {repo}")

if __name__ == "__main__":
    monitor = GitHubAutonomousMonitor()
    monitor.monitor_continuous()
EOF
    
    log_success "Scripts cloud d√©ploy√©s dans $CLOUD_BACKUP_DIR"
}

# Phase 4: Configuration cron autonome
setup_autonomous_cron() {
    log_step "Phase 4: Configuration cron autonome"
    
    # Sauvegarde crontab actuel
    crontab -l > "$CLOUD_BACKUP_DIR/crontab_backup.txt" 2>/dev/null || true
    
    # Cr√©ation nouveau crontab
    cat > "$CLOUD_BACKUP_DIR/autonomous_crontab.txt" << 'EOF'
# PaniniFS Autonomous Operations - Post Totoro
# ===========================================

# Recherche th√©orique hebdomadaire (Dimanche 2h)
0 2 * * 0 cd /home/stephane/GitHub/PaniniFS-1 && python3 Copilotage/agents/theoretical_research_agent.py >> logs/cron_research.log 2>&1

# Critique adverse quotidienne (1h)
0 1 * * * cd /home/stephane/GitHub/PaniniFS-1 && python3 Copilotage/agents/adversarial_critic_agent.py >> logs/cron_critic.log 2>&1

# Monitoring GitHub (toutes les 30 min)
*/30 * * * * cd /home/stephane/GitHub/PaniniFS-1 && python3 Copilotage/scripts/github_workflow_monitor.py >> logs/cron_github.log 2>&1

# Backup Google Drive (quotidien 6h)
0 6 * * * cd /home/stephane/GitHub/PaniniFS-1 && python3 Copilotage/scripts/autonomous_gdrive_manager.py >> logs/cron_backup.log 2>&1

# Publications automatiques (hebdomadaire Lundi 10h)
0 10 * * 1 cd /home/stephane/GitHub/PaniniFS-1 && python3 Copilotage/scripts/generate_remarkable_bibliography.py >> logs/cron_publications.log 2>&1

# Nettoyage logs (mensuel)
0 3 1 * * find /home/stephane/GitHub/PaniniFS-1/logs -name "*.log" -mtime +30 -delete
EOF
    
    log_info "Crontab autonome cr√©√© dans $CLOUD_BACKUP_DIR/autonomous_crontab.txt"
    log_info "Pour activer: crontab $CLOUD_BACKUP_DIR/autonomous_crontab.txt"
}

# Phase 5: Tests pr√©-externalisation
run_pre_externalization_tests() {
    log_step "Phase 5: Tests pr√©-externalisation"
    
    log_info "Test 1: Agents autonomes..."
    if python3 -c "
import sys
sys.path.append('Copilotage/agents')
try:
    from continuous_improvement_orchestrator import ContinuousImprovementOrchestrator
    print('‚úÖ Orchestrateur OK')
except Exception as e:
    print(f'‚ùå Erreur orchestrateur: {e}')
    "; then
        log_success "Orchestrateur fonctionnel"
    else
        log_info "‚ö†Ô∏è V√©rifier orchestrateur"
    fi
    
    log_info "Test 2: GitHub API..."
    if python3 -c "
import requests
try:
    response = requests.get('https://api.github.com/repos/stephanedenis/PaniniFS')
    if response.status_code == 200:
        print('‚úÖ GitHub API OK')
    else:
        print(f'‚ö†Ô∏è GitHub API: {response.status_code}')
except Exception as e:
    print(f'‚ùå Erreur GitHub: {e}')
    "; then
        log_success "GitHub API accessible"
    else
        log_info "‚ö†Ô∏è V√©rifier connexion GitHub"
    fi
    
    log_info "Test 3: Espace disque..."
    DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
    if [ "$DISK_USAGE" -lt 80 ]; then
        log_success "Espace disque OK ($DISK_USAGE%)"
    else
        log_info "‚ö†Ô∏è Espace disque limit√© ($DISK_USAGE%)"
    fi
}

# Phase 6: Instructions finales
generate_final_instructions() {
    log_step "Phase 6: Instructions finales externalisation"
    
    cat > "$CLOUD_BACKUP_DIR/POST_TOTORO_INSTRUCTIONS.md" << 'EOF'
# üåå INSTRUCTIONS POST-TOTORO - AUTONOMIE TOTALE

## √âtapes imm√©diates apr√®s extinction Totoro

### 1. Activation Google Colab
```bash
# Ouvrir Google Colab
# Uploader deploy_to_colab.py depuis Drive
# Ex√©cuter setup automatique
```

### 2. Activation crontab sur serveur backup
```bash
# Si serveur Linux disponible:
crontab autonomous_crontab.txt
systemctl status cron
```

### 3. Monitoring actif
- GitHub: github_autonomous_monitor.py
- Drive: Synchronisation automatique
- Publications: G√©n√©ration hebdomadaire

### 4. Acc√®s publications tablette reMarkable
- Drive/Panini/Publications/: PDFs annotables
- Drive/Panini/Bibliographie/: Recherche th√©orique
- Synchronisation automatique quotidienne

### 5. Contact urgence
Si probl√®me critique:
- GitHub Issues: stephanedenis/PaniniFS
- Email backup: voir gdrive_credentials/

## Statut attendu
‚úÖ Recherche th√©orique: Continue automatiquement
‚úÖ Critique adverse: Quotidienne  
‚úÖ Publications: Mises √† jour hebdomadaires
‚úÖ Monitoring: 24/7 via cloud
‚úÖ Backup: Quotidien sur Drive

## M√©triques succ√®s
- 0 intervention manuelle requise
- Publications √† jour sur tablette
- Monitoring GitHub actif
- Am√©lioration continue mesurable
EOF
    
    log_success "Instructions finales cr√©√©es"
}

# Fonction principale
main() {
    print_banner
    
    log_info "üöÄ D√âBUT EXTERNALISATION TOTALE - $(date)"
    log_info "Objectif: Autonomie 100% post-Totoro"
    
    prepare_cloud_migration
    setup_google_drive_autonomous  
    deploy_cloud_agents
    setup_autonomous_cron
    run_pre_externalization_tests
    generate_final_instructions
    
    echo ""
    echo -e "${GREEN}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó${NC}"
    echo -e "${GREEN}‚ïë  üéâ EXTERNALISATION TOTALE PR√äTE !                           ‚ïë${NC}"
    echo -e "${GREEN}‚ïë                                                              ‚ïë${NC}"
    echo -e "${GREEN}‚ïë  Dans 1 heure vous pourrez √©teindre Totoro en s√©curit√©      ‚ïë${NC}"
    echo -e "${GREEN}‚ïë                                                              ‚ïë${NC}"
    echo -e "${GREEN}‚ïë  ü§ñ Agents autonomes: PR√äTS                                  ‚ïë${NC}"
    echo -e "${GREEN}‚ïë  ‚òÅÔ∏è Cloud backup: CONFIGUR√â                                  ‚ïë${NC}"
    echo -e "${GREEN}‚ïë  üìä Monitoring: ACTIF                                        ‚ïë${NC}"
    echo -e "${GREEN}‚ïë  üìö Publications: SYNCHRONIS√âES                              ‚ïë${NC}"
    echo -e "${GREEN}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù${NC}"
    echo ""
    
    log_success "üåå Backup complet cr√©√© dans: $CLOUD_BACKUP_DIR"
    log_success "üìã Instructions: $CLOUD_BACKUP_DIR/POST_TOTORO_INSTRUCTIONS.md"
    log_success "‚è∞ ETA extinction Totoro: 1 heure"
    
    echo ""
    echo -e "${CYAN}Prochaines √©tapes:${NC}"
    echo "1. V√©rifier $CLOUD_BACKUP_DIR/POST_TOTORO_INSTRUCTIONS.md"
    echo "2. Activer: crontab $CLOUD_BACKUP_DIR/autonomous_crontab.txt"
    echo "3. Tester Google Drive: python3 Copilotage/scripts/autonomous_gdrive_manager.py"
    echo "4. ‚ú® √âteindre Totoro quand pr√™t !"
}

# Ex√©cution
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
